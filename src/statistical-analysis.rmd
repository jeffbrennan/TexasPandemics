---
title: "COVID Statistical Analysis"
author: "Hongyin Lai, Yuan Li, Tara Prezioso, Alison Rector, Jeffrey Brennan, Swaminathan Kumar, Jose-Miguel Yamal"
output:
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: console
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
   output_dir = "diagnostics/",
   knit_root_dir = "C:/Users/jeffb/Desktop/Life/personal-projects/COVID") })
---

# SETUP

```{r, echo = FALSE}
# performance analysis 
# source: https://bookdown.org/yihui/rmarkdown-cookbook/time-chunk.html
all_times = list()  # store the time for each chunk
knitr::knit_hooks$set(time_it = local({
  now = NULL
  function(before, options) {
    if (before) {
      now <<- Sys.time()
    } else {
      res = difftime(Sys.time(), now)
      all_times[[options$label]] <<- res
    }
  }
}))
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# knitr::opts_chunk$set(time_it = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

```{r, warning=FALSE, message=FALSE}
# Data manipulation & cleaning
library(tidyverse)
library(reshape2)
library(nlme)        # gapply
library(data.table)

# Modeling & stats
library(mgcv)       # gam
library(R0)         # rt
library(Kendall)    # Mann-Kendall

# Time series & forecasting
library(forecast)
library(zoo)
library(astsa)
library(fpp2)

select = dplyr::select
```


```{r}
refactor_version = 1.1
set.seed(1)
```

```{r}
# Obtain dfs for analysis
Clean_Data = function(df, level_type) { 
  if (level_type == 'State') {
    clean_df  = df %>% 
      dplyr::select(Date, Cases_Daily_Imputed, Tests_Daily, Population_DSHS) %>%
      group_by(Date) %>% 
      mutate_if(is.numeric, sum, na.rm = TRUE) %>% 
      distinct() %>%
      mutate(Date = as.Date(Date)) %>% 
      arrange(Date) %>% 
      distinct()

  } else { 
    clean_df = df %>% 
      dplyr::select(Date, !!as.name(level_type), Cases_Daily_Imputed, Tests_Daily, Population_DSHS) %>%
      group_by(Date, !!as.name(level_type)) %>% 
      mutate_if(is.numeric, sum, na.rm = TRUE) %>%
      distinct() %>%
      mutate(Date = as.Date(Date)) %>% 
      arrange(Date, !!as.name(level_type)) %>% 
      distinct()
  }
  return(clean_df %>% ungroup())
}

# county_tpr = read.csv('tableau/county_TPR.csv') %>% 
#   dplyr::select(County, Date) %>% 
#   mutate(Date = as.Date(Date))

county = read.csv("tableau/county.csv") %>% 
  dplyr::select(Date, Cases_Daily_Imputed, Tests_Daily,
                County, TSA_Combined, PHR_Combined,
                Metro_Area, Population_DSHS) %>% 
  mutate(Date = as.Date(Date)) %>%
  # left_join(., county_tpr, by = c('County', 'Date')) %>% 
  # mutate(TPR = ifelse(Date < min(county_tpr$Date), NA, TPR),
         # Cases_100K_7Day_MA = ifelse(Date < min(county_tpr$Date), NA, Cases_100K_7Day_MA)) %>%
  # group_by(County) %>%
  # tidyr::fill(TPR, .direction = "down") %>%
  # tidyr::fill(Cases_100K_7Day_MA, .direction = "down") %>%
  # ungroup(County) %>%
  rename(TSA = TSA_Combined, PHR = PHR_Combined, Metro = Metro_Area) 

clean_dfs = sapply(c('County', 'TSA', 'PHR', 'Metro', 'State'), function(x) Clean_Data(county, x))

# add hospitalizations
hospitalizations = read.csv("tableau/hospitalizations_tsa.csv") %>%
  dplyr::select(Date, TSA_Combined, Hospitalizations_Total) %>%
  rename(TSA = TSA_Combined) %>%
  mutate(Date = as.Date(Date)) %>%
  arrange(Date, TSA)

clean_dfs$TSA = clean_dfs$TSA %>% left_join(., hospitalizations, by = c('Date', 'TSA'))

state_hosp = hospitalizations %>% 
  group_by(Date) %>%
  summarize(Hospitalizations_Total = sum(Hospitalizations_Total))

clean_dfs$State = clean_dfs$State %>% left_join(., state_hosp, by = 'Date')
```


```{r}
#extract data frames from the list
County_df = clean_dfs$County
TSA_df = clean_dfs$TSA |> distinct()
PHR_df = clean_dfs$PHR
Metro_df = clean_dfs$Metro
State_df = clean_dfs$State

case_quant = County_df %>%
  filter(Date >= (max(Date) - as.difftime(3, unit = 'weeks'))) %>%
  group_by(County) %>%
  mutate(mean_cases = mean(Cases_Daily_Imputed, na.rm = TRUE)) %>%
  dplyr::select(mean_cases) %>%
  ungroup() %>%
  summarize(case_quant = quantile(mean_cases, c(0.4, 0.5, 0.6, 0.7, 0.8), na.rm = TRUE)[4]) %>% 
  unlist()
```

# RT ANALYSIS

```{r}
rt.df.extraction = function(Rt.estimate.output) {

  # extract r0 estimate values into dataframe
  rt.df = setNames(stack(Rt.estimate.output$estimates$TD$R)[2:1], c('Date', 'Rt'))
  rt.df$Date = as.Date(rt.df$Date)

  # get 95% CI
  CI.lower.list = Rt.estimate.output$estimates$TD$conf.int$lower
  CI.upper.list = Rt.estimate.output$estimates$TD$conf.int$upper

  #use unlist function to format as vector
  CI.lower = unlist(CI.lower.list, recursive = TRUE, use.names = TRUE)
  CI.upper = unlist(CI.upper.list, recursive = TRUE, use.names = TRUE)

  rt.df$lower = CI.lower
  rt.df$upper = CI.upper
  
  rt.df = rt.df %>%
    mutate(lower = replace(lower, Rt == 0, NA)) %>%
    mutate(upper = replace(upper, Rt == 0, NA)) %>%
    mutate(Rt = replace(Rt, Rt == 0, NA))
  
  return(rt.df)
}
```

```{r}
#Function to generate Rt estimates, need to read in data frame and population size
covid.rt = function(mydata, threshold) {
  set.seed(1)
  
  ### DECLARE VALS ###
  #set generation time
  #Tapiwa, Ganyani "Esimating the gen interval for Covid-19":

  # LOGNORMAL OPS
  # gen.time=generation.time("lognormal", c(4.0, 2.9))
  # gen.time=generation.time("lognormal", c(4.7,2.9)) #Nishiura

  # GAMMA OPS
  # gen.time=generation.time("gamma", c(5.2, 1.72)) #Singapore
  # gen.time=generation.time("gamma", c(3.95, 1.51)) #Tianjin
  gen.time = generation.time("gamma", c(3.96, 4.75))
  print(mydata %>% dplyr::select(2) %>% distinct() %>% unlist() %>% setNames(NULL))

  #change na values to 0
  mydata = mydata %>% mutate(Cases_Daily_Imputed = ifelse(is.na(Cases_Daily_Imputed), 0, Cases_Daily_Imputed))
  
  # get case average from past month
  recent_case_avg = mydata %>% 
    filter(Date > seq(max(Date), length = 2, by = "-3 weeks")[2]) %>%
    summarize(mean(Cases_Daily_Imputed, na.rm = TRUE)) %>% 
    unlist()
  
  print(round(recent_case_avg, 2))
  
  pop.DSHS = mydata$Population_DSHS[1]
  #Get 7 day moving average of daily cases
  mydata$MA_7day=rollmean(mydata$Cases_Daily_Imputed, k=7, na.pad=TRUE, align='right')

  #create a vector of new cases 7 day moving average
  mydata.new=pull(mydata, MA_7day)
  #mydata.new = pull(mydata, Cases_Daily_Imputed)
  
  # get dates as vectors
  date.vector = pull(mydata, Date)
  
  #create a named numerical vector using the date.vector as names of new cases
  #Note: this is needed to run R0 package function estimate.R()
  names(mydata.new) = c(date.vector)
  
  
  #get row number of March 15 and first nonzero entry
  #NOTE: for 7 day moving average start March 15, for daily start March 9
  #find max row between the two (this will be beginning of rt data used)
  march15.row = which(mydata$Date=="2020-03-15")
  first.nonzero = min(which(mydata$Cases_Daily_Imputed>0))
  last.nonzero = max(which(mydata$Cases_Daily_Imputed>0))
  
  first.nonzero = ifelse(is.infinite(first.nonzero), NA, first.nonzero)
  last.nonzero = ifelse(is.infinite(last.nonzero), NA, last.nonzero)

  minrow = max(march15.row, first.nonzero, na.rm = TRUE)
  maxrow = as.integer(min(last.nonzero, nrow(mydata), na.rm = TRUE))

  # restrict df to same region as the minrow for addition of TPR & Cases/100
  # TODO: work entirely off mydata and remove individual vars for which row is where
  mydata = mydata %>% slice(minrow:maxrow)
  
  ### R0 ESTIMATION ###
  #reduce the vector to be rows from min date (March 9 or first nonzero case) to current date
  mydata.newest = mydata.new[minrow:maxrow]
    
  tryCatch({
    rt.DSHS = estimate.R(mydata.newest, 
                        gen.time, 
                        begin=as.integer(1),
                        end=length(mydata.newest),
                        methods=c("TD"), 
                        pop.size=pop.DSHS,
                        nsim=1000)
  
    rt.DSHS.df <<- rt.df.extraction(rt.DSHS) %>% 
                    dplyr::select(Date, Rt, lower, upper)
    
    rt.DSHS.df$case_avg = recent_case_avg
    rt.DSHS.df$threshold = ifelse(recent_case_avg > threshold, 'Above', 'Below')
    
    },
    error = function(e) {
      writeLines(paste0('Rt generation error (despite sufficient cases)', '\n'))
      rt.DSHS.df <<- data.frame(Date = as.Date(mydata$Date),
                               Rt = rep(NA, length(mydata$Date)),
                               lower = rep(NA, length(mydata$Date)),
                               upper = rep(NA, length(mydata$Date)),
                               case_avg = NA,
                               threshold = NA)
    })
  return(rt.DSHS.df)
}
```

## County

```{r}
# Generate Rt estimates for each county, using 70% quantile of cases in past 3 weeks as threshold
start_time = Sys.time()
# 13.7 minutes
county.rt.output = nlme::gapply(County_df, FUN = covid.rt,
                                 groups = County_df$County, threshold = case_quant)
print(Sys.time() - start_time)

# combine list of dataframes (1 for each county) to single dataframe
RT_County_df_all = rbindlist(county.rt.output, idcol = 'County') %>% 
  mutate(Date = as.Date(Date))

RT_County_df_all$County %>% unique() %>% length()

# remove errors
min_date = seq(max(RT_County_df_all$Date), length = 2, by = "-3 weeks")[2]
error_counties = RT_County_df_all %>%
  group_by(County) %>%
  mutate(CI_error = factor(ifelse(lower == 0 & upper == 0, 1, 0))) %>%
  mutate(Rt_error = factor(ifelse(is.na(Rt) | Rt == 0 | Rt > 10, 1, 0))) %>%
  filter(Date > min_date & Date != max(Date)) %>%
  filter(is.na(CI_error) | CI_error == 1 | Rt_error == 1) %>%
  dplyr::select(County) %>% 
  distinct() %>%
  unlist()


RT_County_df = RT_County_df_all %>% 
  mutate(Rt = ifelse(County %in% error_counties, NA, Rt)) %>% 
  mutate(lower = ifelse(County %in% error_counties, NA, lower)) %>% 
  mutate(upper = ifelse(County %in% error_counties, NA, upper))
good_counties = RT_County_df$County %>% unique() %>% length()
good_counties/254 # = 0.744
```


<!-- Parallel implementation -->

<!-- ```{r} -->
<!-- library(parallel) -->
<!-- library(pbapply) -->
<!-- Create_Worker = function(fnc_vec) { -->
<!--   n.cores = detectCores() -->
<!--   cl = makeCluster(n.cores) -->

<!--   # create n=12 worker environment -->
<!--   clusterEvalQ(cl, -->
<!--                c(library(magrittr), -->
<!--                  library(dplyr), -->
<!--                  library(R0), -->
<!--                  library(zoo))) %>%  -->
<!--     invisible() -->

<!--   clusterExport(cl, fnc_vec) %>% invisible() -->
<!--   return(cl) -->
<!-- } -->

<!-- rt.df.extraction2 = function(Rt.estimate.output) { -->

<!--   # extract r0 estimate values into dataframe -->
<!--   rt.df = setNames(stack(Rt.estimate.output$estimates$TD$R)[2:1], c('Date', 'Rt')) -->
<!--   rt.df$Date = as.Date(rt.df$Date) -->

<!--   # get 95% CI -->
<!--   CI.lower.list = Rt.estimate.output$estimates$TD$conf.int$lower -->
<!--   CI.upper.list = Rt.estimate.output$estimates$TD$conf.int$upper -->

<!--   #use unlist function to format as vector -->
<!--   CI.lower = unlist(CI.lower.list, recursive = TRUE, use.names = TRUE) -->
<!--   CI.upper = unlist(CI.upper.list, recursive = TRUE, use.names = TRUE) -->

<!--   rt.df$lower = CI.lower -->
<!--   rt.df$upper = CI.upper -->

<!--   rt.df = rt.df %>% -->
<!--     mutate(lower = replace(lower, Rt == 0, NA)) %>% -->
<!--     mutate(upper = replace(upper, Rt == 0, NA)) %>% -->
<!--     mutate(Rt = replace(Rt, Rt == 0, NA)) -->

<!--   return(rt.df) -->
<!-- } -->

<!-- mc_covid_rt = function(df, threshold) { -->
<!--   set.seed(1) -->
<!--   county = df %>% slice(1) %>% pull(County)  -->
<!--   print(county) -->

<!--   mydata = df %>% -->
<!--     mutate(Cases_Daily_Imputed = ifelse(is.na(Cases_Daily_Imputed), 0, Cases_Daily_Imputed)) %>%  -->
<!--     mutate(MA_7day = rollmean(Cases_Daily_Imputed, k = 7, na.pad = TRUE, align = 'right')) -->


<!--   pop_DSHS = pop_list %>% filter(County == County) %>% pull(Population_DSHS) -->


<!--   # get case average from past month -->
<!--   recent_case_avg = mydata %>%  -->
<!--     filter(Date > seq(max(Date), length = 2, by = "-3 weeks")[2]) %>% -->
<!--     summarize(mean(Cases_Daily_Imputed, na.rm = TRUE)) %>%  -->
<!--     unlist() %>%  -->
<!--     unname() %>%  -->
<!--     round(2) %>%  -->
<!--     paste0(county, ' 3 week avg: ', ., ' cases') -->

<!--   #create a vector of new cases 7 day moving average -->
<!--   mydata.new=pull(mydata, MA_7day) -->
<!--   date.vector = pull(mydata, Date) -->

<!--   #create a named numerical vector using the date.vector as names of new cases -->
<!--   #Note: this is needed to run R0 package function estimate.R() -->
<!--   names(mydata.new) = c(date.vector) -->

<!--   #get row number of March 15 and first nonzero entry -->
<!--   #NOTE: for 7 day moving average start March 15, for daily start March 9 -->
<!--   #find max row between the two (this will be beginning of rt data used) -->
<!--   march15_row = which(mydata$Date=="2020-03-15") -->
<!--   first_nonzero = which(mydata$Cases_Daily_Imputed>0) %>%  -->
<!--     min() %>%  -->
<!--     ifelse(is.infinite(.), NA, .) -->

<!--   last.nonzero = which(mydata$Cases_Daily_Imputed>0) %>%  -->
<!--     max() %>%  -->
<!--     ifelse(is.infinite(.), NA, .) -->

<!--   minrow = max(march15_row, first_nonzero, na.rm = TRUE) -->
<!--   maxrow = as.integer(min(last.nonzero, nrow(mydata), na.rm = TRUE)) -->

<!--   # restrict df to same region as the minrow for addition of TPR & Cases/100 -->
<!--   mydata = mydata %>% slice(minrow:maxrow) -->

<!--   ### R0 ESTIMATION ### -->
<!--   #reduce the vector to be rows from min date (March 15 or first nonzero case) to current date -->
<!--   mydata.newest = mydata.new[minrow:maxrow] -->

<!--   rt.DSHS.df = tryCatch({ -->
<!--     rt.DSHS = estimate.R(mydata.newest,  -->
<!--                         gen.time,  -->
<!--                         begin=as.integer(1), -->
<!--                         end=length(mydata.newest), -->
<!--                         methods=c("TD"),  -->
<!--                         pop.size=pop_DSHS, -->
<!--                         nsim=1000) -->

<!--     rt.df.extraction(rt.DSHS) %>% -->
<!--       select(Date, Rt, lower, upper) %>% -->
<!--       mutate(case_avg = recent_case_avg) %>%  -->
<!--       mutate(threshold = ifelse(recent_case_avg > threshold, 'Above', 'Below')) -->
<!--     }, -->
<!--     error = function(e) { -->
<!--       writeLines(paste0('Rt generation error (despite sufficient cases)', '\n')) -->
<!--       return(data.frame(Date = as.Date(mydata$Date), -->
<!--                                Rt = rep(NA, length(mydata$Date)), -->
<!--                                lower = rep(NA, length(mydata$Date)), -->
<!--                                upper = rep(NA, length(mydata$Date)), -->
<!--                                case_avg = NA, -->
<!--                                threshold = NA)) -->
<!--     }) -->
<!--   return(rt.DSHS.df) -->
<!-- } -->

<!-- # 6 minutes 9 second -->
<!-- pop_list = County_df %>% group_by(County) %>% slice(1) %>% select(County, Population_DSHS) -->
<!-- gen.time = generation.time("gamma", c(3.96, 4.75)) -->
<!-- county_df_list = County_df %>% select(-Tests_Daily, -Population_DSHS) %>% group_split(County) -->


<!-- cl = Create_Worker(c('mc_covid.rt', 'rt.df.extraction')) -->
<!-- mc_rt = pblapply(county_df_list[1:10], mc_covid.rt, cl = cl, threshold = case_quant) -->
<!-- stopCluster(cl) -->
<!-- ``` -->


<!-- Result diff -->

<!-- ```{r} -->

<!-- ``` -->






```{r}
district = readxl::read_xlsx('tableau/district_school_reopening.xlsx', sheet=1) %>%
             mutate(LEA = as.character(LEA),
                    Date = as.Date(Date))

district_dates = 
  data.frame('Date' = rep(unique(district$Date), each = 254),
             'County' = rep(unique(County_df$County), times = length(unique(district$Date))))

TPR_df = read.csv('tableau/county_TPR.csv') %>%
  dplyr::select(-contains('Rt')) %>%
  mutate(Date = as.Date(Date))

cms_dates = list.files('C:/Users/jeffb/Desktop/Life/personal-projects/COVID/original-sources/historical/cms_tpr') %>%
  gsub('TPR_', '', .) %>%
  gsub('.csv', '', .) %>%
  as.Date()


cms_TPR_padded = 
  TPR_df %>%
    filter(Date %in% cms_dates) %>%
    left_join(., RT_County_df[, c('County', 'Date', 'Rt')], by = c('County', 'Date')) %>%
    full_join(., district_dates, by = c('County', 'Date')) %>% 
    group_by(County) %>% 
    arrange(County, Date) %>%
    tidyr::fill(TPR, .direction = 'up') %>%
    tidyr::fill(Tests, .direction = 'up') %>%
    tidyr::fill(Rt, .direction = 'up') %>% 
    arrange(County, Date) %>% 
    ungroup() %>% 
    mutate(Tests = ifelse(Date < as.Date('2020-09-09'), NA, Tests))


cpr_TPR = TPR_df %>% 
  filter(!(Date %in% cms_dates)) %>%
  left_join(., RT_County_df[, c('County', 'Date', 'Rt')], by = c('County', 'Date'))



county_TPR = cms_TPR_padded %>% filter(!(Date %in% district_dates$Date)) %>% rbind(cpr_TPR) %>% arrange(County, Date)
county_TPR_sd = cms_TPR_padded %>%  filter(Date %in% district_dates$Date) %>% rbind(cpr_TPR) %>% arrange(County, Date)

write.csv(county_TPR, 'tableau/county_TPR.csv', row.names = FALSE)
write.csv(county_TPR_sd, 'tableau/county_TPR_sd.csv', row.names = FALSE)
```


## TSA

```{r}
RT_TSA_output = nlme::gapply(TSA_df, FUN=covid.rt, groups=TSA_df$TSA, threshold = case_quant)
RT_TSA_df = rbindlist(RT_TSA_output, idcol = 'TSA')
```

## PHR

```{r}
RT_PHR_output = nlme::gapply(PHR_df, FUN=covid.rt, groups=PHR_df$PHR, threshold = case_quant)
RT_PHR_df = rbindlist(RT_PHR_output, idcol = 'PHR')
```

## Metro

```{r}
RT_Metro_output = nlme::gapply(Metro_df, FUN=covid.rt, groups=Metro_df$Metro, threshold = case_quant)
RT_Metro_df = rbindlist(RT_Metro_output, idcol = 'Metro')
```

## State

```{r}
RT_State_df = covid.rt(State_df, threshold = case_quant)
```

## grouping

```{r}
# Rename levels for easier parsing in tableau
colnames(RT_County_df)[1] = 'Level'
colnames(RT_Metro_df)[1] = 'Level'
colnames(RT_TSA_df)[1] = 'Level'
colnames(RT_PHR_df)[1] = 'Level'
RT_State_df$Level = 'Texas'

RT_County_df$Level_Type = 'County'
# RT_District_df$Level_Type = 'District'
RT_Metro_df$Level_Type = 'Metro'
RT_TSA_df$Level_Type = 'TSA'
RT_PHR_df$Level_Type = 'PHR'
RT_State_df$Level_Type = 'State'

RT_Combined_df = 
  rbind(RT_County_df, RT_TSA_df, RT_PHR_df, RT_Metro_df, RT_State_df) %>% 
  filter(Date != max(Date)) %>% 
  dplyr::select(-c(threshold, case_avg))

write.csv(RT_Combined_df, 'tableau/stacked_rt.csv', row.names = FALSE)
```

# TIME SERIES

```{r}
# Compute forecast (UPDATE PREDICTION PERIOD [days] AS NEEDED)
covid.arima.forecast=function(mydata, prediction.period = 10, mindate, threshold) {
  mindate = min(mydata$Date)
  print(as.character(mydata[1,2]))
  maxdate = max(mydata$Date)
  pred_start_label = format(mindate, format = '%m_%d')
  
  mydata = subset(mydata, Date >= mindate)
  model.length = as.numeric(length(mydata$Date) + prediction.period)
  
  recent_case_avg = mydata %>%
    filter(Date > seq(max(Date), length = 2, by = "-3 weeks")[2]) %>%
    summarize(mean(Cases_Daily_Imputed, na.rm = TRUE)) %>% 
    unlist()
  
  print(recent_case_avg)

  if(recent_case_avg >= threshold) {
    # arima requires cases to be a timeseries vector
    my.timeseries=ts(mydata$Cases_Daily_Imputed)

    library(pracma)
    my.timeseries=movavg(my.timeseries,7,"s")
    
    arima.fit = forecast::auto.arima(my.timeseries)
    # save parameters from arima autofit
    p= arima.fit$arma[1]          # autoregressive order 
    q= arima.fit$arma[2]          # moving average order 
    d=arima.fit$arma[6]           # differencing order from model
  
    # 10 day forecast, CI for lower and upper has confidence level 95% set by level =c(95,95)
    arima.forecast = forecast::forecast(arima.fit, h = prediction.period, level=c(95,95))

    #return a dataframe of the arima model(Daily cases by date)
    arima.out = data.frame(Date = seq(mindate, maxdate + prediction.period, by = 'days'),
                            Cases_Raw = c(mydata$Cases_Daily_Imputed, rep(NA, times = prediction.period)),
                            Cases_Daily_Imputed = c(my.timeseries, arima.forecast[['mean']]),
                            CI_Lower = c(rep(NA, times = length(my.timeseries)),
                                         arima.forecast[['lower']][, 2]),
                            CI_Upper = c(rep(NA, times = length(my.timeseries)),
                                         arima.forecast[['upper']][, 2]))
  
    } else {
    # insufficient data catch: return NA values for predictions 
    arima.out = data.frame(Date = seq(mindate, maxdate + prediction.period, by = 'days'),
                            Cases_Raw = c(mydata$Cases_Daily_Imputed, rep(NA, times = prediction.period)),
                            Cases_Daily_Imputed = rep(NA, times = model.length),
                            CI_Lower = rep(NA, times = model.length),
                            CI_Upper =  rep(NA, times = model.length))
              
    }
  #replace CI lower limit with 0 if negative
  arima.out$CI_Lower = ifelse(arima.out$CI_Lower>=0 ,arima.out$CI_Lower, 0)
  return(arima.out)
}
```

## County

```{r county ts}
ARIMA_Case_County_output = nlme::gapply(County_df,
                                   FUN = covid.arima.forecast,
                                   groups = County_df$County,
                                   threshold = case_quant)

ARIMA_Case_County_df = rbindlist(ARIMA_Case_County_output, idcol = 'County')
```

## TSA

```{r}
ARIMA_Case_TSA_output = nlme::gapply(TSA_df,
                                FUN = covid.arima.forecast,
                                groups = TSA_df$TSA,
                                threshold = case_quant)

ARIMA_Case_TSA_df = rbindlist(ARIMA_Case_TSA_output, idcol = 'TSA')
```

## PHR

```{r}
ARIMA_Case_PHR_output = nlme::gapply(PHR_df,
                                 FUN = covid.arima.forecast,
                                 groups = PHR_df$PHR,
                                 threshold = case_quant)

ARIMA_Case_PHR_df = rbindlist(ARIMA_Case_PHR_output, idcol='PHR')
```

## Metro

```{r}
ARIMA_Case_Metro_output = nlme::gapply(Metro_df,
                                  FUN = covid.arima.forecast,
                                  groups = Metro_df$Metro,
                                  threshold = case_quant)

ARIMA_Case_Metro_df = rbindlist(ARIMA_Case_Metro_output, idcol = 'Metro')
```

## State

```{r}
ARIMA_Case_State_df = covid.arima.forecast(State_df, mindate = as.Date('2020-03-04'), threshold = case_quant)
```

## grouping

```{r}
colnames(ARIMA_Case_County_df)[1] = 'Level'
colnames(ARIMA_Case_Metro_df)[1] = 'Level'
colnames(ARIMA_Case_TSA_df)[1] = 'Level'
ARIMA_Case_State_df$Level = 'Texas'
colnames(ARIMA_Case_PHR_df)[1] = 'Level'

ARIMA_Case_County_df$Level_Type = 'County'
ARIMA_Case_Metro_df$Level_Type = 'Metro'
ARIMA_Case_TSA_df$Level_Type = 'TSA'
ARIMA_Case_PHR_df$Level_Type = 'PHR'
ARIMA_Case_State_df$Level_Type = 'State'

ARIMA_Case_Combined_df = rbind(ARIMA_Case_County_df, ARIMA_Case_TSA_df, ARIMA_Case_PHR_df,
                               ARIMA_Case_Metro_df, ARIMA_Case_State_df)
write.csv(ARIMA_Case_Combined_df, 'tableau/stacked_case_timeseries.csv', row.names = FALSE)
```

# Hospitalization Time Series
```{r}
# Compute forecast (UPDATE PREDICTION PERIOD [days] AS NEEDED)
covid.arima.forecast=function(mydata, prediction.period = 10, mindate) {
  maxdate = max(mydata$Date)
  pred_start_label = format(mindate, format = '%m_%d')
  
  mydata = subset(mydata, Date >= mindate)
  model.length = as.numeric(length(mydata$Date) + prediction.period)

  if(max(mydata$Hospitalizations_Total>=100, na.rm = TRUE))
  {
    my.timeseries=ts(mydata$Hospitalizations_Total)

    library(pracma)
    my.timeseries=movavg(my.timeseries,7,"s")

    arima.fit = forecast::auto.arima(my.timeseries)

    # save parameters from arima autofit
    p= arima.fit$arma[1]          # autoregressive order 
    q= arima.fit$arma[2]          # moving average order 
    d=arima.fit$arma[6]           # differencing order from model
  
    # 10 day forecast, CI for lower and upper has confidence level 95% set by level =c(95,95)
    arima.forecast = forecast::forecast(arima.fit, h = prediction.period, level=c(95,95))

    #return a dataframe of the arima model (Daily cases by date)
    arima.out = data.frame(Date = seq(mindate, maxdate + prediction.period, by = 'days'),
                            # Cases_Raw = c(mydata$Hospitalizations_Total, rep(NA, times = prediction.period)),
                            Hospitalizations_Total = c(my.timeseries, arima.forecast[['mean']]),
                            CI_Lower = c(rep(NA, times = length(my.timeseries)),
                                         arima.forecast[['lower']][, 2]),
                            CI_Upper = c(rep(NA, times = length(my.timeseries)),
                                         arima.forecast[['upper']][, 2]))
    } else {
    # insufficient data catch: return NA values for predictions 
    arima.out = data.frame(Date = seq(mindate, maxdate + prediction.period, by = 'days'),
                            # Cases_Raw = c(mydata$Hospitalizations_Total, rep(NA, times = prediction.period)),
                            Hospitalizations_Total = rep(NA, times = model.length),
                            CI_Lower = rep(NA, times = model.length),
                            CI_Upper =  rep(NA, times = model.length))
    }
  #replace CI lower limit with 0 if negative
  arima.out$CI_Lower = ifelse(arima.out$CI_Lower>=0,arima.out$CI_Lower, 0)
  return(arima.out)
}
```

## TSA - Hospitalization

```{r tsa hosp ts}
ARIMA_Hosp_TSA_output = nlme::gapply(TSA_df,
                                     FUN = covid.arima.forecast,
                                     groups = TSA_df$TSA,
                                     mindate = as.Date('2020-04-12'))

ARIMA_Hosp_TSA_df = rbindlist(ARIMA_Hosp_TSA_output, idcol='TSA')
```

## State - hospitalization

```{r}
ARIMA_Hosp_State_df = covid.arima.forecast(State_df, mindate = as.Date('2020-04-12'))
```

## Stacking
```{r}
colnames(ARIMA_Hosp_TSA_df)[1] = 'Level'
ARIMA_Hosp_State_df$Level = 'Texas'

ARIMA_Hosp_TSA_df$Level_Type = 'TSA'
ARIMA_Hosp_State_df$Level_Type = 'State'

ARIMA_Hosp_Combined_df = rbind(ARIMA_Hosp_TSA_df, ARIMA_Hosp_State_df)
write.csv(ARIMA_Hosp_Combined_df, 'tableau/stacked_hosp_timeseries.csv', row.names = FALSE)
```

# STANDARD STATISTICAL TESTS        

## CASE RATIOS

```{r}
Calculate_Ratio = function(df) { 
  latestdate = max(df$Date)
  earliestdate = latestdate - 14
  middate = latestdate - 7
  
  current_ratio = df %>%
    setNames(c('Date', 'Level', 'Cases_Daily_Imputed')) %>%
    filter(Date > earliestdate) %>%
    mutate(Week = ifelse(Date <= latestdate & Date > middate, 'Week_2', 'Week_1')) %>%
    group_by(Level, Week) %>%
    summarize(Cases_Daily_mean = mean(Cases_Daily_Imputed), na.rm = TRUE) %>%
    summarize(current_ratio = Cases_Daily_mean / lag(Cases_Daily_mean)) %>%
    na.omit() %>%
    mutate(current_ratio = replace(current_ratio,
                                   is.infinite(current_ratio) | is.nan(current_ratio) | current_ratio <= 0,
                                   NA)) %>%
    mutate(current_ratio_cat = cut(current_ratio, breaks=unique(c(0,0.5,0.9,1.1,1.5,2,4,8,max(current_ratio)))))
    
  return(current_ratio)
}
```

### County
 
```{r}
Ratio_County_df = County_df %>%
  dplyr::select(Date, County, Cases_Daily_Imputed) %>%
  Calculate_Ratio()
```

### TSA

```{r case ratios}
Ratio_TSA_df = TSA_df %>%
  dplyr::select(Date, TSA, Cases_Daily_Imputed) %>% 
  Calculate_Ratio()
```

### PHR

```{r}
Ratio_PHR_df = PHR_df %>%
  dplyr::select(Date, PHR, Cases_Daily_Imputed) %>%
  Calculate_Ratio()
```

### Metro                                        

```{r}
Ratio_Metro_df = Metro_df %>%
  dplyr::select(Date, Metro, Cases_Daily_Imputed) %>%
  Calculate_Ratio()
```

### State

```{r}
Ratio_State_df = State_df %>%
  mutate(State = 'Texas') %>% 
  dplyr::select(Date, State, Cases_Daily_Imputed) %>%
  Calculate_Ratio()
```

### grouping

```{r}
Ratio_County_df$Level_Type = 'County'
Ratio_Metro_df$Level_Type = 'Metro'
Ratio_TSA_df$Level_Type = 'TSA'
Ratio_PHR_df$Level_Type = 'PHR'
Ratio_State_df$Level_Type = 'State'

Ratio_Combined_df = rbind(Ratio_County_df, Ratio_TSA_df, Ratio_PHR_df, 
                          Ratio_Metro_df, Ratio_State_df)

stacked_ratio_out = Ratio_Combined_df %>% 
  mutate(County = ifelse(Level_Type == 'County', as.character(Level), '')) %>% 
  mutate(TSA = ifelse(Level_Type == 'TSA', as.character(Level), '')) %>% 
  mutate(PHR = ifelse(Level_Type == 'PHR', as.character(Level), '')) %>% 
  mutate(`Metro Area` = ifelse(Level_Type == 'Metro', as.character(Level), '')) %>% 
  mutate(State = ifelse(Level_Type == 'State', as.character(Level), ''))

write.csv(stacked_ratio_out, 'tableau/stacked_case_ratio.csv', row.names = FALSE)
```


## % CHANGE

```{r}
new_pct_change = function(level, dat, region){
  # creates the % difference in cases and tests and smooth line with CIs 
  # level: either "TSA", "County", or "Metro". Note that "county" won't work for many counties unless have enough cases.
  # dat: dataset (e.g. "county", "metro", "tsa")
  # region: the region within the dataset (county, metro region, or tsa)

  if(level != 'State') {dat = dat %>% filter(!!as.name(level) == region)}

  # restrict data to first test date (for % test increase)
  start_date = as.Date("2020-09-30")
  dat = dat %>% filter(Date >= start_date) 
  start_values = dat %>% filter(Date == start_date)
  
  dat$ma_cases_y = 100*(as.vector(dat$Cases_MA_14 / start_values$Cases_MA_14) - 1)
  dat$total_cases_y = 100*(as.vector(dat$Cases_Total_14 / start_values$Cases_Total_14) - 1)
  dat$ma_tests_y = 100*(as.vector(dat$Tests_MA_14 / start_values$Tests_MA_14) - 1)
  dat$total_tests_y = 100*(as.vector(dat$Tests_Total_14 / start_values$Tests_Total_14) - 1)
   
  tmp.df = data.frame(Level = region,
                      Date = dat$Date,
                      cases_ma = dat$Cases_MA_14,
                      cases_total_14 = dat$Cases_Total_14,
                      tests_ma = dat$Tests_MA_14,
                      tests_total_14 = dat$Tests_Total_14,
                      cases_ma_percentdiff = dat$ma_cases_y,
                      cases_total_percentdiff = dat$total_cases_y,
                      tests_ma_percentdiff = dat$ma_tests_y,
                      tests_total_percentdiff = dat$total_tests_y,
                      Level_Type = level)
  return(tmp.df)  
}
```

```{r}
TPR = read.csv('tableau/county_TPR.csv') %>% 
  mutate(Date = as.Date(Date)) %>% 
  dplyr::select(Date, County, Tests)


TPR_dates = list.files('original-sources/historical/cms_tpr/') %>% 
  gsub('TPR_', '', .) %>% 
  gsub('.csv', '', .) %>% 
  as.Date(.)


TPR_merge = county %>% 
  dplyr::select(-Tests_Daily, -Population_DSHS) %>%
  left_join(TPR, by = c('Date', 'County')) %>%
  group_by(County) %>% 
  mutate(Cases_Total_14 = rollsum(Cases_Daily_Imputed, k=14, na.pad=TRUE, align='right')) %>% 
  mutate(Cases_MA_14 = rollmean(Cases_Daily_Imputed, k=14, na.pad=TRUE, align='right')) %>% 
  mutate(Tests_MA_14 = Tests / 14) %>% 
  ungroup() %>%
  dplyr::select(-Cases_Daily_Imputed) %>% 
  rename(Tests_Total_14 = Tests) %>% 
  filter(!is.na(TSA))


TPR_county = TPR_merge %>% dplyr::select(-c(TSA, PHR, Metro))
TPR_TSA = TPR_merge %>% group_by(Date, TSA) %>% summarize_if(is.numeric, sum, na.rm = TRUE)
TPR_PHR = TPR_merge %>% group_by(Date, PHR) %>% summarize_if(is.numeric, sum, na.rm = TRUE)
TPR_Metro = TPR_merge %>% group_by(Date, Metro) %>% summarize_if(is.numeric, sum, na.rm = TRUE)
TPR_State = TPR_merge %>% group_by(Date) %>% summarize_if(is.numeric, sum, na.rm = TRUE)
```


### Calculations

```{r}
PCT_County_df = rbindlist(lapply(unique(TPR_county$County), function(x) new_pct_change('County', TPR_county, x)))

PCT_TSA_df = rbindlist(lapply(unique(TPR_TSA$TSA), function(x) new_pct_change('TSA', TPR_TSA, x))) %>%
  mutate(tests_ma_percentdiff = ifelse(Date > min(Date) & tests_ma_percentdiff == -100, NA, tests_ma_percentdiff)) %>% 
  mutate(tests_total_percentdiff = ifelse(Date > min(Date) & tests_total_percentdiff == -100, NA, tests_total_percentdiff))

PCT_PHR_df = rbindlist(lapply(unique(TPR_PHR$PHR), function(x) new_pct_change('PHR', TPR_PHR, x))) %>%
  mutate(tests_ma_percentdiff = ifelse(Date > min(Date) & tests_ma_percentdiff == -100, NA, tests_ma_percentdiff)) %>% 
  mutate(tests_total_percentdiff = ifelse(Date > min(Date) & tests_total_percentdiff == -100, NA, tests_total_percentdiff))


PCT_Metro_df = rbindlist(lapply(unique(TPR_Metro$Metro), function(x) new_pct_change('Metro', TPR_Metro, x))) %>%
  mutate(tests_ma_percentdiff = ifelse(Date > min(Date) & tests_ma_percentdiff == -100, NA, tests_ma_percentdiff)) %>% 
  mutate(tests_total_percentdiff = ifelse(Date > min(Date) & tests_total_percentdiff == -100, NA, tests_total_percentdiff))


PCT_State_df = new_pct_change('State', TPR_State, 'Texas') %>%
  mutate(tests_ma_percentdiff = ifelse(Date > min(Date) & tests_ma_percentdiff == -100, NA, tests_ma_percentdiff)) %>% 
  mutate(tests_total_percentdiff = ifelse(Date > min(Date) & tests_total_percentdiff == -100, NA, tests_total_percentdiff))
```

### grouping

```{r}
PCT_Combined_df = rbind(PCT_County_df, PCT_TSA_df, PCT_PHR_df, PCT_Metro_df, PCT_State_df)

write.csv(PCT_Combined_df, 'tableau/stacked_pct_change_new.csv', row.names = FALSE)
```


<!-- ## % CHANGE (old) -->

<!-- ```{r} -->
<!-- old_pct_change = function(level, dat, region){ -->
<!--   # creates the % difference in cases and tests and smooth line with CIs  -->
<!--   # level: either "TSA", "County", or "Metro". Note that "county" won't work for many counties unless have enough cases. -->
<!--   # dat: dataset (e.g. "county", "metro", "tsa") -->
<!--   # region: the region within the dataset (county, metro region, or tsa) -->
<!--   if(level != 'State') {dat = dat %>% filter(!!as.name(level) == region)} -->
<!--   # restrict data to first test date (for % test increase) -->
<!--   first.test.date = as.Date("2020-04-22") -->
<!--   dat$Date = as.Date(dat$Date) -->
<!--   dat$Date2 = as.numeric(dat$Date) -->

<!--   # get 14 day rolling avg for instances where initial cases or tests are 0 -->
<!--   dat$cases_avg14 = rollmean(dat$Cases_Daily_Imputed, k=14, fill = NA, align = 'right', na.rm = TRUE) -->
<!--   dat$tests_avg14 = rollmean(dat$Tests_Daily, k=14, fill = NA, align = 'right', na.rm = TRUE) -->

<!--   # restrict new df to first.test.date forward   -->
<!--   slopedata.tests = data.frame(subset(dat, select=c(Date, Date2, Cases_Daily_Imputed, -->
<!--                                                      Tests_Daily, cases_avg14, tests_avg14))) %>% -->
<!--     subset(Date >= first.test.date) -->

<!--   tests_start = as.numeric(subset(slopedata.tests, Date==first.test.date, select=Tests_Daily)) -->
<!--   cases_start = as.numeric(subset(slopedata.tests, Date==first.test.date, select=Cases_Daily_Imputed)) -->

<!--   # numeric date for gam                          -->
<!--   tmpdata = data.frame(Date2=slopedata.tests$Date2) -->
<!--   if (cases_start != 0 & tests_start != 0) { -->

<!--     # Calc splines if cases and tests will produce non Inf values -->
<!--     slopedata.tests$newtestsY = 100*(as.vector(slopedata.tests$Tests_Daily / tests_start) - 1) -->
<!--     slopedata.tests$newcasesY = 100*(as.vector(slopedata.tests$Cases_Daily_Imputed / cases_start) - 1) -->

<!--     # fit and predict w/ gam for spline vals -->
<!--     cases.gam = gam(newcasesY~s(Date2,bs="cs", k=5), data=slopedata.tests) -->
<!--     tests.gam = gam(newtestsY~s(Date2,bs="cs",k=5), data=slopedata.tests) -->

<!--     cases.fit = predict(cases.gam, tmpdata, se.fit=TRUE) -->
<!--     tests.fit = predict(tests.gam, tmpdata, se.fit=TRUE) -->

<!--     # Use 95% CI for splines -->
<!--     tmp.df = data.frame(Level = region, -->
<!--                         Date = slopedata.tests$Date, -->
<!--                         Data_Type = 'Raw', -->
<!--                         cases_percentdiff = slopedata.tests$newcasesY, -->
<!--                         tests_percentdiff = slopedata.tests$newtestsY, -->
<!--                         cases_percentdiff_spline = cases.fit$fit,  -->
<!--                         cases_percentdiff_spline_lower = cases.fit$fit-1.96*cases.fit$se,  -->
<!--                         cases_percentdiff_spline_upper = cases.fit$fit+1.96*cases.fit$se, -->
<!--                         tests_percentdiff_spline = tests.fit$fit, -->
<!--                         tests_percentdiff_spline_lower = tests.fit$fit-1.96*tests.fit$se, -->
<!--                         tests_percentdiff_spline_upper = tests.fit$fit+1.96*tests.fit$se, -->
<!--                         Level_Type = level) -->
<!--   } else { -->
<!--     # only calc % increase for regions w/ sparse cases -->
<!--     cases_avg_start = as.numeric(subset(slopedata.tests, Date==first.test.date, select=cases_avg14)) -->
<!--     tests_avg_start = as.numeric(subset(slopedata.tests, Date==first.test.date, select=tests_avg14)) -->
<!--     slopedata.tests$newcasesY = 100*(as.vector(slopedata.tests$cases_avg14 / cases_avg_start) - 1) -->
<!--     slopedata.tests$newtestsY = 100*(as.vector(slopedata.tests$tests_avg14 / tests_avg_start) - 1) -->

<!--     tmp.df = data.frame(Level = region, -->
<!--                         Date = slopedata.tests$Date, -->
<!--                         Data_Type = '14-Day Average', -->
<!--                         cases_percentdiff = slopedata.tests$newcasesY, -->
<!--                         tests_percentdiff = slopedata.tests$newtestsY, -->
<!--                         cases_percentdiff_spline = rep(NA, times = nrow(slopedata.tests)), -->
<!--                         cases_percentdiff_spline_lower = rep(NA, times = nrow(slopedata.tests)), -->
<!--                         cases_percentdiff_spline_upper = rep(NA, times = nrow(slopedata.tests)), -->
<!--                         tests_percentdiff_spline = rep(NA, times = nrow(slopedata.tests)), -->
<!--                         tests_percentdiff_spline_lower = rep(NA, times = nrow(slopedata.tests)), -->
<!--                         tests_percentdiff_spline_upper = rep(NA, times = nrow(slopedata.tests)), -->
<!--                         Level_Type = level)   -->
<!--     } -->

<!--   return(tmp.df)   -->
<!-- } -->
<!-- ``` -->

<!-- ### Calculations -->

<!-- ```{r} -->
<!-- PCT_County_df = rbindlist(lapply(unique(County_df$County), function(x) old_pct_change('County', County_df, x))) -->
<!-- PCT_TSA_df = rbindlist(lapply(unique(TSA_df$TSA), function(x) old_pct_change('TSA', TSA_df, x))) -->
<!-- PCT_PHR_df = rbindlist(lapply(unique(PHR_df$PHR), function(x) old_pct_change('PHR', PHR_df, x))) -->
<!-- PCT_Metro_df = rbindlist(lapply(unique(Metro_df$Metro), function(x) old_pct_change('Metro', Metro_df, x))) -->
<!-- PCT_State_df = old_pct_change('State', State_df, 'Texas') -->
<!-- ``` -->

<!-- ### grouping -->

<!-- ```{r} -->
<!-- PCT_Combined_df = rbind(PCT_County_df, PCT_TSA_df, PCT_PHR_df, PCT_Metro_df, PCT_State_df) -->
<!-- write.csv(PCT_Combined_df, 'tableau/stacked_pct_change.csv', row.names = FALSE) -->
<!-- ``` -->

# STACK COMBINATIONS

```{r}
Ratio_Combined_df$Date = max(PCT_Combined_df$Date)
colnames(ARIMA_Case_Combined_df)[5:6] = c('TS_CI_Lower', 'TS_CI_Upper')
colnames(RT_Combined_df)[4:5] = c('RT_CI_Lower', 'RT_CI_Upper')
colnames(ARIMA_Hosp_Combined_df)[4:5] = c('TS_Hosp_CI_Lower', 'TS_Hosp_CI_Upper')

stacked_all = Reduce(function(x, y) merge(x, y, by = c('Level_Type', 'Level', 'Date'), all=TRUE),
       list(PCT_Combined_df, Ratio_Combined_df, 
            ARIMA_Case_Combined_df, RT_Combined_df, ARIMA_Hosp_Combined_df))

write.csv(stacked_all, 'tableau/stacked_critical_trends.csv', row.names = FALSE)
```

# PERFORMANCE REVIEW

```{r, fig.width=12, fig.height=6}
# time_flat = unlist(all_times)
# print(time_flat)
# names(time_flat) = NULL
# 
# time_df = data.frame('time_sec' = time_flat) %>%
#   mutate(chunk = as.numeric(rownames(.)) + 2) %>%
#   mutate(version = refactor_version) %>%
#   mutate(script = 'covid-scraping.rmd') %>%
#   arrange(desc(time_sec))
# 
# ggplot(time_df, aes(y = time_sec, x = chunk, fill = time_sec)) +
#   geom_bar(stat = 'identity') +
#   geom_text(aes(label = chunk), position=position_dodge(width = 0.9), vjust = -0.25) +
#   labs(x = 'chunk #', y = 'runtime (seconds)') +
#   scale_fill_gradient(low = 'gray80', high = 'tomato1') +
#   theme_pubr() +
#   theme(axis.text.x = element_blank(),
#         legend.position = 'none')
```

## total run time

```{r}
# time_df %>% summarize(sum(time_sec))
```

```{r}
# write.csv(time_df, paste0('diagnostics/stats_runtime_', refactor_version, '.csv'),
#           row.names = FALSE)
```
