---
title: "diagnostics"
author: "Jeffrey Brennan"
output: html_document
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  knit_root_dir = "C:/Users/jeffb/Desktop/Life/personal-projects/COVID",
  output_dir = "diagnostics/")})
---

# SETUP
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(time_it = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

```{r, include=FALSE}
library(tidyverse)
library(data.table)
library(ggpubr)

select = dplyr::select
filter = dplyr::filter
```


```{r}
wastewater = fread('tableau/wastewater_zip.csv')
head(wastewater)

wastewater$ZIPCODE %>% unique() %>% length()

```

```{r}
Add_Emoji = function(long_df) { 
  output = long_df %>% 
    mutate(Emoji = case_when(Text == 'Date' & Statistic < date_out ~ ':warning:',
                             Text == 'Date' & Statistic == date_out ~ ':heavy_check_mark:',
                             Text != 'Date' & (Statistic < 0 | is.na(Statistic)) ~ ':warning:',
                             Text != 'Date' & (Statistic < 0 | is.na(Statistic)) ~ ':heavy_check_mark:',
                             TRUE ~ ':warning:')
          )
  return(output)
}

# Requires df in Date, County|TSA|State/NA|Stat format
# takes dynamic vector of desired columns
# group_text used for stacked dataframes
Calc_Stats = function(df, stat_vec, url=NA, group_text=NA, ts = FALSE) {
  level = case_when('County' %in% names(df) ~ 'County',
                    'TSA' %in% names(df) ~ 'TSA',
                    TRUE ~ 'State')

  latest_date = df %>%
    mutate(Date = as.Date(Date)) %>%
    filter(across(any_of("Group_Type"), ~.== group_text)) %>%
    mutate(across(stat_vec, ~(. > 0) & !is.na(.), .names = '{col}_check')) %>% 
    mutate(nonzero = any(nrow(.)-length(stat_vec):nrow(.))) %>%
    group_by(Date) %>%
    mutate(keep_date = sum(nonzero) / length(nonzero) > 0) %>%
    filter(keep_date) %>% 
    ungroup() %>%
    summarize(Date = max(Date, na.rm = TRUE)) %>%
    pull(Date)
  
  avg_df = df %>% 
    mutate(Date = as.Date(Date)) %>% 
    arrange(Date) %>%
    filter(Date <= latest_date) %>%
    filter(across(any_of("Group_Type"), ~.== group_text)) %>%
    group_by(Date) %>%
    select(any_of(c('Date', stat_vec))) %>%
    summarize_all(mean)
  
  if (ts == TRUE) {
    results = avg_df %>%
      mutate(across(stat_vec, ~(. - lag(.)), .names = '{col}_lag')) %>%
      filter(Date == latest_date) %>% 
      select(Date, contains('lag')) %>% 
      mutate(Level = level) %>% 
      mutate(across(is.numeric, ~round(., 4))) %>%
      mutate(across(everything(), as.character)) %>%
      pivot_longer(!c(Level)) %>% 
      rename(Text = name, Statistic = value) %>% 
      mutate(Text = str_replace_all(Text, '_', ' ')) %>%
      group_by(row_number()) %>%
      mutate(Sublevel = ifelse(is.na(group_text),
                           Text,
                           group_text)) %>%
      mutate(Sublevel = str_squish(Sublevel)) %>%
      ungroup() %>%
      Add_Emoji() %>% 
      select(-`row_number()`) %>% 
      mutate(URL = url)
  } else { 
    
    results = avg_df %>%
      select(Date, stat_vec) %>% 
      mutate(Level = level) %>% 
      mutate(across(is.numeric, ~round(., 4))) %>%
      mutate(across(everything(), as.character)) %>%
      pivot_longer(!c(Level)) %>% 
      rename(Text = name, Statistic = value) %>% 
      mutate(Text = str_replace_all(Text, '_', ' ')) %>%
      group_by(row_number()) %>%
      mutate(Sublevel = ifelse(is.na(group_text),
                           Text,
                           group_text)) %>%
      mutate(Sublevel = str_squish(Sublevel)) %>%
      ungroup() %>%
      Add_Emoji() %>% 
      select(-`row_number()`) %>% 
      mutate(URL = url)
    }
  return(results)
}
```



# VALIDATION

Builds validation text to be read by slack and outputted by slackbot


```{r}
date_out = ifelse((Sys.time() < as.POSIXct(paste0(Sys.Date(), '16:00'), tz = 'America/Chicago')),
                   Sys.Date() - as.difftime(1, units = 'days'),
                   Sys.Date()) %>% 
  as.Date(origin = '1970-01-01') %>%
  format('%Y-%m-%d')
```



## Vaccination

Updated: 

- County level Vaccination counts, vaccination rate
- State level breakdown by age, race, gender


```{r}
county_vaccine = fread('tableau/sandbox/county_daily_vaccine.csv')
results_county_vax = Calc_Stats(county_vaccine,
                                stat_vec = c('Doses_Administered', 'At_Least_One_Dose'),
                                url = 'https://www.dshs.texas.gov/immunize/covid19/COVID-19-Vaccine-Data-by-County.xls',
                                ts = TRUE
                                )

vaccine_state = fread('tableau/sandbox/state_vaccine_demographics.csv')
results_state_vax = Calc_Stats(vaccine_state,
                               stat_vec = c('Doses_Administered', 'At_Least_One_Vaccinated'),
                               url = 'https://www.dshs.texas.gov/immunize/covid19/COVID-19-Vaccine-Data-by-County.xls',
                               ts = FALSE
                              )
```


## Hot Spots (TPR, Cases/100k)

```{r}
county_tpr = fread('tableau/county_tpr.csv')
# TODO: check/finalize URL
# last updated 3/1 - prob need to backfill
results_county_tpr = Calc_Stats(
  df = county_tpr,
  stat_vec = c('TPR'),
  url = '',
  ts = TRUE
)


county_cases = fread('tableau/county.csv')

```


## Hot Spots (Case Ratio)

```{r}

```


## Cases & Fatalities

```{r}

```



## Critical Trends

```{r}

```


## Hospitalization

```{r}

```



## Mobility

```{r}

```


## Demographics


```{r}

```


## setup
```{r}
county = fread('tableau/county.csv')
tsa = fread('tableau/hospitalizations_tsa.csv')
state_demo_df = fread('tableau/stacked_demographics.csv')


data_urls = c('<https://tabexternal.dshs.texas.gov/t/THD/views/COVIDExternalQC/COVIDTrends?:isGuestRedirectFromVizportal=y&:embed=y|CASES>',
              '<https://dshs.texas.gov/coronavirus/TexasCOVID19DailyCountyFatalityCountData.xlsx|DEATHS>',
              '<https://dshs.texas.gov/coronavirus/TexasCOVID-19CumulativeTestsbyCounty.xlsx|TESTS>',
              '<https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv|GOOGLE MOBILITY>',
              '<https://dshs.texas.gov/coronavirus/TexasCOVID-19HospitalizationsOverTimebyTSA.xlsx|TOTAL HOSPITALIZATIONS>',
              '<https://dshs.texas.gov/coronavirus/TexasCOVID-19HospitalizationsOverTimebyTSA.xlsx|ICU HOSPITALIZATIONS>',
              '<https://dshs.texas.gov/coronavirus/TexasHospitalCapacityoverTimebyTSA.xlsx|TOTAL CAPACITY>',
              '<https://dshs.texas.gov/coronavirus/TexasHospitalCapacityoverTimebyTSA.xlsx|ICU CAPACITY>',
              # '<https://apps.hhs.texas.gov/providers/directories/Texas_Nursing_Facilities_COVID_Summary.xls|NURSING FACILITIES>',
              # '<https://apps.hhs.texas.gov/providers/directories/Texas_Assisted_Living_Facilities_COVID_Summary.xls|ALF>',
              '<https://dshs.texas.gov/coronavirus/TexasCOVID19CaseCountData.xlsx|AGE>',
              '<https://dshs.texas.gov/coronavirus/TexasCOVID19CaseCountData.xlsx|GENDER>',
              '<https://dshs.texas.gov/coronavirus/TexasCOVID19CaseCountData.xlsx|RACE>')

calc_count_stats = function(daily_stat, df) { 
  
  # TODO: refactor to combine with demo component
  # get most recent data date where > 0 counties, TSAs etc report a valid value
  # some stats have missing values for smaller regions (including google mobility and lagged cases)
  latest_date = df %>%
    mutate(Date = as.Date(Date)) %>%
    group_by(Date) %>%
    mutate(nonzeros = !!as.name(daily_stat) > 0 & !is.na(!!as.name(daily_stat))) %>% 
    filter(sum(nonzeros) / length(nonzeros) > 0) %>%
    ungroup() %>%
    summarize(max(Date)) %>% 
    unlist() %>% 
    as.Date(origin = '1970-01-01')

  df = df %>%
    mutate(Date = as.Date(Date)) %>% 
    filter(Date <= latest_date)
  
  avg_df = df %>% 
    group_by(Date) %>% 
    summarize(Daily_Avg = mean(!!as.name(daily_stat), na.rm = TRUE)) %>%
    mutate(lag = Daily_Avg - lag(Daily_Avg))

  nonzeros = df %>%
    filter(Date == max(as.Date(df$Date))) %>% 
    summarize(!!as.name(daily_stat) > 0 & !is.na(!!as.name(daily_stat))) %>%
    unlist()
  
  stats = list(max(df[['Date']]),
               round(avg_df[['Daily_Avg']][nrow(avg_df)], 2),
               round(avg_df[['lag']][[nrow(avg_df)]], 2),
               round(sum(nonzeros) / length(nonzeros), 2) * 100)
  
  emojis = c(ifelse(stats[[1]] < date_out, ':warning:', ':heavy_check_mark:'),
             ifelse(stats[[2]] <= 0 | is.na(stats[2]), ':warning:', ':heavy_check_mark:'),
             ifelse(stats[[3]] <= 0 | is.na(stats[3]), ':warning:', ':heavy_check_mark:'),
             ifelse(stats[[4]] < 50 | is.na(stats[4]), ':warning:', ':heavy_check_mark:'))

  stats[[1]] = format(stats[[1]], '%Y-%m-%d')

  
  return(list(unlist(stats), emojis))
}




calc_demo_stats = function(group_text, df) {
  level = case_when('County' %in% names(df) ~ 'County',
                    'TSA' %in% names(df) ~ 'TSA',
                    TRUE ~ 'State')

  latest_date = df %>%
    mutate(Date = as.Date(Date)) %>%
    filter(Group_Type == group_text) %>%
    mutate(nonzeros = (Cases_Daily > 0 & !is.na(Cases_Daily) | (Deaths_Daily > 0 & !is.na(Deaths_Daily)))) %>%
    group_by(Date) %>%
    mutate(keep_date = sum(nonzeros) / length(nonzeros) > 0) %>%
    filter(keep_date) %>% 
    ungroup() %>%
    summarize(date_out = max(Date, na.rm = TRUE)) %>%
    unlist() %>%
  
  df = df %>%
    mutate(Date = as.Date(Date)) %>% 
    filter(Date <= latest_date)

  results = df %>% 
    filter(Group_Type == group_text) %>%
    group_by(Date) %>%
    select(Cases_Daily, Deaths_Daily) %>%
    summarize_all(mean) %>%
    mutate(case_lag = Cases_Daily - lag(Cases_Daily)) %>%
    mutate(death_lag = Deaths_Daily - lag(Deaths_Daily)) %>%
    filter(Date == latest_date) %>% 
    select(Date, case_lag, death_lag) %>% 
    mutate(Level = level,
           Sublevel = group_text) %>%
    mutate(across(is.numeric, ~round(., 4))) %>%
    mutate(across(everything(), as.character)) %>%
    pivot_longer(!c(Level, Sublevel)) %>% 
    rename(Text = name, Statistic = value) %>% 
    Add_Emoji()
  
  return(results)
}
```


## compute stats
```{r}
county_check = lapply(c('Cases_Daily', 'Deaths_Daily', 'Tests_Daily', 'Residential'), 
                      calc_count_stats, df = county)

tsa_check = lapply(c('Hospitalizations_Total', 'Hospitalizations_ICU',
                     'Beds_Available_Total', 'Beds_Available_ICU'),
                   calc_count_stats, df = tsa)

state_check = map(c('Age', 'Gender', 'Race'), ~calc_demo_stats(., state_demo_df)) %>% 
  rbindlist(fill = TRUE)

# https://stackoverflow.com/questions/20428742/select-first-element-of-nested-list
stats_out = unlist(c(lapply(county_check, `[[`, 1),
                     lapply(tsa_check, `[[`, 1),
                     lapply(state_check, `[[`, 1)))

emojis_out = unlist(c(lapply(county_check, `[[`, 2),
                      lapply(tsa_check, `[[`, 2),
                      lapply(state_check, `[[`, 2)))
```

## organize stats
```{r}
# declare sublevels for use in creating validation df and renaming nested list output
# county_sublevels = c('Cases', 'Deaths', 'Tests', 'Mobility')
# tsa_sublevels = c('Hosp_Total', 'Hosp_ICU', 'Cap_Total', 'Cap_ICU')
# state_sublevels = c('Age', 'Gender', 'Race')


validation_df = data.frame(Level = c(rep('County', each = 16),
                                     rep('TSA', each = 16),
                                     rep('State', each = 9)),
                           Sublevel = c(rep(county_sublevels, each = 4),
                                        rep(tsa_sublevels, each = 4),
                                        rep(state_sublevels, each = 3)),
                           Emoji = emojis_out,
                           Text = c(rep(c('Latest date:', 'Average daily value:' ,
                                          'Average % change:', '% reporting > 0:'),
                                        times = 4 + 4),
                                rep(c('Latest Date', 'Average case change:', 'Average death change:'),
                                    times = 3)),
                       Statistic = stats_out) %>% 
  mutate_all(as.character)
```


## build slack text
```{r}
build_text = function(text_filters, data_url) { 
  # based on level and sublevel match, combined all despcriptive text and statistics into string separated by newlines ('\n')
  text_out = validation_df %>% 
    dplyr::filter(Level == text_filters[[1]] & Sublevel == text_filters[[2]]) %>%
    unite(combined, Emoji, Text, Statistic, sep = ' ') %>% 
    dplyr::select(combined) %>% 
    unlist() %>%
    paste0(collapse = '\n ')
    
  return(list(text = text_out, url = data_url))
}

# declare for combination into 'text_filters' list
level_text = c(rep('County', each = 4), rep('TSA', each = 4), rep('State', each = 3))
sublevel_text = c(unique(validation_df$Sublevel))

# obtain list of lists (~4 of 4)
validation_text = mapply(build_text, 
                         text_filters = mapply(list, level_text, sublevel_text, SIMPLIFY = FALSE),
                         data_urls,
                         SIMPLIFY = FALSE)
```

## final formatting

```{r}
library(jsonlite)
# convert to lists of list of lists (~3 of 4 of 4)
validation_out = list(County = validation_text[which(names(validation_text) == 'County')],
                      TSA = validation_text[which(names(validation_text) == 'TSA')],
                      State = validation_text[which(names(validation_text) == 'State')])

# rename repeated top level with correct sublevel for stat (mapply only supports list of lists natively)
names(validation_out$County) = county_sublevels
names(validation_out$TSA) = tsa_sublevels
names(validation_out$State) = state_sublevels

validation_json = toJSON(validation_out, auto_unbox = TRUE)
write(validation_json, file = 'diagnostics/validation.json')
```


# special requests

```{r, fig.height = 12, fig.width = 8}
# demo = read.csv('original-sources/census/county_demo.csv')
# 
# demo_summary = demo %>% 
#   filter(CTYNAME == 'Harris County' & YEAR == '11' & AGEGRP != 0) %>%
#   mutate(AGEGRP_TEST = ifelse((AGEGRP %% 2) != 0, AGEGRP + 1, AGEGRP)) %>%
#   group_by(AGEGRP_TEST) %>% 
#   mutate_at(vars(8:ncol(demo)), funs(sum)) %>% 
#   filter((AGEGRP %% 2) != 0) %>% 
#   mutate(AGEGRP = dplyr::recode(AGEGRP,  `1` = '0-9', `3` = '10-19', `5` = '20-29',
#                                 `7` = '30-39', `9` = '40-49', `11` = '50-59',
#                                 `13` = '60-69', `15` = '70-79', `17` = '80+')) %>%
#   gather('demographic', 'value', 9:ncol(demo)) %>% 
#   mutate(demo_group = gsub('\\_.*', '', demographic)) %>%
#   group_by(demo_group, AGEGRP) %>% 
#   summarize(total = sum(value)) %>% 
#   filter(demo_group %in% c('WA', 'BA', 'IA', 'AA', 'NA', 'NH', 'H')) %>% 
#   mutate(demo_group = recode(demo_group, 'WA' = 'White', 'BA' = 'Black',
#                              'IA' = 'American Indian & Alaska Native',
#                              'AA' = 'Asian', 'NA' = 'Native Hawaiian & Pacific Islander',
#                              'NH' = 'Not Hispanic', 'H' = 'Hispanic')) %>% 
#   mutate(pct = prop.table(total))
# 
# write.csv(demo_summary, 'harris_demographics.csv', row.names = F)
# 
# ggplot(demo_summary, aes(x = AGEGRP, y = total, fill = demo_group)) + 
#   geom_bar(stat = 'identity') +
#   labs(title = 'Age X Race - Harris County') + 
#   geom_text(aes(label = round(pct, 2))) + 
#   facet_wrap(~demo_group, ncol = 1, scales = 'free') + 
#   theme_pubr() + 
#   theme(legend.position = 'right')
# 
# 
# age_summary = demo %>%
#   filter(CTYNAME == 'Harris County' & YEAR == '11' & AGEGRP != 0) %>%
#   mutate(AGEGRP_TEST = ifelse((AGEGRP %% 2) != 0, AGEGRP + 1, AGEGRP)) %>%
#   group_by(AGEGRP_TEST) %>% 
#   mutate_at(vars(8:ncol(demo)), funs(sum)) %>% 
#   filter((AGEGRP %% 2) != 0) %>% 
#   mutate(AGEGRP = dplyr::recode(AGEGRP,  `1` = '0-9', `3` = '10-19', `5` = '20-29',
#                                 `7` = '30-39', `9` = '40-49', `11` = '50-59',
#                                 `13` = '60-69', `15` = '70-79', `17` = '80+')) %>% 
#   dplyr::select(c(AGEGRP, TOT_POP))
```

```{r}
# county = read.csv('combined-datasets/county.csv') 
# Q_df = county %>%
#   mutate(Date = as.Date(Date)) %>%
#   dplyr::filter(Date == max(Date)) %>%
#   dplyr::filter(TSA == 'Q') %>%
#   dplyr::select(County, Population_DSHS, TSA) %>% 
#   arrange(desc(Population_DSHS)) %>% 
#   mutate(Q_POP = sum(Population_DSHS))
#  
#  Q_pop = Q_df$Q_POP[1]
#  
# TMC_df = county %>%
#   mutate(Date = as.Date(Date)) %>% 
#   dplyr::filter(Date == max(Date)) %>%
#   dplyr::filter(County %in% c('Austin', 'Brazoria', 'Chambers', 'Fort Bend',
#                               'Galveston', 'Harris', 'Liberty', 'Montgomery', 'Waller')) %>%
#   dplyr::select(County, Population_DSHS, TSA, Cases_Daily, Date) %>% 
#   arrange(desc(Population_DSHS)) %>% 
#   mutate(TMC_POP = sum(Population_DSHS))
# 
# TMC_pop = TMC_df$TMC_POP[1]
# 
# 
# # ICU hospitalizations from TSA Q (8/31)
# hosp_tsa = read.csv('combined-datasets/tsa.csv')
# Q_ICU = hosp_tsa %>%
#   mutate(Date = as.Date(Date)) %>%
#   dplyr::filter(Date == max(Date) & TSA == 'Q') %>%
#   dplyr::select(Hospitalizations_ICU) %>% unlist()
# 
# # TMC dashboard value - 9/20
# TMC_ICU = 154
# 
# # proposed TMC reporting and ICU share of surrounding 9 counties
# TMC_coverage = 0.75
# 
# # 1.1 - Surrounding 9 county area has larger population than TSA Q
# TMC_Q_ratio = round(TMC_pop / Q_pop, 2)
# 
# # expected TSA Q hosp assuming above values are accurate
# Q_expected = (TMC_ICU / TMC_coverage) / TMC_Q_ratio
# Q_expected
# # actual
# Q_ICU
# 
# # actual TMC_coverage
# round(TMC_ICU / Q_ICU, 2) 
# 
# # expected / actual
# Q_expected / Q_ICU
```

<!-- ```{r} -->
<!-- county = read.csv('tableau/county.csv')  -->
<!-- county %>%  -->
<!--   filter(County %in% c('Austin', 'Brazoria', 'Chambers', 'Fort Bend', -->
<!--                               'Galveston', 'Harris', 'Liberty', 'Montgomery', 'Waller')) %>%  -->
<!--   group_by(Date) %>%  -->
<!--   summarize(sum(Cases_Daily)) %>%  -->
<!--   tail(14) -->

<!-- recent_tmc_cases = county %>%  -->
<!--   filter(County %in% c('Austin', 'Brazoria', 'Chambers', 'Fort Bend', -->
<!--                        'Galveston', 'Harris', 'Liberty', 'Montgomery', 'Waller')) %>%  -->
<!--   filter(as.Date(Date) >= max(as.Date(Date)) - 2) %>%  -->
<!--   group_by(Date, County) %>% -->
<!--   summarize(Cases_Daily) -->
<!-- ``` -->


<!-- # Regional comparisons -->

<!-- ```{r} -->
<!-- # northeast -->
<!-- northeast = county %>%  -->
<!--   filter(County %in% c('Rains', 'Wood', 'Van Zandt', 'Smith', 'Gregg', 'Henderson', 'Anderson')) %>% -->
<!--   # filter(as.Date(Date) >= Sys.Date()-7) %>% -->
<!--   dplyr::select(Date, County, Cases_Cumulative, Cases_Daily) %>%  -->
<!--   arrange(County, Date) -->

<!-- write.csv(northeast, 'diagnostics/northeast.csv', row.names = F) -->

<!-- # south -->
<!-- county %>%  -->
<!--   filter(County %in% c('Cameron')) %>% -->
<!--   filter(as.Date(Date) >= Sys.Date()-7) %>% -->
<!--   dplyr::select(Date, County, Cases_Cumulative, Cases_Daily) %>%  -->
<!--   arrange(County, Date) -->
<!-- ``` -->

<!-- # School districts -->

<!-- ```{r} -->
<!-- schools = readxl::read_xlsx('tableau/district_school_reopening.xlsx', sheet = 1) -->

<!-- weekly = schools %>%  -->
<!--   mutate(Total_Enrollment = as.numeric(Total_Enrollment), -->
<!--          Weekly_Cases = (Cases_Weekly_GRADE_EE_3 + Cases_Weekly_GRADE_4_6 + Cases_Weekly_GRADE_7_12), -->
<!--          Weekly_total_Ratio = Weekly_Cases / Total_Enrollment, -->
<!--          Weekly_Approx_Ratio = Weekly_Cases / Approximate_Enrollment) -->

<!-- weekly %>% filter(Weekly_total_Ratio > 1 | Weekly_Approx_Ratio > 1) -->

<!-- summary(weekly$Weekly_total_Ratio) -->
<!-- summary(weekly$Weekly_Approx_Ratio) -->


<!-- cumulative = schools %>%  -->
<!--   filter(Date == max(as.Date(Date))) %>%  -->
<!--   mutate(Total_Enrollment = as.numeric(Total_Enrollment), -->
<!--          Cumulative_Cases = (Cases_Cumulative_GRADE_EE_3 + Cases_Cumulative_GRADE_4_6 + Cases_Cumulative_GRADE_7_12), -->
<!--          Cumulative_total_Ratio = Cumulative_Cases / Total_Enrollment, -->
<!--          Cumulative_Approx_Ratio = Cumulative_Cases / Approximate_Enrollment) -->

<!-- cumulative %>% filter(Cumulative_total_Ratio > 1 | Cumulative_Approx_Ratio > 1) -->

<!-- summary(cumulative$Cumulative_total_Ratio) -->
<!-- summary(cumulative$Cumulative_Approx_Ratio) -->


<!-- # schools %>%  -->
<!-- #   filter(District == 'Houston ISD') %>%  -->
<!-- #   dplyr::select(Total_Enrollment, Cases_Cumulative_GRADE_4_6, Cases_Cumulative_GRADE_EE_3, Cases_Cumulative_GRADE_7_12, Cases_Cumulative_Staff) -->
<!-- ``` -->


<!-- # TSA Hosp check -->

<!-- ```{r} -->
<!-- hosp = read.csv('tableau/hospitalizations_tsa.csv') -->

<!-- test = hosp %>%  -->
<!--   mutate(Date = as.Date(Date)) %>% -->
<!--   group_by(TSA, Date) %>% -->
<!--   summarize(pct_cap = Beds_Occupied_ICU / (Beds_Occupied_ICU + Beds_Available_ICU)) -->

<!-- ggplot(test, aes(x=Date, y = pct_cap, group=TSA)) +  -->
<!--   geom_point() +  -->
<!--   scale_x_date(breaks = '1 month', date_labels = '%b') +  -->
<!--   facet_wrap(~TSA, scales = 'free') +  -->
<!--   theme(axis.text.x = element_text(angle = -45)) -->
<!-- ``` -->


# TPR comparison

```{r}
# tpr = read.csv('original-sources/historical/TPR/TPR_2020-10-07.csv')
# 
# county_tpr = county %>% 
#   group_by(County) %>%
#   mutate(Cases_Cumulative_daily = as.numeric(c(Cases_Cumulative[1], diff(Cases_Cumulative)))) %>%
#   filter(Date >= as.Date('2020-09-24') & Date <= as.Date('2020-10-07')) %>% 
#   select(County, TSA_Name, Tests_Daily, Cases_Cumulative, Cases_Cumulative_daily, Cases_Daily) %>% 
#   group_by(County, TSA_Name) %>% 
#   summarize(TPR_new_cases = sum(Cases_Daily, na.rm=T) / sum(Tests_Daily, na.rm=T),
#             TPR_cumulative_cases = sum(Cases_Cumulative_daily, na.rm=T) / sum(Tests_Daily, na.rm=T)) %>% 
#   merge(., tpr, by = 'County') %>%
#   mutate(TPR_new_ratio = TPR_new_cases / TPR_CMS,
#          TPR_cumulative_ratio = TPR_cumulative_cases / TPR_CMS) %>%
#   dplyr::select(1,2,8,9) %>%
#   mutate(County_Group = cut(as.numeric(rownames(.)), 6)) %>% 
#   reshape2::melt(c('County', 'County_Group', 'TSA_Name')) %>%
#   na.omit()
# 
# ggplot(county_tpr, aes(x = County, y = value, color = variable)) + 
#   geom_point(alpha=0.3, size = 4) + 
#   geom_hline(yintercept = 1, color = 'black', linetype = 'dashed') +
#   scale_color_manual(values = c('red', 'black')) + 
#   # facet_wrap(~ TSA_Name, scales = 'free') +
#   theme_pubr() + 
#   facet_wrap(~ County_Group, nrow=2, scales = 'free_x') + 
#   theme(axis.text.y = element_text(size = 12),
#         axis.text.x = element_text(size = 12, angle = -45, hjust = 0),
#         strip.background = element_blank(),
#         strip.text.x = element_blank())
# 
# ggsave('diagnostics/TPR.png', dpi=800, width = 15, height = 10)
# 
# county_tpr %>% 
#   filter(variable == 'TPR_new_ratio') %>% 
#   select(value) %>%
#   unlist() %>%
#   fivenum() %>% 
#   round(3)
# 
# county_tpr %>% 
#   filter(variable == 'TPR_cumulative_ratio') %>% 
#   select(value) %>% 
#   unlist() %>% 
#   fivenum() %>% 
#   round(3)
```

<!-- # New PCT Calcs -->

<!-- ```{r} -->
<!-- pct_df = read.csv("tableau/stacked_pct_change_new.csv") -->
<!-- pct_tsa = pct_df %>% -->
<!--   dplyr::select(Level, Level_Type, Date, cases_total_14, tests_total_14, -->
<!--                 cases_total_percentdiff, tests_total_percentdiff) %>%  -->
<!--   filter(Level_Type == 'TSA') %>% -->
<!--   mutate(Date = as.Date(Date)) -->



<!-- ggplot(pct_tsa, aes(group = Level)) +  -->
<!--   geom_point(aes(x = Date, y = cases_total_percentdiff, color = 'Cases % Difference (14 Day Total)'), size = 2) +  -->
<!--   geom_line(aes(x = Date, y = cases_total_percentdiff, color = 'Cases % Difference (14 Day Total)'), size = 1) +  -->
<!--   geom_point(aes(x = Date, y = tests_total_percentdiff, color = 'Tests % Difference (14 Day Total)'), size = 2) + -->
<!--   geom_line(aes(x = Date, y = tests_total_percentdiff, color = 'Tests % Difference (14 Day Total)'), size = 1) + -->
<!--   facet_wrap(~Level) + -->
<!--   scale_x_date(date_labels = '%m/%d', breaks = seq(as.Date('2020-09-30'), max(pct_tsa$Date), by = '1 week')) + -->
<!--   labs(y = '% Difference from Baseline (9/30)') + -->
<!--   theme_pubr() +  -->
<!--   theme(axis.text.x = element_text(size = 10, angle = -45)) -->

<!-- # ggplot(pct_tsa, aes(group = Level)) +  -->
<!-- #   geom_point(aes(x = Date, y = cases_ma_percentdiff, color = 'Cases % Difference (14 Day MA)'), size = 2) +  -->
<!-- #   geom_line(aes(x = Date, y = cases_ma_percentdiff, color = 'Cases % Difference (14 Day MA)'), size = 1) +  -->
<!-- #   geom_point(aes(x = Date, y = tests_ma_percentdiff, color = 'Tests % Difference (14 Day MA)'), size = 2) + -->
<!-- #   geom_line(aes(x = Date, y = tests_ma_percentdiff, color = 'Tests % Difference (14 Day MA)'), size = 1) + -->
<!-- #   facet_wrap(~Level, scales = 'free_y') + -->
<!-- #   scale_x_date(date_labels = '%m/%d') + -->
<!-- #   theme_pubr() +  -->
<!-- #   labs(y = '% Difference from Baseline (9/30)') + -->
<!-- #   theme(axis.text.x = element_text(angle = -90)) -->
<!-- ``` -->


<!-- # TSA TPR -->

<!-- ```{r} -->
<!-- county_link = county %>% dplyr::select(County, TSA) %>% distinct() -->

<!-- tpr_tsa = read.csv('tableau/county_TPR.csv') %>%  -->
<!--   left_join(., county_link, by = 'County') %>%  -->
<!--   group_by(Date, TSA) %>% -->
<!--   summarize(TPR = mean(TPR_CMS, na.rm = TRUE)) %>%  -->
<!--   mutate(Date = as.Date(Date)) -->

<!-- el_paso = read.csv('tableau/county_TPR.csv') %>%  -->
<!--   left_join(., county_link, by = 'County') %>%  -->
<!--   filter(TSA == 'I - El Paso') -->

<!-- ggplot(tpr_tsa, aes(x = Date, y = TPR, group = TSA)) +  -->
<!--   geom_point(size = 2) +  -->
<!--   geom_line(size = 1) + -->
<!--   facet_wrap(~ TSA) +  -->
<!--   scale_x_date(date_labels = '%m/%d') + -->
<!--   theme_pubr() +  -->
<!--   theme(axis.text.x = element_text(angle = -90)) -->

<!-- ``` -->


<!-- # Performance review -->

<!-- ```{r, fig.width=12, fig.height=6} -->
<!-- time_flat = unlist(all_times) -->
<!-- print(time_flat) -->

<!-- names(time_flat) = NULL -->

<!-- time_df = data.frame('time_sec' = time_flat) %>% -->
<!--   mutate(chunk = as.numeric(rownames(.)) + 2) %>% -->
<!--   mutate(version = refactor_version) %>% -->
<!--   mutate(script = 'covid-scraping.rmd') %>% -->
<!--   arrange(desc(time_sec)) -->

<!-- ggplot(time_df, aes(y = time_sec, x = chunk, fill = time_sec)) +  -->
<!--   geom_bar(stat = 'identity') +  -->
<!--   geom_text(aes(label = chunk), position=position_dodge(width = 0.9), vjust = -0.25) +  -->
<!--   labs(x = 'chunk #', y = 'runtime (seconds)') +  -->
<!--   scale_fill_gradient(low = 'gray80', high = 'tomato1') +  -->
<!--   theme_pubr() +  -->
<!--   theme(axis.text.x = element_blank(), -->
<!--         legend.position = 'none') -->
<!-- ``` -->

<!-- ## total run time -->

<!-- ```{r} -->
<!-- time_df %>% summarize(sum(time_sec)) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- write.csv(time_df, paste0('diagnostics/diagnostics_runtime_', refactor_version, '.csv'), -->
<!--           row.names = FALSE) -->
<!-- ``` -->



