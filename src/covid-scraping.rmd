---
title: 'COVID Scraping'
author: 'Jeffrey Brennan'
output: html_document
editor_options: 
  chunk_output_type: console
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "diagnostics/",
                    knit_root_dir = "C:/Users/jeffb/Desktop/Life/personal-projects/COVID") })
---

# SETUP

```{r, echo = FALSE}
# performance analysis 
# source: https://bookdown.org/yihui/rmarkdown-cookbook/time-chunk.html
all_times <- list()  # store the time for each chunk
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      now <<- Sys.time()
    } else {
      res <- difftime(Sys.time(), now)
      all_times[[options$label]] <<- res
    }
  }
}))
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(time_it = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = NA)
```

```{r, echo = FALSE}
refactor_version = '3'
```

```{r}
# data manipulation
library(tidyverse)
library(data.table)
library(readxl)
library(writexl)
library(stringr)
library(zoo)

library(lubridate)

library(ggpubr)

# web scraping
library(rvest)
library(jsonlite)
library(glue)
```

```{r}
# Grab every sheet from an excel file and convert to list of dataframes
# https://stackoverflow.com/questions/12945687/read-all-worksheets-in-an-excel-workbook-into-an-r-list-with-data-frames
read_excel_allsheets = function(filename, tibble = FALSE, col_option = TRUE) {
    sheets = readxl::excel_sheets(filename)
    x = lapply(sheets, function(X) read_excel(filename, sheet = X, skip = 1,
                                              col_names = col_option, na = '.'))
    x = lapply(x, as.data.frame)
    return(x)
}

# set date for writing files
# If before 5 PM EST, then record as last date since DSHS data will not be updated yet
date_out = ifelse((Sys.time() < as.POSIXct(paste0(Sys.Date(), '16:00'), tz = 'America/Chicago')),
                   Sys.Date() - 1,
                   Sys.Date())

# convert numeric sys.date() to yyyy-mm-dd
date_out = as.Date(date_out, origin = '1970-1-1')


Fix_Num_Dates = function(dates) { 
  # TODO: add more checks for different int dates
  clean_dates = as.Date(as.numeric(dates), '1899-12-30')

  if (sum(is.na(clean_dates)) > 0) {
    clean_dates[which(is.na(clean_dates))] = as.Date(clean_dates[which(is.na(clean_dates))], origin = '1970-1-1')
  }
  return(format(clean_dates, '%Y-%m-%d'))
}
  
Fix_Char_Dates = function(dates) { 
  #Matches 2 or 4 digits, separator, 2 or 4 digits, optional separator, optional 2 or 4 digits
  # Coerces all common separators to "-" 
  date_regex = '(\\d{4}|\\d{2}|\\d{1})(\\.|\\-|\\/)(\\d{4}|\\d{2}|\\d{1})?(\\.|\\-|\\/)?(\\d{4}|\\d{2})'
  clean_dates = str_extract(dates, date_regex) %>% str_replace_all(., '\\/|\\.', '\\-')
  
  mdy_dates = which(!is.na(as.Date(clean_dates, format = '%m-%d-%y')))
  md_dates = which(is.na(as.Date(clean_dates, format = '%m-%d-%Y')))
  # if (length(mdy_dates) == length(md_dates)) { 
  #   md_dates = c()
  # }
  

  if (length(md_dates > 0)){
      md_dates_2020 = which(format(as.Date(clean_dates[md_dates], '%m-%d'), '%m') %in% as.character(seq(as.numeric(format(date_out, '%m')) + 1, 12)))
    
    if (length(md_dates_2020) > 0) { 
      clean_dates[md_dates[md_dates_2020]] = paste0('2020-', clean_dates[md_dates[md_dates_2020]])
      clean_dates[md_dates[-md_dates_2020]] = format(as.Date(clean_dates[md_dates[-md_dates_2020]],
                                                             '%m-%d'), '%Y-%m-%d')
    } else { 
      clean_dates[md_dates] = format(as.Date(clean_dates, '%m-%d'), '%Y-%m-%d')
    }
  }
  
  if (length(mdy_dates > 0)) { 
    clean_dates[mdy_dates] = format(as.Date(clean_dates[mdy_dates], '%m-%d-%Y'), '%Y-%m-%d')
  }

  return(clean_dates)
}


Date_Parser = function(raw_date) { 
  numeric_loc = which(!is.na(as.numeric(raw_date)))

    if (length(numeric_loc) == 0){
      clean_dates = Fix_Char_Dates(raw_date)
    } else {
      clean_num_date = Fix_Num_Dates(raw_date[numeric_loc])
      clean_char_date = Fix_Char_Dates(raw_date[-numeric_loc])
      clean_dates = sort(c(clean_num_date, clean_char_date))
    }
  return(clean_dates)
}
```

## Classifications

```{r}
# add metro and PHR code designations
# source: https://www.dshs.state.tx.us/chs/info/TxCoPhrMsa.xls
# add PHR readable names from https://dshs.texas.gov/regions/default.shtm
PHR_helper = data.frame(PHR = c("1", "2/3", "4/5N",
                                "6/5S", "7", "8",
                                "9/10", "11"),
                        PHR_Name = c('Lubbock PHR', 'Arlington PHR', 'Tyler PHR',
                                     'Houston PHR', 'Temple PHR', 'San Antonio PHR',
                                     'El Paso PHR', 'Harlingen PHR'))


county_classifications = read_xlsx('original-sources/helpers/county_classifications.xlsx', sheet = 1) %>% 
  slice(1:254) %>% 
  dplyr::select(1, 5, 8) %>%
  setNames(c('County', 'PHR', 'Metro_Area')) %>% 
  left_join(., PHR_helper, by = 'PHR') %>%
  mutate(PHR_Combined = paste0(PHR, ' - ', PHR_Name))
```

```{r}
# TSA levels
tsa_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID-19HospitalizationsOverTimebyTSA.xlsx'
temp = tempfile()
download.file(tsa_url, temp, mode = 'wb')
DSHS_tsa_names = readxl::read_xlsx(temp)[3:24, 1:2]

names(DSHS_tsa_names) = c('TSA', 'TSA_Name')

# drop . suffix from TSA codes
DSHS_tsa_names$TSA = gsub('.', '', DSHS_tsa_names$TSA, fixed = TRUE)

# get list of counties per TSA
tsa = read.csv('original-sources/helpers/tsa_list.csv', header = F)[-1]
tsa_long = reshape::melt(tsa, id = c('V2', 'V3'))
tsa_long_complete = subset(tsa_long, value != '')[, c(1, 4)] %>% 
  setNames(c('TSA', 'County')) %>%
  mutate(County = trimws(County)) %>% 
  left_join(DSHS_tsa_names, by = 'TSA') %>% 
  distinct() %>% 
  mutate(TSA_Combined = paste0(TSA, ' - ', TSA_Name))


dshs_pops =
  read_csv('https://raw.githubusercontent.com/jeffbrennan/COVID-19/d03d476f7fb060dfd2e1a600a6a1e449df0ab8df/original-sources/DSHS_county_cases.csv') %>%
  distinct() %>%
  select(County, Population) %>%
  rename(Population_DSHS = Population)
```

```{r}
# https://www.nrcs.usda.gov/wps/portal/nrcs/detail/tx/technical/dma/rwa/?cid=nrcs143_013697
# fips = read_csv('original-sources/helpers/fips_county.csv')

# 
# 
# # https://www.huduser.gov/portal/datasets/usps_crosswalk.html#codebook
# zip_crosswalk = read_csv('original-sources/helpers/zip_county.csv') %>%
#   inner_join(fips, by = c('COUNTY'= 'FIPS')) %>%
#   left_join(tsa_long_complete %>% dplyr::select(County, TSA_Combined), by = 'County') %>% 
#   left_join(county_classifications %>% dplyr::select(County, PHR_Combined)) %>%
#   left_join(dshs_pops) %>% 
#   group_by(ZIP) %>% 
#   mutate(dupe = n())
# 
# dupe_zips = zip_crosswalk %>% 
#   filter(dupe > 1) %>%
#   arrange(ZIP, -Population_DSHS) %>% 
#   slice(1)
# 
# zips_out = zip_crosswalk %>% 
#   filter(dupe == 1) %>% 
#   rbind(dupe_zips) %>% 
#   arrange(ZIP) %>% 
#   select(-dupe, -COUNTY, -Population_DSHS)

# https://www.zip-codes.com/state/tx.asp
# zip_crosswalk = read_csv('original-sources/helpers/zips_com_list.csv') %>%
#   mutate(County = gsub('Mcculloch', 'McCulloch', County)) %>% 
#   mutate(County = gsub('Mclennan', 'McLennan', County)) %>% 
#   mutate(County = gsub('De Witt', 'DeWitt', County)) %>% 
#   mutate(County = gsub('Mcmullen', 'McMullen', County)) %>%
#   # inner_join(fips, by = c('COUNTY'= 'FIPS')) %>%
#   left_join(tsa_long_complete %>% dplyr::select(County, TSA_Combined), by = 'County') %>%
#   left_join(county_classifications %>% dplyr::select(County, PHR_Combined)) %>%
#   left_join(dshs_pops) %>%
#   group_by(ZIP) %>%
#   mutate(dupe = n()) %>%
#   dplyr::select(-Population_DSHS, -dupe)
# 
# 
# # write_csv(dupe_zips, 'original-sources/helpers/dupe_zips.csv')
# write_csv(zip_crosswalk, 'original-sources/helpers/zip_crosswalk.csv')
```


# HOSPITAL LEVEL

```{r}
# TODO: finalize metrics of interest and add to tableau folder
# 
# hosp_dates = seq(as.Date('2020-12-07'), length = 52, by = 'week')
# hosp_date = max(hosp_dates[which(hosp_dates <= date_out)])
# hosp_date_f = format(hosp_date, '%Y%m%d')
# #
# 
# # https://healthdata.gov/sites/default/files/reported_hospital_capacity_admissions_facility_level_weekly_average_timeseries_20201214.csv
# base_hosp_url = 'https://healthdata.gov/sites/default/files/reported_hospital_capacity_admissions_facility_level_weekly_average_timeseries_'
# hosp_df = fread(paste0(base_hosp_url, hosp_date_f, '.csv'), na.strings = c('-999999', '-999999.0'))
# 
# fips_link = read.csv('original-sources/helpers/unpublished/county_fips.csv') %>%
#   dplyr::select(fips, county_name) %>%
#   setNames(c('fips_code', 'County'))
# 
# hosp_df_parsed = hosp_df %>%
#   filter(state == 'TX') %>%
#   dplyr::select(-ccn, -state, -hospital_subtype, -is_metro_micro,
#                 -total_patients_hospitalized_confirmed_influenza_and_covid_7_day_avg,
#                 -contains('_sum'), -contains('_coverage')) %>%
#   mutate(inpatient_beds_used_pct = inpatient_beds_used_7_day_avg / all_adult_hospital_inpatient_beds_7_day_avg) %>% 
#   mutate(total_patients_hospitalized_confirmed_and_suspected_covid_7_day_avg
#            = total_adult_patients_hospitalized_confirmed_and_suspected_covid_7_day_avg
#            + total_pediatric_patients_hospitalized_confirmed_and_suspected_covid_7_day_avg) %>% 
#   mutate(total_patients_hospitalized_confirmed_covid_7_day_avg
#            = total_adult_patients_hospitalized_confirmed_covid_7_day_avg
#            + total_pediatric_patients_hospitalized_confirmed_covid_7_day_avg) %>% 
#   mutate(total_pediatric_icu_beds_7_day_avg
#            = icu_beds_used_7_day_avg
#            - total_staffed_adult_icu_beds_7_day_avg) %>% 
#   relocate(inpatient_beds_used_pct, .after = inpatient_beds_used_7_day_avg) %>%
#   relocate(total_patients_hospitalized_confirmed_and_suspected_covid_7_day_avg,
#            .after = total_pediatric_patients_hospitalized_confirmed_and_suspected_covid_7_day_avg) %>% 
#   relocate(total_patients_hospitalized_confirmed_covid_7_day_avg, 
#            .after = total_pediatric_patients_hospitalized_confirmed_covid_7_day_avg) %>% 
#   relocate(total_pediatric_icu_beds_7_day_avg, .after = icu_beds_used_7_day_avg) %>%
#   setNames(gsub('_7_day_avg', '', names(.))) %>%
#   left_join(fips_link, by = 'fips_code') %>%
#   mutate(County = gsub(' County', '', County)) %>%
#   left_join(tsa_long_complete %>% dplyr::select(County, TSA_Combined), by = 'County') %>%
#   left_join(county_classifications %>% dplyr::select(County, PHR_Combined), by = 'County') %>%
#   relocate(County, .after = collection_week) %>%
#   relocate(TSA_Combined, .after = County) %>%
#   relocate(PHR_Combined, .after = TSA_Combined) %>%
#   relocate(fips_code, .after = PHR_Combined)
```

<!-- # hosp investigation -->

<!-- ```{r} -->
<!-- tmc_hospital_list = c('HARRIS HEALTH SYSTEM', 'HOUSTON METHODIST HOSPITAL', -->
<!--                   'UNIVERSITY OF TEXAS M D ANDERSON CANCER CENTER,THE', 'MEMORIAL HERMANN TEXAS MEDICAL CENTER', -->
<!--                   "ST LUKE'S PATIENTS MEDICAL CENTER", 'TEXAS CHILDRENS HOSP') -->

<!-- hhs_tmc = hosp_df_parsed %>%  -->
<!--   filter(hospital_name %in% tmc_hospital_list) -->


<!-- write.csv(hosp_df_parsed, -->
<!--           'C:/Users/jeffb/Desktop/Life/personal-projects/COVID/original-sources/helpers/unpublished/hhs_hospitals.csv', -->
<!--           row.names = FALSE) -->


<!-- write.csv(hhs_tmc, -->
<!--           'C:/Users/jeffb/Desktop/Life/personal-projects/COVID/original-sources/helpers/unpublished/hhs_tmc_comparison.csv', -->
<!--           row.names = FALSE) -->
<!-- ``` -->

# SCHOOL LEVEL

```{r}
# school files are small (~ 6kb - read every time and don't overwrite)
nyt_schools = rbindlist(lapply(list.files('original-sources/historical/nyt/archive', full.names = TRUE), read.csv)) %>% 
  setNames(c('School', 'City', 'County', 'Deaths_Cumulative', 'Cases_Cumulative', 'Date')) %>%
  mutate(Date = as.Date(Date)) %>% 
  mutate(Cases_Cumulative = ifelse(Cases_Cumulative == -1, NA, Cases_Cumulative))
```

## Texas school districts

```{r}
# data ending on Sunday posted on Friday (5 day lag)
school_dates = seq(as.Date('2020-10-11'), by = 'week', length.out = 52)
# no 11/22 update due to Thanksgiving
# missing 12/27 update prob due to christmas/new years
school_dates = school_dates[-12]
# school_dates = school_dates[-10]
school_date = max(school_dates[which(school_dates <= date_out - 5)])

tryCatch({
  # school_url = paste0('https://dshs.texas.gov/chs/data/tea/district-level-school-covid-19-case-data/campus-level-Data-',
  #                   format(school_date+2, '%m%d%Y'), '.xls')
  # school_url = 'https://dshs.texas.gov/chs/data/tea/district-level-school-covid-19-case-data/District-level-data.xlsx'
  school_url = 'https://dshs.texas.gov/chs/data/tea/district-level-school-covid-19-case-data/campus-level-Data_01122021v3.xls'
  temp = tempfile()
  download.file(school_url, temp, mode = 'wb')
  DSHS_schools_raw = data.frame(read_excel(temp, sheet = 1))
  },
  error = function(e) {
   school_url = paste0('https://dshs.texas.gov/chs/data/tea/district-level-school-covid-19-case-data/campus-level-Data_',
                    format(school_date+2, '%m%d%Y'), '.xls')
  temp = tempfile()
  download.file(school_url, temp, mode = 'wb')
  DSHS_schools_raw <<- data.frame(read_excel(temp, sheet = 1))
  })


first_row = which(DSHS_schools_raw[, 1] == 'District Name') + 1
last_row = which(DSHS_schools_raw[, 1] == 'ZEPHYR ISD')
names(DSHS_schools_raw)[1:2] = c('District', 'LEA')


# read in matching county data (overlapping counties available for public, but not private ISDs)
# public school source: http://tea-texas.maps.arcgis.com/sharing/rest/content/items/87c957f2ec334c83bc2b952bf6e64344/data
# private school source: http://mansfield.tea.state.tx.us/Tea.AskTed.Web/Forms/DownloadDefault.aspx
county_isd_wide = read.csv('original-sources/helpers/county_isd_wide.csv')

DSHS_schools_clean = DSHS_schools_raw[first_row:last_row, ] %>%
  mutate(LEA = as.numeric(gsub("'", '', LEA))) %>%
  mutate(District = str_to_title(District)) %>%
  mutate(District = gsub('Isd', 'ISD', District)) %>%
  mutate(District = gsub('\n', ' ', District)) %>%
  mutate(Date = school_date) %>%
  # dplyr::select(District, Date, County, LEA, everything()) %>%
  dplyr::select(District, Date, LEA, everything()) %>%
  mutate_at(5:ncol(.), as.numeric) %>%
  setNames(c('District', 'Date', 'LEA', 'Total_Enrollment', 'Approximate_Enrollment',
             'Cases_Weekly_GRADE_EE_3', 'Cases_Weekly_GRADE_4_6', 'Cases_Weekly_GRADE_7_12',
             'Cases_Weekly_Staff', 'Infections_Weekly_On_Campus',
             'Infections_Weekly_Off_Campus', 'Infections_Weekly_Unknown',

             'Cases_Cumulative_GRADE_EE_3', 'Cases_Cumulative_GRADE_4_6',
             'Cases_Cumulative_GRADE_7_12', 'Cases_Cumulative_Staff',
             'Infections_Cumulative_On_Campus', 'Infections_Cumulative_Off_Campus',
             'Infections_Cumulative_Unknown'))

# save for future combinations - avoids cleaning on every run
write.csv(DSHS_schools_clean,
          paste0('original-sources/historical/dshs-schools/DSHS_Schools_', school_date, '.csv'),
          row.names = FALSE)
```


```{r}
# combine previous cleaned versions w/ current week
DSHS_school_df = rbindlist(lapply(list.files('original-sources/historical/dshs-schools', full.names = TRUE), read.csv))

DSHS_school_df = DSHS_school_df %>% 
  mutate(District = gsub('\n', ' ', District, fixed = TRUE)) %>% 
  mutate(District = gsub('  ', ' ', District)) %>% 
  mutate(District = gsub('Lighthouse Charter School', 'Lighthouse Public Schools', District)) %>% 
  mutate(Total_Enrollment = as.numeric(Total_Enrollment)) %>% 
  mutate(Approximate_Enrollment = as.numeric(Approximate_Enrollment)) %>% 
  mutate(Total_Enrollment = ifelse(Total_Enrollment == 0, NA, Total_Enrollment)) %>% 
  mutate(Approximate_Enrollment = ifelse(Approximate_Enrollment == 0, NA, Approximate_Enrollment)) %>%
  distinct()

write_xlsx(list('school_data' = DSHS_school_df,
                'helper' = read.csv('original-sources/helpers/county_isd_long.csv')),
           'tableau/district_school_reopening.xlsx',
           format_headers = FALSE)
```

# COUNTY LEVEL

## Google mobility

```{r}
# fread for faster processing
mobility_data = fread('https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv')
```

```{r}
mobility_texas = mobility_data %>% 
  filter(sub_region_1 == 'Texas') %>% 
  dplyr::select(sub_region_2, date, 
                retail_and_recreation_percent_change_from_baseline,
                grocery_and_pharmacy_percent_change_from_baseline,
                parks_percent_change_from_baseline,
                transit_stations_percent_change_from_baseline,
                workplaces_percent_change_from_baseline,
                residential_percent_change_from_baseline) %>% 
  setNames(c('County', 'Date', 'Retail_Recreation', 'Grocery_Pharmacy',
             'Parks', 'Transit', 'Workplaces', 'Residential')) %>% 
  mutate(County =  sub('^$', 'Unallocated', County)) %>% 
  mutate(County = as.factor(gsub(' County', '', County))) %>% 
  filter(County != 'Unallocated') %>% 
  mutate(Date = as.Date(Date))

# # drop cols
# mobility_texas = mobility_texas[, -c(1:3, 5:7)]
# 
# # fix colnames
# names(mobility_texas) = c('County', 'Date', 'Retail_Recreation', 'Grocery_Pharmacy',
#                              'Parks', 'Transit', 'Workplaces', 'Residential')
# 
# # Add name for blank county cells & drop 'county' suffix
# mobility_texas$County = sub('^$', 'Unallocated', mobility_texas$County)
# mobility_texas$County = gsub(' County', '', mobility_texas$County)
# 
# # drop blank cells
# mobility_texas = subset(mobility_texas, County != 'Unallocated')
# 
# #fix types
# mobility_texas$County = as.factor(mobility_texas$County)
# mobility_texas$Date = as.Date(mobility_texas$Date)
```

## cases

```{r}
# download xlsx as tempfile and load using readxl
case_url = 'http://dshs.texas.gov/coronavirus/TexasCOVID19DailyCountyCaseCountData.xlsx'
temp = tempfile()
download.file(case_url, temp, mode = 'wb') 

DSHS_cases_wide = data.frame(read_excel(temp, sheet = 1, skip = 2)) %>% slice(1:254)
names(DSHS_cases_wide)[2:ncol(DSHS_cases_wide)] = Date_Parser(names(DSHS_cases_wide)[2:ncol(DSHS_cases_wide)])

DSHS_cases_long = DSHS_cases_wide %>% 
  reshape::melt('County.Name') %>% 
  setNames(c('County', 'Date', 'Cases_Cumulative')) %>%
  mutate(Date = as.Date(Date)) %>%
  mutate(Cases_Cumulative = as.integer(as.character(Cases_Cumulative))) %>% 
  group_by(County) %>%
  tidyr::complete(Date = seq.Date(min(Date), date_out, by="day")) %>%
  mutate(Cases_Cumulative_NA = Cases_Cumulative) %>% 
  tidyr::fill(Cases_Cumulative, .direction = "down")
```

## deaths

```{r}
death_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID19DailyCountyFatalityCountData.xlsx'
temp = tempfile()
download.file(death_url, temp, mode = 'wb') 

DSHS_deaths_wide = data.frame(readxl::read_excel(temp, sheet = 1, skip = 2)) %>% slice(1:254)
names(DSHS_deaths_wide) = gsub('X', '', names(DSHS_deaths_wide))

names(DSHS_deaths_wide)[2:ncol(DSHS_deaths_wide)] = Date_Parser(names(DSHS_deaths_wide)[2:ncol(DSHS_deaths_wide)])

DSHS_deaths_long = DSHS_deaths_wide %>% 
  reshape2::melt('County.Name') %>% 
  setNames(c('County', 'Date', 'Deaths_Cumulative')) %>% 
  mutate(Date = as.Date(Date)) %>% 
  mutate(Deaths_Cumulative = as.integer(as.character(Deaths_Cumulative))) %>% 
  mutate(County = stringr::str_to_title(County)) %>% 
  mutate(County = gsub('De Witt', 'DeWitt', County)) %>%
  mutate(County = gsub('Dewitt', 'DeWitt', County)) %>%
  mutate(County = gsub('Mcculloch', 'McCulloch', County)) %>% 
  mutate(County = gsub('Mclennan', 'McLennan', County)) %>%
  mutate(County = gsub('Mcmullen', 'McMullen', County)) %>%
  group_by(County) %>%
  tidyr::complete(Date = seq.Date(min(Date), date_out, by="day")) %>%
  mutate(Deaths_Cumulative_NA = Deaths_Cumulative) %>%
  tidyr::fill(Deaths_Cumulative, .direction = "down") %>%
  mutate(Deaths_Daily = c(Deaths_Cumulative[1], diff(Deaths_Cumulative))) %>% 
  ungroup()
```

## testing

```{r}
# LEGACY
legacy_tests_long = read.csv('original-sources/historical/testing/DSHS_county_tests_legacy_cleaned.csv') %>% 
  mutate(Date = as.Date(Date))

# NEW
test_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID-19CumulativeTestsbyCounty.xlsx'
temp = tempfile()
download.file(test_url, temp, mode = 'wb')

new_tests = data.frame(readxl::read_excel(temp, sheet = 1, skip = 1))
new_tests_long = new_tests %>% 
  filter(str_detect(County, 'County|Unknown|Total', negate = TRUE)) %>% 
  reshape::melt(id = 'County') %>% 
  setNames(c('County', 'Date', 'Tests_Cumulative')) %>% 
  mutate(Date = as.Date(as.integer(Date), '2020-09-12'))

# MERGE
merged_tests = rbind(legacy_tests_long, new_tests_long)

DSHS_tests_long = merged_tests %>%
  group_by(County) %>% 
  tidyr::complete(Date = seq.Date(min(Date), date_out, by="day")) %>%
  mutate(Tests_Cumulative_NA = Tests_Cumulative) %>%
  tidyr::fill(Tests_Cumulative, .direction = "down") %>%
  mutate(Tests_Daily = c(Tests_Cumulative[1], diff(Tests_Cumulative)))
```

## new cases

```{r}
# 10/23 - file includes all dates now
# get new cases as excel file
new_case_url ='https://dshs.texas.gov/coronavirus/TexasCOVID-19NewCasesOverTimebyCounty.xlsx'
temp = tempfile()
download.file(new_case_url, temp, mode = 'wb') 


# MANUALLY ADD MONTGOMERY CASES PER MISTI WILLINGHAM (11/20)
# 11/1 - 11/20 [manual entry] | 11/21 DSHS value
montgomery_new_cases = c(32, 61, 78, 110, 98, 124, 78, 77, 144, 97, 146, 133, 124, 103, 90, 109, 33, 3, 330, 162, 484)
montgomery_case_dates = seq(as.Date('2020-11-01'), as.Date('2020-11-21'), by = 'day')

DSHS_new_cases_wide = data.frame(readxl::read_excel(temp, sheet = 1, skip = 2)) %>% slice(1:254)
names(DSHS_new_cases_wide)[2:ncol(DSHS_new_cases_wide)] = Date_Parser(names(DSHS_new_cases_wide)[2:ncol(DSHS_new_cases_wide)])

DSHS_new_cases_long = DSHS_new_cases_wide %>%
  reshape2::melt('County') %>% 
  setNames(c('County', 'Date', 'Cases_Daily')) %>%
  mutate(Date = as.Date(Date)) %>%
  mutate(Cases_Daily = ifelse(Cases_Daily < 0, 0, Cases_Daily)) %>%
  mutate(Cases_Daily = replace(Cases_Daily, 
                               County == 'Montgomery' & Date %in% montgomery_case_dates,
                               montgomery_new_cases)) %>%
  arrange(Date, County)
```

## active cases

```{r}
old_active_cases_long = read.csv('original-sources/historical/active-cases/active_case_archive.csv') %>% 
  mutate(Date = as.Date(Date))


# current
new_case_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID-19ActiveCaseDatabyCounty.xlsx'
temp = tempfile()
download.file(new_case_url, temp, mode = 'wb') 
new_active_cases = data.frame(readxl::read_excel(temp, sheet = 1, skip = 2)) %>%
  slice(which(County == 'Anderson'):which(County == 'Zavala')) %>% 
  dplyr::select(-Notes) %>% 
  select_if(function(x) all(!is.na(x)))

names(new_active_cases)[2:ncol(new_active_cases)] = Date_Parser(names(new_active_cases)[2:ncol(new_active_cases)])


# melt
new_active_cases_long = reshape::melt(new_active_cases, id = 'County') %>% 
  setNames(c('County', 'Date', 'Active_Cases_Cumulative')) %>%
  mutate(Date = as.Date(Date)) %>%
  group_by(Date) %>%
  # mutate(Date = as.Date(paste(str_extract_all(Date, '\\d+')[[1]], collapse = ' '), '%m%d')) %>% 
  ungroup() %>%
  group_by(County) %>% 
  distinct() %>%
  mutate(Active_Cases_Cumulative = as.integer(as.character(Active_Cases_Cumulative))) %>%
  tidyr::complete(Date = seq.Date(min(Date), date_out, by="day")) %>%
  mutate(Active_Cases_Cumulative_NA = Active_Cases_Cumulative) %>%
  tidyr::fill(Active_Cases_Cumulative, .direction = "down") %>%
  mutate(Active_Cases_Daily = c(Active_Cases_Cumulative[1], diff(Active_Cases_Cumulative))) %>%
  filter(!is.na(County))

DSHS_active_cases_long = rbind(old_active_cases_long, new_active_cases_long) %>% arrange(Date, County)
```


### merge

```{r}
# combine DSHS sources using merge helper function
# https://www.musgraveanalytics.com/blog/2018/2/12/how-to-merge-multiple-data-frames-using-base-r

county_counts = Reduce(function(x, y) merge(x, y, by = c('Date', 'County'), all=TRUE),
       list(DSHS_cases_long, DSHS_new_cases_long, DSHS_deaths_long, DSHS_tests_long,
            DSHS_active_cases_long))
```


## merge

```{r}
# DSHS pop - removed by DSHS 07/30 - defaulting to previous file
merged_dshs = Reduce(function(x, y) merge(x, y, by = 'County', all = TRUE),
                       list(county_counts, tsa_long_complete, dshs_pops, county_classifications))

# add TSA, PHR & HHSC combination
merged_dshs$TSA_Combined = paste0(merged_dshs$TSA, ' - ', merged_dshs$TSA_Name)
merged_dshs$PHR_Combined = paste0(merged_dshs$PHR, ' - ', merged_dshs$PHR_Name)
# merged_dshs$HHSC_Combined = paste0(merged_dshs$HHSC, ' - ', merged_dshs$HHSC_Name)

merged_county = as.data.frame(merge(merged_dshs, mobility_texas,
                                    by = c('Date', 'County'), all = TRUE)) %>% 
  filter(!is.na(County) & County != 'Unknown')

# fix types
merged_county$County = as.factor(merged_county$County)
merged_county$Population_DSHS = as.numeric(merged_county$Population_DSHS)

# keep only relevant dates (previous dates include google mobility only)
merged_county = merged_county %>% 
  filter(Date >= as.Date('2020-03-04') & !is.na(County)) %>% 
  distinct() 
```

## TPR 

```{r}
Get_TPR = function() { 
  page = read_html('https://data.cms.gov/stories/s/q5r5-gjyu')
  tpr_url = page %>% html_nodes('a') %>% html_attr('href') %>%
    .[grepl('download', .)] %>% .[1] %>% gsub('%2F', '/', .)
  
  # temp dir needed for unzip to keep directory clean
  temp_dir = tempdir()
  temp_file = tempfile()
  download.file(tpr_url, temp_file, mode = 'wb')
  tpr_df = read_excel(unzip(temp_file, exdir = temp_dir)[[1]])
  tpr_date = Date_Parser(format(as.Date(str_match(tpr_df[2,2], '-(.*)')[2], '%B %d'), '%m-%d'))
  print(tpr_date)
  
  tpr_out = tpr_df %>% 
    setNames(.[which(tpr_df[, 1] == 'County'), ]) %>% 
    filter(State == 'TX') %>% 
    mutate(County = gsub(' County, TX', '', County)) %>% 
    dplyr::select(1, 7, 9) %>% 
    mutate_at(c(2,3), as.numeric) %>% 
    setNames(c('County', 'Tests', 'TPR_CMS')) %>% 
    mutate(Date = tpr_date) %>% 
    dplyr::select(County, Date, Tests, TPR_CMS)
  write.csv(tpr_out, paste0('original-sources/historical/cms_tpr/TPR_', tpr_date,  '.csv'),
            row.names = FALSE) 
  }
  
Get_TPR()
tpr_df = rbindlist(
         lapply(list.files('original-sources/historical/cms_tpr/', full.names = TRUE), read.csv),
         fill = TRUE) %>% 
         mutate(Date = as.Date(Date)) %>% 
  rename(TPR = TPR_CMS) %>%  
  mutate(TPR = ifelse(Date >= '2020-12-16', NA, TPR))
```


## TPR cpr

Source for TPR data post 12/16. Still use CMS tests and dates for case averages to keep % change section of stat analysis rmd the same

```{r}
# get latest url
page = read_html('https://beta.healthdata.gov/National/COVID-19-Community-Profile-Report/gqxm-d9w9')
file_loc = page %>%
  html_nodes('script') %>%
  str_detect('.xlsx') %>%
  which()

file_text = page %>% html_nodes('script') %>%
  .[file_loc] %>%
  html_text() %>%
  gsub('\n    var initialState =\n      ', '', .) %>%
  gsub('\n   ;\n  ', '', .)


newest_file = fromJSON(file_text)$view$attachments %>%
  filter(href %>% str_detect('.xlsx')) %>%
  dplyr::select(href) %>%
  slice(1) %>% 
  unlist()


file_date = as.Date(str_match(newest_file, '(Report |Report_)(.*)(_)')[3], '%Y%m%d')
file_url = (paste0('https://beta.healthdata.gov', newest_file))

temp = tempfile()
download.file(file_url, temp, mode = 'wb')

cpr_day = read_xlsx(temp, sheet = 6) %>%
  slice(1) %>% 
  dplyr::select(contains('VIRAL (RT-PCR) LAB TESTING: LAST WEEK')) %>% 
  names() %>% 
  str_match(., '(\\d{1,2}).(?<=\\))') %>% 
  .[2] %>% 
  as.numeric()

if (cpr_day > as.numeric(format(Sys.Date(), '%d'))) { 
  cpr_month = format(seq.Date(Sys.Date(), length.out = 2, by = '-1 month')[2], '%m')
  cpr_date = as.Date(glue('{cpr_month}/{cpr_day}'), '%m/%d')  
} else { 
  cpr_date = as.Date(glue('{format(Sys.Date(), "%m")}/{cpr_day}'), '%m/%d')  
  }

cpr_tpr = read_xlsx(temp, sheet = 6, skip = 1) %>% 
  filter(`State Abbreviation` == 'TX') %>% 
  dplyr::select('County',
         contains('lab test positivity rate - last 7 days'),
         contains('diagnostic tests - last 7 days')) %>% 
  filter(County != 'Unallocated, TX') %>%
  mutate(County = gsub(' County, TX', '', County)) %>% 
  setNames(c('County', 'TPR_CPR', 'Tests')) %>% 
  mutate(Date = cpr_date) %>% 
  arrange(County)

# save
write.csv(cpr_tpr,
          paste0('original-sources/historical/cpr/cpr_tpr_', cpr_date, '.csv'),
          row.names = FALSE)


# add cms archive (8/19 - 12/09) (data represented 2 weeks of cases)

cpr_dates = list.files('original-sources/historical/cpr') %>% 
  gsub('cpr_tpr_', '', .) %>% 
  gsub('.csv', '', .) %>% 
  as.Date(.)

cms_dates = list.files('original-sources/historical/cms_tpr/') %>% 
  gsub('TPR_', '', .) %>% 
  gsub('.csv', '', .) %>% 
  as.Date(.)

TPR_dates = sort(unique(c(cpr_dates, cms_dates)))

# combine cpr archive
all_cpr_tpr = rbindlist(lapply(list.files('original-sources/historical/cpr/', full.names = TRUE), read.csv)) %>% 
  rename(TPR = TPR_CPR) %>% 
  mutate(Date = as.Date(Date)) %>% 
  mutate(Tests = NA)
  
cms_archive = tpr_df %>% filter(Date < '2020-12-16')
cms_new = tpr_df %>% filter(Date >= '2020-12-16') %>% dplyr::select(-TPR)

tpr_cases = merged_county %>% 
  dplyr::select(County, Date, Cases_Daily, Population_DSHS) %>%
  filter(Date >= as.Date(min(TPR_dates)) - 13 & Date <= max(TPR_dates)) %>%
  group_by(County) %>%
  mutate(Cases_100K_7Day_MA = (rollmean(Cases_Daily, k = 7, align = 'right',
                                        na.pad = TRUE, na.rm = TRUE)
                               / Population_DSHS) * 100000) %>%
  mutate(Cases_100K_14Day_MA = (rollmean(Cases_Daily, k = 14, align = 'right',
                                         na.rm = TRUE, na.pad = TRUE)
                                / Population_DSHS) * 100000) %>% 
  filter(Date %in% TPR_dates) %>% 
  dplyr::select(-Cases_Daily, -Population_DSHS, -Cases_100K_14Day_MA)


tpr_out = all_cpr_tpr %>% 
  rbind(cms_archive, fill = TRUE) %>%
  left_join(tpr_cases, by = c('County', 'Date')) %>%
  left_join(cms_new, by = c('County', 'Date')) %>%
  mutate(Tests.x = ifelse(is.na(Tests.y), Tests.x, Tests.y)) %>% 
  rename(Tests = Tests.x) %>%
  dplyr::select(-Tests.y) %>% 
  dplyr::select(County, Date, TPR, Tests, Cases_100K_7Day_MA) %>%
  mutate(TPR = ifelse(TPR == 0 | TPR == 1, NA, TPR)) %>%
  arrange(County, Date)

write.csv(tpr_out, 'tableau/county_TPR.csv', row.names = FALSE)
```

## vaccinations

```{r}
download.file('https://www.dshs.texas.gov/immunize/covid19/COVID-19-Vaccine-Data-by-County.xls', mode = 'wb', 
              glue('original-sources/historical/vaccinations/vaccinations_{date_out}.xlsx'))

# Clean_Vaccines = function(x) { 
#   file_date = Date_Parser(x)
#   df = read_excel(x, sheet = 2) %>%
#     mutate(Date = file_date) %>% 
#     setNames(c('County', 'PHR',
#                'Doses_Allocated', 'Doses_Administered',
#                'People_Vaccinated_Partial', 'People_Vaccinated_Full',
#                'Population_Over_16', 'Population_Over_65',
#                'Population_Phase_1A_Healthcare',
#                'Population_Phase1A_Care_Residents',
#                'Population_Phase_1B_Medical_Condition', 'Date')) %>% 
#     filter(!(County %in% c('Texas', '*Other', 'Federal Long-Term Care Vaccination Program'))) %>% 
#     dplyr::select(Date, everything())
# } 
# 
# vaccine_files = list.files('original-sources/historical/vaccinations/', full.names = TRUE)
# 
# county_vaccine = rbindlist(lapply(vaccine_files, Clean_Vaccines))
# demographics_vaccine = read_excel(vaccine_files[length(vaccine_files)], sheet = 3) %>% 
#   setNames(c('Gender', 'Age', 'Race_Ethnicity', 'Doses_Administered', 'People_Vaccinated_Partial', 'People_Vaccinated_Full'))
#   
# 
# write.csv(county_vaccine, 'tableau/county_vaccine.csv', row.names = FALSE)
# write.csv(demographics_vaccine, 'tableau/demographics_vaccine.csv', row.names = FALSE)
```

## vaccine providers

```{r}
download.file('https://genesis.soc.texas.gov/files/accessibility/vaccineprovideraccessibilitydata.csv', mode = 'wb', 
              glue('original-sources/historical/vaccine-providers/vaccination-providers_{date_out}.csv'))
```

## vaccines zip

```{r}
temp = tempfile()
download.file('https://dshs.texas.gov/coronavirus/TexasCOVID19VaccinesbyZIP.xlsx',
              temp, mode = 'wb') 
vaccines_zip = read_excel_allsheets(temp, col_option = FALSE)

vaccine_date = vaccines_zip[[1]] %>% slice(1) %>% select(2) %>% Date_Parser()

if (!is.na(vaccine_date)) {

vaccines_zip_out = vaccines_zip[[2]] %>% 
  setNames(c('ZIP', 'Doses_Administered', 'At_Least_One_Dose', 'Fully_Vaccinated')) %>% 
  mutate_all(as.numeric) %>% 
  filter(!is.na(ZIP)) %>% 
  mutate(Date = vaccine_date) %>% 
  select(Date, ZIP, everything())
write_csv(vaccines_zip_out, glue('original-sources/historical/vaccine-zip/vaccination-zip_{date_out}.csv'))
}


zip_archive = list.files(glue('original-sources/historical/vaccine-zip'), full.names = TRUE)

vaccines_zip_all = rbindlist(lapply(zip_archive, read_csv), fill = TRUE) %>% distinct() %>% 
  mutate(Date = as.Date(Date))

write_csv(vaccines_zip_all, 'tableau/zip_vaccine.csv')
```



## vaccine dashboard

```{r}
# TODO: update to only run when its monday and the files are new 
vax_dir = 'original-sources/historical/vax-dashboard'
date_modified = list.files(glue('{vax_dir}/temp/allocation'), full.names = TRUE)[1] %>%
  file.info() %>%
  .[['ctime']] %>%
  as.Date(.)

if (format(date_out, '%A') == 'Monday' & (date_out - date_modified == -1)) {
  vax_allocation = rbindlist(lapply(list.files(glue('{vax_dir}/temp/allocation/'), full.names = TRUE),
                                read.csv, fileEncoding="UTF-16LE", sep = '\t'),
                         fill = TRUE) %>%
    filter(X != 'DosesAllocatedWindow along Week No' & 
           X != 'SumDosesAllocated (copy)') %>%
    dplyr::select(-X) %>%
    reshape2::melt(id = c('Allocation.Week.Range', 'CountyNameDisplay', 'Dose.Number..group.')) %>%
    dplyr::select(-variable) %>%
    setNames(c('Date', 'County', 'Dose', 'Count')) %>%
    mutate(Count = ifelse(Count == '', NA, Count)) %>%
    mutate(Count = as.numeric(gsub(',', '', Count))) %>%
    na.omit() %>%
    mutate(County = gsub(' County', '', County)) %>%
    filter(County != 'Texas') %>%
    mutate(Date = as.Date(Date, '%m/%d/%Y')) %>%
    reshape(idvar = c('Date', 'County'), timevar = 'Dose', direction = 'wide') %>%
    rename('Doses_Allocated_1' = `Count.First Doses`,
           'Doses_Allocated_2' = `Count.Second Doses`) %>%
    group_by(Date, County) %>%
    mutate(Doses_Allocated_1 = sum(Doses_Allocated_1, `Count.Federal Programs, First Doses`, na.rm = TRUE)) %>% 
    dplyr::select(Date, County, Doses_Allocated_1, Doses_Allocated_2)

  vax_admin = rbindlist(lapply(list.files(glue('{vax_dir}/temp/admin/'), full.names = TRUE),
                                read.csv, fileEncoding="UTF-16LE", sep = '\t'),
                         fill = TRUE) %>%
    reshape2::melt(id = c('Week.Start.End', 'CountyNameDisplay')) %>%
    dplyr::select(-variable) %>%
    setNames(c('Date', 'County', 'Doses_Administered')) %>%
    mutate(Doses_Administered) %>%
    mutate(Doses_Administered = as.numeric(gsub(',', '', Doses_Administered))) %>%
    na.omit() %>%
    mutate(County = gsub(' County', '', County)) %>%
    mutate(Date = str_extract(Date, '\\- (.*)')) %>%
    mutate(Date = gsub('- ', '', Date)) %>%
    mutate(Date = as.Date(Date, '%m/%d/%Y'))

## FULL
  demo_archive = list.files(glue('{vax_dir}/archive/'), full.names = TRUE)
  
  age_archive = rbindlist(lapply(demo_archive %>% .[str_detect(., 'age')], read_csv), fill = TRUE) %>% distinct()
  race_archive = rbindlist(lapply(demo_archive %>% .[str_detect(., 'race')], read_csv), fill = TRUE) %>% distinct()
  
  vax_age_full = rbindlist(lapply(list.files(glue('{vax_dir}/temp/demo_age_full/'), full.names = TRUE),
                                  read.csv, fileEncoding="UTF-16LE", sep = '\t'),
                           fill = TRUE) %>%
    dplyr::select(X, X.1, X.3, People.Vaccinated) %>%
    reshape2::melt(id = c('X', 'X.1', 'X.3')) %>%
    dplyr::select(-variable) %>%
    setNames(c('Age', 'County', 'Gender', 'Fully_Vaccinated')) %>%
    mutate(Date = max(vax_admin$Date)) %>%
    mutate(County = gsub(' County', '', County)) %>%
    dplyr::select(Date, County, everything()) %>% 
    mutate(Date = as.Date(Date)) %>%
    mutate(Fully_Vaccinated = as.numeric(gsub(',', '', Fully_Vaccinated))) %>%
    arrange(Date, County)


  Read_Race = function(x) {
    county_name = str_match(x, '\\/race_(.*)\\.csv')[2]
    x_out = read.csv(x, fileEncoding="UTF-16LE", sep = '\t') %>%
              mutate(County = county_name)
    return(x_out)
    }


  vax_race_full = rbindlist(lapply(list.files(glue('{vax_dir}/temp/demo_race_full/'), full.names = TRUE),
                               Read_Race),
                         fill = TRUE) %>%
    setNames(c('Race', 'dump1', 'Fully_Vaccinated', 'dump2', 'County')) %>%
    mutate(Date = max(vax_admin$Date)) %>%
    dplyr::select(Date, County, Race, Fully_Vaccinated, -dump1, -dump2) %>% 
    mutate(Date = as.Date(Date)) %>%
    mutate(Fully_Vaccinated = as.numeric(gsub(',', '', Fully_Vaccinated))) %>%
    arrange(Date, County)

  
# PARTIAL
  vax_age_partial = rbindlist(lapply(list.files(glue('{vax_dir}/temp/demo_age_partial/'), full.names = TRUE),
                                  read.csv, fileEncoding="UTF-16LE", sep = '\t'),
                           fill = TRUE) %>%
    dplyr::select(X, X.1, X.3, People.Vaccinated) %>%
    reshape2::melt(id = c('X', 'X.1', 'X.3')) %>%
    dplyr::select(-variable) %>%
    setNames(c('Age', 'County', 'Gender', 'At_Least_One_Vaccinated')) %>%
    mutate(Date = max(vax_admin$Date)) %>%
    mutate(County = gsub(' County', '', County)) %>%
    dplyr::select(Date, County, everything()) %>% 
    mutate(Date = as.Date(Date)) %>%
    mutate(At_Least_One_Vaccinated = as.numeric(gsub(',', '', At_Least_One_Vaccinated))) %>%
    arrange(Date, County)


  vax_race_partial = rbindlist(lapply(list.files(glue('{vax_dir}/temp/demo_race_partial/'), full.names = TRUE),
                               Read_Race),
                         fill = TRUE) %>%
    setNames(c('Race', 'dump1', 'At_Least_One_Vaccinated', 'dump2', 'County')) %>%
    mutate(Date = max(vax_admin$Date)) %>%
    dplyr::select(Date, County, Race, At_Least_One_Vaccinated, -dump1, -dump2) %>% 
    mutate(Date = as.Date(Date)) %>%
    mutate(At_Least_One_Vaccinated = as.numeric(gsub(',', '', At_Least_One_Vaccinated))) %>%
    arrange(Date, County)
 
  vax_age = vax_age_full %>% 
    left_join(vax_age_partial, by = c('County', 'Date', 'Age', 'Gender')) %>% 
    plyr::rbind.fill(age_archive) %>% 
    arrange(County, Date)
  
  vax_race = vax_race_full %>% 
    left_join(vax_race_partial, by = c('County', 'Date', 'Race')) %>% 
    plyr::rbind.fill(race_archive) %>% 
    arrange(County, Date)

  pop_files = list.files('original-sources/historical/vaccinations/', full.names = TRUE)

  vax_pop_counts = read_xlsx(pop_files[length(pop_files)], sheet = 2) %>%
    dplyr::select(1, 7, 8, 9, 10, 11) %>%
      setNames(c('County',
                 'Population_Over_16', 'Population_Over_65',
                 'Population_Phase_1A_Healthcare',
                 'Population_Phase1A_Care_Residents',
                 'Population_Phase_1B_Medical_Condition', 'Date')) %>%
      filter(!(County %in% c('Texas', '*Other', 'Federal Long-Term Care Vaccination Program')))
  
  vax_out = vax_allocation %>% 
    full_join(vax_admin, by = c('Date', 'County')) %>% 
    left_join(vax_pop_counts, by = 'County') %>% 
    full_join(vax_age_partial %>% 
                group_by(Date, County) %>%
                summarize(At_Least_One_Vaccinated = sum(At_Least_One_Vaccinated, na.rm = TRUE))) %>% 
    full_join(vax_age_full %>% 
                group_by(Date, County) %>%
                summarize(Fully_Vaccinated = sum(Fully_Vaccinated, na.rm = TRUE))) %>% 
    dplyr::select(Date, County, Doses_Allocated_1, Doses_Allocated_2,
                  Doses_Administered, At_Least_One_Vaccinated, Fully_Vaccinated,
                  everything())

  
  write.csv(vax_out, 'tableau/county_vaccine.csv', row.names = FALSE)
  write.csv(vax_age, 'tableau/demographics_vax_age.csv', row.names = FALSE)
  write.csv(vax_age %>% filter(Date == max(Date)),
            glue('{vax_dir}/archive/{max(vax_admin$Date)}_demographics_vax_age.csv'), row.names = FALSE)
  write.csv(vax_race, 'tableau/demographics_vax_race.csv', row.names = FALSE)
  write.csv(vax_race %>% filter(Date == max(Date)),
            glue('{vax_dir}/archive/{max(vax_admin$Date)}_demographics_vax_race.csv'), row.names = FALSE)

}
```




# TSA LEVEL

## Computed

```{r}
# longitudinal counts (sum)
DSHS_tsa_counts =
    merged_county %>%
    group_by(Date, TSA, TSA_Name) %>% 
    summarize_at(vars(Cases_Cumulative, Cases_Daily,
                      Deaths_Cumulative, Deaths_Daily,
                      Tests_Cumulative, Tests_Daily,
                      Active_Cases_Cumulative, Active_Cases_Daily),
                 funs(sum))

# static pop counts (sum)
DSHS_tsa_pops = 
  subset(merged_county, Date == '2020-03-04') %>%
  group_by(TSA) %>%
  summarize_at(vars(Population_DSHS),
               funs(sum))

# longitudinal google data (mean)
DSHS_tsa_google = 
  merged_county %>%
  group_by(Date, TSA, TSA_Name) %>%
  summarize_at(vars(Retail_Recreation, Grocery_Pharmacy,
                    Parks, Transit,
                    Workplaces, Residential),
               funs(weighted.mean(., Population_DSHS)), na.rm = TRUE)

DSHS_tsa = merge(DSHS_tsa_counts, DSHS_tsa_google, by = c('Date', 'TSA', 'TSA_Name'))
DSHS_tsa = merge(DSHS_tsa, DSHS_tsa_pops, by = 'TSA', all = TRUE)
```

## DSHS hospitals

```{r}
hosp_url = 'https://dshs.texas.gov/coronavirus/CombinedHospitalDataoverTimebyTSA.xlsx'
temp = tempfile()

download.file(hosp_url, temp, mode = 'wb') 
DSHS_tsa_hosp = read_excel_allsheets(temp)
 
DSHS_hosp_clean = function(df, var_name) { 
  names(df) = df[1, ]
  df = df[2:23, c(1, 3:ncol(df))]
  df$`TSA ID` = gsub('.', '', df$`TSA ID`, fixed = TRUE)

  # add temp fix for DSHS duplicated dates (8/8) (fixed by DSHS 8/10)
  # TODO: add dynamic handling
  if (length(grep('.x', names(df)) > 0)) { 
    df = df[, -grep('.x', names(df))]
    names(df) = gsub('.y', '', names(df))
  }

  # TODO: make date conversion function
  dates = names(df)[2:length(names(df))]
  numeric_dates = which(is.na(as.Date(dates, format = '%Y-%m-%d')))
  
  # convert from 5 digit excel numeric format
  # https://stackoverflow.com/questions/43230470/how-to-convert-excel-date-format-to-proper-date-in-r
  dates[numeric_dates] = format(as.Date(as.integer(dates[numeric_dates]), origin = '1899-12-30'))
  dates[-numeric_dates] = format(as.Date(dates[-numeric_dates]), '%Y-%m-%d')
  names(df)[2:length(names(df))] = dates

  df_long = reshape::melt(df, id = 'TSA ID')
  names(df_long) = c('TSA', 'Date', var_name)
  df_long$Date = as.Date(df_long$Date)
  
  if(length(which(df_long$Date == '2008-08-08')) > 0) {
    df_long$Date[which(df_long$Date == '2008-08-08')] = as.Date('2020-08-08')
  }
  
  return(df_long)
}
# 1,2,3 references the 3 sheets produced by DSHS
hosp_1 = DSHS_hosp_clean(DSHS_tsa_hosp[[1]], 'Hospitalizations_Total')
hosp_2 = DSHS_hosp_clean(DSHS_tsa_hosp[[8]], 'Hospitalizations_General')
hosp_3 = DSHS_hosp_clean(DSHS_tsa_hosp[[9]], 'Hospitalizations_ICU')
hosp_cap1 = DSHS_hosp_clean(DSHS_tsa_hosp[[4]], 'Beds_Available_Total')
hosp_cap2 = DSHS_hosp_clean(DSHS_tsa_hosp[[5]], 'Beds_Available_ICU')
hosp_cap3 = DSHS_hosp_clean(DSHS_tsa_hosp[[10]], 'Beds_Occupied_Total')
hosp_cap4 = DSHS_hosp_clean(DSHS_tsa_hosp[[11]], 'Beds_Occupied_ICU')
```

## DSHS dashboard

```{r}
# pull DSHS dashboard data using link found from inspect element -> network
DSHS_json_hosp_tsa = jsonlite::fromJSON("https://services5.arcgis.com/ACaLB9ifngzawspq/arcgis/rest/services/DSHS_COVID_Hospital_Data/FeatureServer/0/query?f=json&where=1%3D1&returnGeometry=false&spatialRel=esriSpatialRelIntersects&outFields=*&outSR=102100&resultOffset=0&resultRecordCount=25&resultType=standard&cacheHint=true")[['features']][['attributes']]

DSHS_json_hosp_tsa = DSHS_json_hosp_tsa[, c(2,5:9)]
# 
names(DSHS_json_hosp_tsa) = c('TSA', 'Hospital_Beds_Staffed', 'Hospital_Beds_Available',
                                 'ICU_Beds_Available', 'Ventilators_Available', 'Current_Cases')

# export today's file
write.csv(DSHS_json_hosp_tsa, paste0('original-sources/historical/hosp/tsa_hosp_', date_out, '.csv'),
          row.names = FALSE)

# read in all files
hosp_list = list.files('original-sources/historical/hosp', pattern = '*.csv', full.names = TRUE)
hosp_dates = sapply(hosp_list, function(x) str_extract(x, '\\d{4}-\\d{2}-\\d{2}'))
tsa_all_hosp = lapply(hosp_list, read.csv, fileEncoding = 'UTF-8-BOM')
names(tsa_all_hosp) = hosp_dates

tsa_combined_hosp = rbindlist(tsa_all_hosp, fill = TRUE, idcol = TRUE) %>% 
  dplyr::select(-Date) %>% 
  rename(Date = .id) %>% 
  dplyr::select(TSA, Date, Ventilators_Available)
```

## merge

```{r}
merged_tsa = Reduce(function(x, y) merge(x, y, by = c('Date', 'TSA'), all = TRUE),
                    list(DSHS_tsa, tsa_combined_hosp,
                         hosp_1, hosp_2, hosp_3,
                         hosp_cap1, hosp_cap2, hosp_cap3, hosp_cap4))

# fix types & ensure TSA values are valid
merged_tsa = merged_tsa %>% 
  mutate_at(vars(Beds_Available_Total, Beds_Available_ICU, Ventilators_Available,
                 Beds_Occupied_Total, Beds_Occupied_ICU, Hospitalizations_Total,
                 Hospitalizations_General, Hospitalizations_ICU),
            funs(as.character)) %>%
  mutate_at(vars(Beds_Available_Total, Beds_Available_ICU, Ventilators_Available,
                 Beds_Occupied_Total, Beds_Occupied_ICU, Hospitalizations_Total,
                 Hospitalizations_General, Hospitalizations_ICU),
            funs(as.integer)) %>%
  mutate(TSA_Combined = paste0(TSA, ' - ', TSA_Name)) %>%
  filter(!is.na(TSA) & !is.na(Date)) %>% 
  distinct()
```


# STATE LEVEL

```{r}
state_url = 'https://www.dshs.state.tx.us/coronavirus/TexasCOVID19CaseCountData.xlsx'
temp = tempfile()
download.file(state_url, temp, mode = 'wb')
dshs_header = names(read_excel(temp, sheet = 1)[1])

current_year =  substr(Sys.Date(), 1, 4)
dshs_date = paste0(current_year, '/',  str_extract_all(dshs_header, '\\d*\\/\\d*')[[1]])
dshs_date = format(as.Date(dshs_date), '%Y_%m_%d')

# save state level file to historical database for longitudinal demo
download.file(state_url, paste0('original-sources/historical/state/dshs_',
                                dshs_date, '.xlsx'), mode = 'wb')
```

## DSHS Demographics

## POST 12/11 DEMOGRAPHIC SCRAPING 

```{r}

Clean_Demographics = function(index) {

  group_conversion =  c('Age', 'Gender', 'Race')
  
  case_df = weekly_demo[[index]] %>%
    select(1:2) %>%
    setNames(c('Group', 'Cases_Cumulative')) %>%
    filter(!Group %in% c('Pending DOB', 'Total', 'Unknown', 'Grand Total')) %>%
    mutate(Date = date_out) %>%
    mutate(Group_Type = group_conversion[index]) %>%
    group_by(Date) %>%
    mutate(Cases_PCT = Cases_Cumulative / sum(Cases_Cumulative)) %>%
    dplyr::select(Date, Group_Type, Group, Cases_Cumulative, Cases_PCT)

  death_df = weekly_demo[[index + 3]] %>% 
    select(1:2) %>%
    setNames(c('Group', 'Deaths_Cumulative')) %>%
    filter(!Group %in% c('Pending DOB', 'Total', 'Unknown', 'Grand Total')) %>%
    mutate(Date = date_out) %>%
    mutate(Group_Type = group_conversion[index]) %>%
    group_by(Date) %>%
    mutate(Deaths_PCT = Deaths_Cumulative / sum(Deaths_Cumulative)) %>%
    dplyr::select(Date, Group_Type, Group, Deaths_Cumulative, Deaths_PCT)

  clean_df = merge(case_df, death_df, by = c('Date', 'Group_Type', 'Group'))
}

# TODO: add contingency if not posted on friday
demo_releases = seq(as.Date('2020-09-25'), by = 'week', length = 52)

if (date_out %in% demo_releases) {
  demo_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID19Demographics.xlsx.asp'
  temp = tempfile()
  download.file(demo_url, temp, mode = 'wb')
  weekly_demo = read_excel_allsheets(temp, tibble = FALSE, col_option = FALSE)
  download.file(demo_url, glue('original-sources/historical/demo-archive/demo_{date_out}.xlsx'))
  
  
  daily_demo_stack = rbindlist(lapply(seq(1,3), Clean_Demographics))
  write.csv(daily_demo_stack, paste0('original-sources/historical/demo/dshs_', date_out, '.csv'), row.names = FALSE)
}
```


### merge

```{r}
daily_demo_stack_all = rbindlist(lapply(list.files('original-sources/historical/demo/',
                                                   full.names = TRUE), read.csv)) %>% 
  mutate(Date = as.Date(Date))
  # distinct(Cases_Cumulative, Cases_PCT, Deaths_Cumulative, Deaths_PCT, .keep_all = TRUE)

legacy_demo = read.csv('original-sources/helpers/legacy_demographics.csv') %>% mutate(Date = as.Date(Date))

demo_stacked_combined = rbind(legacy_demo, daily_demo_stack_all) %>% 
  group_by(Group_Type, Group) %>% 
  mutate(Cases_Daily = as.numeric(c(Cases_Cumulative[1], diff(Cases_Cumulative)))) %>%
  mutate(Cases_Daily_NO_NEGATIVE = ifelse(Cases_Daily < 0, 0, Cases_Daily)) %>%
  mutate(Deaths_Daily = as.numeric(c(Deaths_Cumulative[1], diff(Deaths_Cumulative)))) %>%
  mutate(Deaths_Daily_NO_NEGATIVE = ifelse(Deaths_Daily < 0, 0, Deaths_Daily)) %>% 
  dplyr::select(Date, Group_Type, Group, Cases_Cumulative, Cases_PCT, Cases_Daily, Cases_Daily_NO_NEGATIVE, everything()) %>% 
  arrange(Date)
```


# OUTPUT

## Schools

```{r}
write.csv(nyt_schools, file = 'original-sources/historical/nyt/nyt_colleges.csv', row.names = F)
```

## County

```{r}
merged_county_out = merged_county %>% 
  dplyr::select(-c(Cases_Cumulative_NA, Deaths_Cumulative_NA,
                   Tests_Cumulative_NA, Active_Cases_Cumulative_NA))
write.csv(merged_county_out, 'tableau/county.csv', row.names = FALSE)
```

## TSA

```{r}
hosp_tsa = merged_tsa %>% 
  dplyr::select(Date, TSA, TSA_Name, TSA_Combined, Population_DSHS, Ventilators_Available,
                Hospitalizations_Total, Hospitalizations_General, Hospitalizations_ICU,
                Beds_Available_Total, Beds_Available_ICU, Beds_Occupied_Total, Beds_Occupied_ICU) %>% 
  filter(Date >= min(hosp_cap1$Date))
write.csv(hosp_tsa, file = 'tableau/hospitalizations_tsa.csv', row.names = F)
```

## Demographics

```{r}
write.csv(demo_stacked_combined, file = 'tableau/stacked_demographics.csv', row.names = FALSE)
```
