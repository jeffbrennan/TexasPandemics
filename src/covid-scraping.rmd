---
title: 'COVID Scraping'
author: 'Jeffrey Brennan'
output: html_document
editor_options: 
  chunk_output_type: console
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "diagnostics/",
                    knit_root_dir = "C:/Users/jeffb/Desktop/Life/personal-projects/COVID") })
---

# SETUP

```{r, echo = FALSE}
# performance analysis 
# source: https://bookdown.org/yihui/rmarkdown-cookbook/time-chunk.html
all_times <- list()  # store the time for each chunk
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      now <<- Sys.time()
    } else {
      res <- difftime(Sys.time(), now)
      all_times[[options$label]] <<- res
    }
  }
}))
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(time_it = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = NA)
```

```{r, echo = FALSE}
refactor_version = '3'
```

```{r}
# data manipulation
library(tidyverse)
library(data.table)
library(readxl)
library(writexl)
library(stringr)
library(zoo)

library(lubridate)

library(ggpubr)

# web scraping
library(rvest)
library(jsonlite)
library(glue)

select = dplyr::select
```

```{r}
# Grab every sheet from an excel file and convert to list of dataframes
# https://stackoverflow.com/questions/12945687/read-all-worksheets-in-an-excel-workbook-into-an-r-list-with-data-frames
read_excel_allsheets = function(filename, col_option = TRUE, add_date = FALSE, skip_option = 1) {
    sheets = readxl::excel_sheets(filename)
    x = lapply(sheets, function(X) read_excel(filename, sheet = X,
                                              skip = skip_option,
                                              col_names = col_option, na = '.'))
    names(x) = sheets
    x = lapply(x, as.data.frame)
    
    if (add_date == TRUE) { 
      file_date = str_extract(filename, '\\d.*\\d')
      x = lapply(x, function(z) return(mutate(z, Date = as.Date(file_date))))
    }
    return(x)
}

# set date for writing files
# If before 5 PM EST, then record as last date since DSHS data will not be updated yet
date_out = ifelse((Sys.time() < as.POSIXct(paste0(Sys.Date(), '15:45'), tz = 'America/Chicago')),
                   Sys.Date() - 1,
                   Sys.Date())

# convert numeric sys.date() to yyyy-mm-dd
date_out = as.Date(date_out, origin = '1970-1-1')


Fix_Num_Dates = function(dates) { 
  # TODO: add more checks for different int dates
  clean_dates = as.Date(as.numeric(dates), '1899-12-30')

  if (sum(is.na(clean_dates)) > 0) {
    clean_dates[which(is.na(clean_dates))] = as.Date(clean_dates[which(is.na(clean_dates))], origin = '1970-1-1')
  }
  return(format(clean_dates, '%Y-%m-%d'))
}
  
Fix_Char_Dates = function(dates) { 
  #Matches 2 or 4 digits, separator, 2 or 4 digits, optional separator, optional 2 or 4 digits
  # Coerces all common separators to "-" 
  date_regex = '(\\d{4}|\\d{2}|\\d{1})(\\.|\\-|\\/)(\\d{4}|\\d{2}|\\d{1})?(\\.|\\-|\\/)?(\\d{4}|\\d{2})'
  clean_dates = str_extract(dates, date_regex) %>% str_replace_all(., '\\/|\\.', '\\-')
  
  mdy_dates = which(!is.na(as.Date(clean_dates, format = '%m-%d-%y')))
  md_dates = which(is.na(as.Date(clean_dates, format = '%m-%d-%Y')))
  # if (length(mdy_dates) == length(md_dates)) { 
  #   md_dates = c()
  # }
  

  if (length(md_dates > 0)){
      md_dates_2020 = which(format(as.Date(clean_dates[md_dates], '%m-%d'), '%m') %in% as.character(seq(as.numeric(format(date_out, '%m')) + 1, 12)))
    
    if (length(md_dates_2020) > 0) { 
      clean_dates[md_dates[md_dates_2020]] = paste0('2020-', clean_dates[md_dates[md_dates_2020]])
      clean_dates[md_dates[-md_dates_2020]] = format(as.Date(clean_dates[md_dates[-md_dates_2020]],
                                                             '%m-%d'), '%Y-%m-%d')
    } else { 
      clean_dates[md_dates] = format(as.Date(clean_dates, '%m-%d'), '%Y-%m-%d')
    }
  }
  
  if (length(mdy_dates > 0)) { 
    clean_dates[mdy_dates] = format(as.Date(clean_dates[mdy_dates], '%m-%d-%Y'), '%Y-%m-%d')
  }

  return(clean_dates)
}


Date_Parser = function(raw_date) { 
  numeric_loc = which(!is.na(as.numeric(raw_date)))

    if (length(numeric_loc) == 0){
      clean_dates = Fix_Char_Dates(raw_date)
    } else {
      clean_num_date = Fix_Num_Dates(raw_date[numeric_loc])
      clean_char_date = Fix_Char_Dates(raw_date[-numeric_loc])
      clean_dates = sort(c(clean_num_date, clean_char_date))
    }
  return(clean_dates)
}

Download_Temp = function(url) { 
    temp = tempfile()
    download.file(url, temp, mode = 'wb')
    return(temp)
}
```

## Classifications

```{r}
# add metro and PHR code designations
# source: https://www.dshs.state.tx.us/chs/info/TxCoPhrMsa.xls
# add PHR readable names from https://dshs.texas.gov/regions/default.shtm
PHR_helper = data.frame(PHR = c("1", "2/3", "4/5N",
                                "6/5S", "7", "8",
                                "9/10", "11"),
                        PHR_Name = c('Lubbock PHR', 'Arlington PHR', 'Tyler PHR',
                                     'Houston PHR', 'Temple PHR', 'San Antonio PHR',
                                     'El Paso PHR', 'Harlingen PHR'))


county_classifications = read_xlsx('original-sources/helpers/county_classifications.xlsx', sheet = 1) %>% 
  slice(1:254) %>% 
  dplyr::select(1, 5, 8) %>%
  setNames(c('County', 'PHR', 'Metro_Area')) %>% 
  left_join(., PHR_helper, by = 'PHR') %>%
  mutate(PHR_Combined = paste0(PHR, ' - ', PHR_Name))
```

```{r}
# TSA levels
tsa_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID-19HospitalizationsOverTimebyTSA.xlsx'
temp = tempfile()
curl::curl_download(tsa_url, temp, mode = 'wb')
DSHS_tsa_names = readxl::read_xlsx(temp)[3:24, 1:2]

names(DSHS_tsa_names) = c('TSA', 'TSA_Name')

# drop . suffix from TSA codes
DSHS_tsa_names$TSA = gsub('.', '', DSHS_tsa_names$TSA, fixed = TRUE)

# get list of counties per TSA
tsa = read.csv('original-sources/helpers/tsa_list.csv', header = F)[-1]
tsa_long = reshape::melt(tsa, id = c('V2', 'V3'))
tsa_long_complete = subset(tsa_long, value != '')[, c(1, 4)] %>% 
  setNames(c('TSA', 'County')) %>%
  mutate(County = trimws(County)) %>% 
  left_join(DSHS_tsa_names, by = 'TSA') %>% 
  distinct() %>% 
  mutate(TSA_Combined = paste0(TSA, ' - ', TSA_Name))


dshs_pops =
  read_csv('https://raw.githubusercontent.com/jeffbrennan/COVID-19/d03d476f7fb060dfd2e1a600a6a1e449df0ab8df/original-sources/DSHS_county_cases.csv') %>%
  select(County, Population) %>%
  distinct() %>%
  rename(Population_DSHS = Population)
```

## County level demographics

### race

```{r}
# https://www.census.gov/data/datasets/time-series/demo/popest/2010s-counties-detail.html
# 2019 county level race estimates
# collapse into asian, black, hispanic, white, other 
# exclude totals to avoid double counting
  race_group_df = data.frame(race = 
                             c('AA', 'AAC', 'BA', 'BAC', 'H', 'HAA',
                               'HAAC', 'HBA', 'HBAC', 'HIA', 'HIAC', 'HNA',
                               'HNAC', 'HTOM', 'HWA', 'HWAC', 'IA', 'IAC',
                               'NA', 'NAC', 'NH', 'NHAA', 'NHAAC', 'NHBA', 'NHBAC',
                               'NHIA', 'NHIAC', 'NHNA', 'NHNAC', 'NHTOM', 'NHWA',
                               'NHWAC', 'TOM', 'WA', 'WAC'),
                           race_group = 
                             c(NA, NA, NA, NA, 'Hispanic', NA,
                               NA, NA, NA, NA, NA , NA,
                               NA, NA, NA, NA, NA, 'Other',
                               NA, 'Other', NA, 'Asian', NA, 'Black', NA,
                               NA, NA, NA, NA, NA, 'White',
                               NA, 'Other', NA, NA))


Get_County_Race = function(age_groups) { 
  county_demo_race_prelim = fread('original-sources/helpers/demographics/county/county_pop_race.csv') %>% 
  filter(YEAR == '12' & AGEGRP %in% age_groups) %>% 
  select(-c(SUMLEV, STATE, COUNTY, STNAME, YEAR, AGEGRP, TOT_POP, TOT_MALE, TOT_FEMALE)) %>% 
  reshape2::melt(idvars = 'CTYNAME') %>% 
  separate(variable, c('race', 'gender')) %>% 
  group_by(CTYNAME, race) %>% 
  summarize(Total = sum(value, na.rm = TRUE)) %>% 
  left_join(race_group_df) %>% 
  group_by(CTYNAME, race_group) %>% 
  summarize(Total = sum(Total, na.rm = TRUE)) %>% 
  filter(!is.na(race_group)) %>% 
  ungroup() %>% 
  mutate(CTYNAME = gsub(' County', '', CTYNAME)) %>% 
  setNames(c('County', 'Race/Ethnicity', 'Population_Total'))

  county_demo_other_race  = fread('original-sources/helpers/demographics/county/county_pop_race.csv') %>% 
  filter(YEAR == '12' & AGEGRP %in% age_groups) %>% 
  select(-c(SUMLEV, STATE, COUNTY, STNAME, YEAR, AGEGRP, TOT_POP, TOT_MALE, TOT_FEMALE)) %>% 
  reshape2::melt(idvars = 'CTYNAME') %>% 
  separate(variable, c('race', 'gender')) %>% 
  filter(race %in% c('AA', 'AAC', 'BA', 'BAC', 'NA', 'NAC', 'IA', 'IAC', 'WA', 'WAC')) %>% 
  group_by(CTYNAME, race) %>% 
  summarize(Total = sum(value, na.rm = TRUE)) %>% 
  mutate(Total_combo = Total-lag(Total)) %>% 
  filter(str_detect(race, 'C')) %>% 
  mutate(`Race/Ethnicity` = 'Other') %>% 
  mutate(CTYNAME = gsub(' County', '', CTYNAME)) %>% 
  select(CTYNAME, `Race/Ethnicity`, Total_combo) %>%
  setNames(c('County', 'Race/Ethnicity', 'Population_Total'))
  
  county_demo_race = rbind(county_demo_race_prelim, county_demo_other_race) %>%
    group_by(County, `Race/Ethnicity`) %>%
    summarize(Population_Total = sum(Population_Total)) %>%
    ungroup() %>%
    arrange(County, `Race/Ethnicity`)
  
  return(county_demo_race)
}

  
county_demo_race = Get_County_Race(c('0'))
county_demo_race_age_15 = Get_County_Race(as.character(seq(4, 18))) %>% rename('Population_16' = 'Population_Total')
county_demo_race_age_5 = Get_County_Race(as.character(seq(2, 18))) %>% rename('Population_5' = 'Population_Total')

503443 / county_demo_race %>%
  group_by(`Race/Ethnicity`) %>%
  summarize(sum(Population_Total)) %>%
  filter(`Race/Ethnicity` == 'Other') %>%
  select(2)

503443 / county_demo_race_age_15 %>%
  group_by(`Race/Ethnicity`) %>%
  summarize(sum(Population_16)) %>%
  filter(`Race/Ethnicity` == 'Other') %>%
  select(2)

# white
2499249 / 10034155
```


### age & sex

```{r}
# 2019 county level race estimates
# TODOl
age_lookup = data.frame(age =
                          c('POPEST', 'UNDER5', 'AGE513', 'AGE1417', 'AGE1824',
                            'AGE16PLUS', 'AGE18PLUS', 'AGE1544', 'AGE2544',
                            'AGE4564', 'AGE65PLUS', 'AGE04', 'AGE59', 'AGE1014',
                            'AGE1519', 'AGE2024', 'AGE2529', 'AGE3034', 'AGE3539',
                            'AGE4044', 'AGE4549', 'AGE5054', 'AGE5559', 'AGE6064',
                            'AGE6569', 'AGE7074', 'AGE7579', 'AGE8084', 'AGE85PLUS'),
                        age_group =
                          c('Total', NA, NA, NA, NA,
                            '16+', NA, NA, NA,
                            NA, NA, NA, NA, NA,
                            NA, NA, NA, NA, NA,
                            NA, NA, '50-64 years', '50-64 years', '50-64 years',
                            '65-79 years', '65-79 years', '65-79 years', '80+ years', '80+ years'))

demo_12_15 =  read_csv('original-sources/helpers/demographics/county/county_pop_age_sex.csv') %>%
  filter(YEAR == '12') %>% 
  select(-c(SUMLEV, STATE, COUNTY, STNAME, YEAR,
            POPESTIMATE,
            MEDIAN_AGE_TOT, MEDIAN_AGE_MALE, MEDIAN_AGE_FEM )) %>%
  reshape2::melt(idvars = 'CTYNAME') %>% 
  separate(variable, c('age', 'gender')) %>%
  filter(gender != 'TOT') %>% 
  filter(age %in% c('AGE1014', 'AGE1519')) %>% 
  mutate(value = ifelse(age == 'AGE1014', value * 0.6, value * 0.2)) %>% 
  group_by(CTYNAME, gender) %>% 
  summarize(Population_Total = round(sum(value), 0)) %>% 
  mutate(`Age Group` = '12-15 years') %>%
  rename(County = CTYNAME, Gender = gender)

demo_5_11 = read_csv('original-sources/helpers/demographics/county/county_pop_age_sex.csv') %>%
  filter(YEAR == '12') %>% 
  select(-c(SUMLEV, STATE, COUNTY, STNAME, YEAR,
            POPESTIMATE,
            MEDIAN_AGE_TOT, MEDIAN_AGE_MALE, MEDIAN_AGE_FEM )) %>%
  reshape2::melt(idvars = 'CTYNAME') %>% 
  separate(variable, c('age', 'gender')) %>%
  filter(gender != 'TOT') %>%
  filter(age == 'AGE513') %>% 
  mutate(value = ifelse(age == 'AGE513', value * (7/9), value)) %>% 
  group_by(CTYNAME, gender) %>% 
  summarize(Population_Total = round(sum(value), 0)) %>% 
  mutate(`Age Group` = '5-11 years') %>%
  rename(County = CTYNAME, Gender = gender)

county_demo_agesex = read_csv('original-sources/helpers/demographics/county/county_pop_age_sex.csv') %>%
  filter(YEAR == '12') %>% 
  select(-c(SUMLEV, STATE, COUNTY, STNAME, YEAR,
            POPESTIMATE,
            MEDIAN_AGE_TOT, MEDIAN_AGE_MALE, MEDIAN_AGE_FEM )) %>%
  reshape2::melt(idvars = 'CTYNAME') %>% 
  separate(variable, c('age', 'gender')) %>%
  filter(gender != 'TOT') %>% 
  left_join(age_lookup) %>% 
  group_by(CTYNAME, age_group, gender) %>% 
  summarize(Total = sum(value, na.rm = TRUE)) %>%
  filter(!is.na(age_group)) %>%
  spread(age_group, Total) %>%
  mutate('<16' = Total - `16+`) %>%
  mutate(`16-49 years` = `16+` - `50-64 years` - `65-79 years` - `80+ years`) %>% 
  select(-Total) %>% 
  reshape2::melt(idvars = c('CTYNAME', 'gender')) %>%
  setNames(c('County', 'Gender', 'Age Group', 'Population_Total')) %>% 
  rbind(demo_12_15) %>%
  rbind(demo_5_11) %>%
  mutate(County = gsub(' County', '', County)) %>% 
  mutate(Gender = recode(Gender, 'FEM' = 'Female', 'MALE' = 'Male'))
```

# Wastewater

```{r}


Scrape_Wastewater = function(data_type, offset='') {
  plant_url = glue('https://services.arcgis.com/lqRTrQp2HrfnJt8U/ArcGIS/rest/services/WWTP_gdb/FeatureServer/0//query?where=0%3D0&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=none&distance=0.0&units=esriSRUnit_Meter&returnGeodetic=false&outFields=*&returnGeometry=true&returnCentroid=false&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset={offset}&resultRecordCount=&returnZ=false&returnM=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pjson&token=')
  
  
  zip_url = glue('https://services.arcgis.com/lqRTrQp2HrfnJt8U/arcgis/rest/services/Wastewater_Zip_Case_Analysis/FeatureServer/0/query?where=1%3D1&objectIds=&time=&resultType=none&outFields=*&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnDistinctValues=false&cacheHint=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset={offset}&resultRecordCount=&sqlFormat=none&f=pjson&token=')
 
  
  
  url_selection = c('zip' = zip_url,
                    'plant' = plant_url)
  
  ww_df = jsonlite::fromJSON(url_selection[[data_type]])[['features']][['attributes']]
  
  if (length(ww_df) > 0) { 
  
    if(data_type == 'zip') { 
      out_df = ww_df %>%
        mutate(across(contains('date'), function(x) as_datetime(x/1000) %>% as_date())) %>%
        select(ZIPCODE, date, pop, contains('Spline'), contains('vax'))
        
    } else if (data_type == 'plant') { 
      out_df = ww_df %>%
        mutate(across(contains('date'), function(x) as_datetime(x/1000) %>% as_date())) %>%
        select(corname, date, vl_est, i_est_p, t_est, firstdate, lastdate, v1_est, v2_est, spline_ww) %>%
        rename(Plant = corname,
           Date = date,
           Viral_Load_PCT = vl_est,
           p_value = i_est_p,
           Trend = t_est,
           Date_First = firstdate,
           Date_Last = lastdate,
           Viral_Copies_Log = spline_ww)
    }
  } else {
    return(list(NULL))
  }
  return(out_df)
}

ww_plant_df = rbindlist(lapply(c('', seq(2000, 10000, by = 2000)), function(x) Scrape_Wastewater('plant', offset=x)), fill = TRUE)
ww_zip_df = rbindlist(lapply(c('', seq(1000, 10000, by = 1000)), function(x) Scrape_Wastewater('zip', offset=x)), fill = TRUE)

fwrite(ww_plant_df, 'tableau/wastewater_plant.csv')
fwrite(ww_zip_df, 'tableau/wastewater_zip.csv')
```

# ww variant ocr

```{r}
# image path updates: https://services.arcgis.com/lqRTrQp2HrfnJt8U/ArcGIS/rest/services/Variants_Heatmaps_List/FeatureServer/0/query?where=0%3D0&objectIds=&time=&resultType=none&outFields=*&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnDistinctValues=false&cacheHint=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&sqlFormat=none&f=html&token=


# download
image_paths = c('omicron' = 'https://covidwwtp.spatialstudieslab.org/hhd/datasets/variants/B11529.png',
                'lambda' = 'https://covidwwtp.spatialstudieslab.org/hhd/datasets/variants/C37.png',
                'delta' = 'https://covidwwtp.spatialstudieslab.org/hhd/datasets/variants/B16172.png',
                'alpha' = 'https://covidwwtp.spatialstudieslab.org/hhd/datasets/variants/B117.png')

sapply(names(image_paths), function(x) download.file(image_paths[[x]], glue('original-sources/historical/wastewater-variants/{x}_{date_out}.png'), mode = 'wb'), USE.NAMES = TRUE)
# ocr

# delta
library(magick)
library(tesseract)
img_crop = image_read("original-sources/historical/wastewater-variants/delta_2022-01-14.png") %>% 
  image_crop(geometry_area(0,0,-690,120)) %>% 
  image_crop(geometry_area(0,0, 10, -190))


data = img_crop %>% 
  geometry_area()


data



```



## diagnostics
```{r}
max(ww_zip_df$date)

# matches
ww_zip_df %>% 
  filter(ZIPCODE %in% c('77085', '77029') & date == '2022-01-03') %>% 
  select(ZIPCODE, date, Spline_WW_weight)


```



# SCHOOL LEVEL

```{r}
# school files are small (~ 6kb - read every time and don't overwrite)
nyt_schools = rbindlist(lapply(list.files('original-sources/historical/nyt/archive', full.names = TRUE), read.csv)) %>% 
  setNames(c('School', 'City', 'County', 'Deaths_Cumulative', 'Cases_Cumulative', 'Date')) %>%
  mutate(Date = as.Date(Date)) %>% 
  mutate(Cases_Cumulative = ifelse(Cases_Cumulative == -1, NA, Cases_Cumulative))

write.csv(nyt_schools, file = 'original-sources/historical/nyt/nyt_colleges.csv', row.names = F)
```

### Current

```{r}
# # Retains only district level data (filters for rows containing total)
Clean_DSHS_Schools = function(df) {
  df_out = df %>%
    select(1:11) %>%
    setNames(c('District', 'LEA', 'District_Total_Enrollment',
            'Campus', 'Campus_ID', 'School_Total_Enrollment',
            'Cases_Student_New', 'Cases_Staff_New',
            'Case_Source_Campus', 'Case_Source_OffCampus', 'Case_Source_Unknown')) %>%
    select(-contains('School')) %>%
    filter(str_detect(District, 'TOTAL')) %>%
    mutate(District = str_squish(District)) %>%
    mutate(District = gsub(' TOTAL', '', District)) %>%
    mutate(Date = school_date) %>%
    relocate(Date, .after=District) %>%
    mutate(across(matches('Case'), as.numeric)) %>%
    mutate(across(c(LEA, Campus_ID), ~gsub("'", '', .)))
  }

current_school_dates = seq(as.Date('2021-08-15'), by = 'week', length = 200)
school_date = max(current_school_dates[which(current_school_dates <= date_out - 5)])
base_url = 'https://dshs.texas.gov/chs/data/tea/district-level-school-covid-19-case-data/campus-level-data_'

DSHS_schools <- glue('{base_url}{format(school_date+2, "%Y%m%d")}v1.xls') %>%
  Download_Temp(.) %>%
  read_excel(sheet = 1) %>%
  data.frame() %>% 
  Clean_DSHS_Schools(.) %>% 
  try()

if (class(DSHS_schools) != 'try-error') {
   write_csv(DSHS_schools,
             file = glue('./original-sources/historical/dshs-schools/2021/{school_date}_DSHS_schools.csv'))
}
```


## Combine

```{r}
DSHS_schools_2021 = list.files('./original-sources/historical/dshs-schools/2021/', full.names = TRUE) %>% 
  lapply(., read_csv) %>% 
  rbindlist(fill = TRUE) 

DSHS_schools_archive = read_csv('./original-sources/historical/dshs-schools/historical_archive.csv')

DSHS_schools_combined = DSHS_schools_2021 %>%
  plyr::rbind.fill(DSHS_schools_archive) %>% 
  arrange(District, Date)


write_xlsx(
  list('school_data' = DSHS_schools_combined,
       'helper' = read.csv('original-sources/helpers/county_isd_long.csv')),
  'tableau/district_school_reopening.xlsx',
  format_headers = FALSE
  )
```

# COUNTY LEVEL

## CDC Community Levels

```{r}
cdc_community_json = fromJSON('https://www.cdc.gov/coronavirus/2019-ncov/modules/science/us_community_burden_by_county.json')

cdc_community_date =  as.Date(str_extract(cdc_community_json[['dataFileName']], '\\d{8}'), '%Y%m%d')

cdc_community_levels = cdc_community_json %>% 
  .[['data']] %>% 
  filter(State == 'Texas') %>% 
  mutate(Date = cdc_community_date) %>% 
  mutate(across(contains(' - '), ~str_replace(., '\\%', ''))) %>% 
  mutate(across(contains(' - '), as.numeric)) %>% 
  mutate(County = str_replace(County,', Texas, US', '')) %>% 
  select(-FIPS, -State) %>% 
  relocate(Date, .before = 'County') %>% 
  rename_with(~str_replace(., ., 'inpatient_bed_utilization'), contains('Inpatient')) %>% 
  rename_with(~str_replace(., ., 'admissions_100k'), contains('Admissions')) %>% 
  rename_with(~str_replace(., ., 'cases_100k'), contains('Cases per')) %>% 
  rename_with(~str_replace(., ., 'cases_7day_MA'), contains('Transmission Level - Cases')) %>% 
  rename_with(~str_replace(., ., 'TPR'), contains('Positivity')) %>%
  rename_with(~str_replace(., ., 'transmission_level'), contains('Transmission')) %>%
  rename_with(~str_replace(., ., 'community_level'), contains('Community'))


fwrite(cdc_community_levels, 
       glue('original-sources/historical/cdc-levels/{cdc_community_date}_cdc_community_level.csv')
      )
```


## Google mobility

```{r}
# fread for faster processing
# mobility_data = fread('https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv')
# 11/7/21: stop acquring new mobility data

mobility_data = fread('original-sources/historical/google/mobility.csv')
```

```{r}
mobility_texas = mobility_data %>%
  filter(sub_region_1 == 'Texas') %>%
  dplyr::select(sub_region_2, date,
                retail_and_recreation_percent_change_from_baseline,
                grocery_and_pharmacy_percent_change_from_baseline,
                parks_percent_change_from_baseline,
                transit_stations_percent_change_from_baseline,
                workplaces_percent_change_from_baseline,
                residential_percent_change_from_baseline) %>%
  setNames(c('County', 'Date', 'Retail_Recreation', 'Grocery_Pharmacy',
             'Parks', 'Transit', 'Workplaces', 'Residential')) %>%
  mutate(County =  sub('^$', 'Unallocated', County)) %>%
  mutate(County = as.factor(gsub(' County', '', County))) %>%
  filter(County != 'Unallocated') %>%
  mutate(Date = as.Date(Date))

# # drop cols
# mobility_texas = mobility_texas[, -c(1:3, 5:7)]
#
# # fix colnames
names(mobility_texas) = c('County', 'Date', 'Retail_Recreation', 'Grocery_Pharmacy',
                             'Parks', 'Transit', 'Workplaces', 'Residential')
#
# # Add name for blank county cells & drop 'county' suffix
mobility_texas$County = sub('^$', 'Unallocated', mobility_texas$County)
mobility_texas$County = gsub(' County', '', mobility_texas$County)
#
# # drop blank cells
mobility_texas = subset(mobility_texas, County != 'Unallocated')
#
# #fix types
mobility_texas$County = as.factor(mobility_texas$County)
mobility_texas$Date = as.Date(mobility_texas$Date)
```

## cases

```{r}
Clean_Vitals = function(df, data_type) { 
  
  df_out = df %>%
    filter(County %in% unique(county_demo_agesex$County)) %>%
    reshape2::melt('County') %>% 
    setNames(c('County', 'Date', data_type)) %>%
    filter(!Date %in% c('Total', 'Unknown Date')) %>% 
    mutate_all(as.character) %>% 
    mutate(Date = Date_Parser(Date)) %>%
    mutate_at(3, as.numeric) %>%
    # mutate('{data_type}' := ifelse('{data_type}' < 0, 0, '{data_type}')) %>%
    arrange(Date, County)
}
# download xlsx as tempfile and load using readxl
case_url = 'http://dshs.texas.gov/coronavirus/TexasCOVID19DailyCountyCaseCountData.xlsx'
temp = tempfile()
curl::curl_download(case_url, temp, mode = 'wb') 
DSHS_cases = read_excel_allsheets(temp, skip = 2)

DSHS_cases_long =  lapply(DSHS_cases, function(x) Clean_Vitals(x, 'Cases_Cumulative')) %>% 
  rbindlist() %>%
  mutate(Date = as.Date(Date)) %>%
  mutate(Cases_Cumulative = as.integer(as.character(Cases_Cumulative))) %>% 
  group_by(County) %>%
  tidyr::complete(Date = seq.Date(min(Date), date_out, by="day")) %>%
  mutate(Cases_Cumulative_NA = Cases_Cumulative) %>% 
  tidyr::fill(Cases_Cumulative, .direction = "down")
```

## deaths

```{r}
death_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID19DailyCountyFatalityCountData.xlsx'
temp = tempfile()
curl::curl_download(death_url, temp, mode = 'wb') 


DSHS_deaths = read_excel_allsheets(temp, skip = 2)

DSHS_deaths_long = lapply(DSHS_deaths, function(x) Clean_Vitals(x, 'Deaths_Cumulative')) %>% 
  rbindlist() %>%
  mutate(Date = as.Date(Date)) %>%
  group_by(County) %>%
  tidyr::complete(Date = seq.Date(min(Date), date_out, by="day")) %>%
  mutate(Deaths_Cumulative_NA = Deaths_Cumulative) %>%
  tidyr::fill(Deaths_Cumulative, .direction = "down") %>%
  mutate(Deaths_Daily = c(Deaths_Cumulative[1], diff(Deaths_Cumulative))) %>% 
  ungroup()
```

## testing

```{r}
# LEGACY
legacy_tests_long = read.csv('original-sources/historical/testing/DSHS_county_tests_legacy_cleaned.csv') %>% 
  mutate(Date = as.Date(Date))

# NEW
test_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID-19CumulativeTestsbyCounty.xlsx'
temp = tempfile()
curl::curl_download(test_url, temp, mode = 'wb')

DSHS_tests = read_excel_allsheets(temp, skip = 1)

DSHS_tests_long = lapply(DSHS_tests, function(x) Clean_Vitals(x, 'Tests_Cumulative')) %>% 
  rbindlist() %>% 
  mutate(Date = as.Date(Date))

new_tests = data.frame(readxl::read_excel(temp, sheet = 1, skip = 1))
new_tests_long = new_tests %>% 
  filter(str_detect(County, 'County|Unknown|Total', negate = TRUE)) %>% 
  reshape::melt(id = 'County') %>% 
  setNames(c('County', 'Date', 'Tests_Cumulative')) %>% 
  mutate(Date = as.Date(as.integer(Date), '2020-09-12'))

# MERGE
merged_tests = rbind(legacy_tests_long, new_tests_long)

DSHS_tests_long = merged_tests %>%
  group_by(County) %>% 
  tidyr::complete(Date = seq.Date(min(Date), date_out, by="day")) %>%
  mutate(Tests_Cumulative_NA = Tests_Cumulative) %>%
  tidyr::fill(Tests_Cumulative, .direction = "down") %>%
  mutate(Tests_Daily = c(Tests_Cumulative[1], diff(Tests_Cumulative))) %>% 
  distinct()
```

## new cases

```{r}
# MANUALLY ADD MONTGOMERY CASES PER MISTI WILLINGHAM (11/20)
# 11/1 - 11/20 [manual entry] | 11/21 DSHS value
montgomery_new_cases = c(32, 61, 78, 110, 98, 124, 78, 77, 144, 97, 146, 133, 124, 103, 90, 109, 33, 3, 330, 162, 484)
montgomery_case_dates = seq(as.Date('2020-11-01'), as.Date('2020-11-21'), by = 'day')

new_case_url ='https://dshs.texas.gov/coronavirus/TexasCOVID-19NewCasesOverTimebyCounty.xlsx'
temp = tempfile()
curl::curl_download(new_case_url, temp, mode = 'wb') 
DSHS_new_cases = read_excel_allsheets(temp, skip = 2)

DSHS_new_cases_long = lapply(DSHS_new_cases, function(x) Clean_Vitals(x, 'Cases_Daily')) %>% 
  rbindlist() %>% 
  mutate(Cases_Daily = replace(Cases_Daily,
                               County == 'Montgomery' & Date %in% montgomery_case_dates,
                               montgomery_new_cases)) %>%
  mutate(Date = as.Date(Date)) %>%
  arrange(Date, County)
```

### diagnostics

```{r}
# DSHS_new_cases_long %>% 
#   filter(County == 'Harris') %>% 
#   filter(Date >= date_out-7)
```

## active cases

```{r}
old_active_cases_long = read.csv('original-sources/historical/active-cases/active_case_archive.csv') %>% 
  mutate(Date = as.Date(Date))


# current
new_case_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID-19ActiveCaseDatabyCounty.xlsx'
temp = tempfile()
curl::curl_download(new_case_url, temp, mode = 'wb') 
new_active_cases = data.frame(readxl::read_excel(temp, sheet = 1, skip = 2)) %>%
  slice(which(County == 'Anderson'):nrow(.)) %>%
  dplyr::select(-Notes) %>% 
  filter(!is.na(County)) %>%
  select_if(function(x) all(!is.na(x)))

# names(new_active_cases)[2:ncol(new_active_cases)] = Date_Parser(names(new_active_cases)[2:ncol(new_active_cases)])


# melt
new_active_cases_long = reshape::melt(new_active_cases, id = 'County') %>% 
  setNames(c('County', 'Date', 'Active_Cases_Cumulative')) %>%
  group_by(Date) %>%
  mutate(Date = as.Date(paste(str_extract_all(Date, '\\d+')[[1]], collapse = ' '), '%m %d %y')) %>%
  ungroup() %>%
  group_by(County) %>% 
  distinct() %>%
  mutate(Active_Cases_Cumulative = as.integer(as.character(Active_Cases_Cumulative))) %>%
  tidyr::complete(Date = seq.Date(min(Date), date_out, by="day")) %>%
  mutate(Active_Cases_Cumulative_NA = Active_Cases_Cumulative) %>%
  tidyr::fill(Active_Cases_Cumulative, .direction = "down") %>%
  mutate(Active_Cases_Daily = c(Active_Cases_Cumulative[1], diff(Active_Cases_Cumulative))) %>%
  filter(!is.na(County))

DSHS_active_cases_long = rbind(old_active_cases_long, new_active_cases_long) %>% arrange(Date, County)
```


### merge

```{r}
# combine DSHS sources using merge helper function
# https://www.musgraveanalytics.com/blog/2018/2/12/how-to-merge-multiple-data-frames-using-base-r

county_counts = Reduce(function(x, y) merge(x, y, by = c('Date', 'County'), all=TRUE),
       list(DSHS_cases_long, DSHS_new_cases_long, DSHS_deaths_long, DSHS_tests_long,
            DSHS_active_cases_long)) %>% 
  filter(Date <= date_out)
```


## merge

```{r}
# DSHS pop - removed by DSHS 07/30 - defaulting to previous file
merged_dshs = Reduce(function(x, y) merge(x, y, by = 'County', all = TRUE),
                       list(county_counts, tsa_long_complete, dshs_pops, county_classifications))

# add TSA, PHR & HHSC combination
 merged_dshs$TSA_Combined = paste0(merged_dshs$TSA, ' - ', merged_dshs$TSA_Name)
merged_dshs$PHR_Combined = paste0(merged_dshs$PHR, ' - ', merged_dshs$PHR_Name)
# merged_dshs$HHSC_Combined = paste0(merged_dshs$HHSC, ' - ', merged_dshs$HHSC_Name)
# 
merged_county = as.data.frame(merge(merged_dshs, mobility_texas,
                                    by = c('Date', 'County'), all = TRUE)) %>%
  filter(!is.na(County) & County != 'Unknown')

# fix types
merged_county$County = as.factor(merged_county$County)
merged_county$Population_DSHS = as.numeric(merged_county$Population_DSHS)

# keep only relevant dates (previous dates include google mobility only)
merged_county = merged_county %>% 
  filter(Date >= as.Date('2020-03-06') & !is.na(County)) %>% 
  distinct() 


merged_county_out = merged_county %>% 
  dplyr::select(-c(Cases_Cumulative_NA, Deaths_Cumulative_NA,
                   Tests_Cumulative_NA, Active_Cases_Cumulative_NA))

write_csv(merged_county_out %>% arrange(County, Date), 'tableau/county.csv')
```

## TPR 

```{r}
Get_TPR = function() { 
  page = read_html('https://data.cms.gov/covid-19/covid-19-nursing-home-data')
  tpr_url = page %>% html_nodes('a') %>% html_attr('href') %>%
    .[grepl('download', .)] %>%
    .[1] %>% 
    gsub('%2F', '/', .)
  
  # temp dir needed for unzip to keep directory clean
  temp_dir = tempdir()
  temp_file = tempfile()
  curl::curl_download(tpr_url, temp_file, mode = 'wb')
  tpr_df = read_excel(unzip(temp_file, exdir = temp_dir)[[1]])
  tpr_date = Date_Parser(format(as.Date(str_match(tpr_df[2,2], '-(.*)')[2], '%B %d'), '%m-%d'))
  print(tpr_date)
  
  tpr_out = tpr_df %>% 
    setNames(.[which(tpr_df[, 1] == 'County'), ]) %>% 
    filter(State == 'TX') %>% 
    mutate(County = gsub(' County, TX', '', County)) %>% 
    dplyr::select(1, 7, 9) %>% 
    mutate_at(c(2,3), as.numeric) %>% 
    setNames(c('County', 'Tests', 'TPR_CMS')) %>% 
    mutate(Date = tpr_date) %>% 
    dplyr::select(County, Date, Tests, TPR_CMS)
  write.csv(tpr_out, paste0('original-sources/historical/cms_tpr/TPR_', tpr_date,  '.csv'),
            row.names = FALSE) 
  }
# Get_TPR()
# 7/22: No longer reporting TPR from this source
tpr_df = rbindlist(
         lapply(list.files('original-sources/historical/cms_tpr/', full.names = TRUE), read.csv),
         fill = TRUE) %>% 
         mutate(Date = as.Date(Date)) %>% 
  rename(TPR = TPR_CMS) %>%  
  mutate(TPR = ifelse(Date >= '2020-12-16', NA, TPR))
```


## TPR cpr

Source for TPR data post 12/16. Still use CMS tests and dates for case averages to keep % change section of stat analysis rmd the same

```{r}
# 11/25 - csv no longer available 
# get latest url
Clean_TPR = function(newest_file) { 
  file_date = as.Date(str_match(newest_file, '\\d{8}'), '%Y%m%d')
  file_url = paste0('https://beta.healthdata.gov', newest_file) %>% 
    str_replace(.,
                'https://beta.healthdata.govhttps://beta.healthdata.gov',
                'https://beta.healthdata.gov')
  
  temp = tempfile()
  download.file(file_url, temp, mode = 'wb')
  
  tpr_names =
    read_xlsx(temp, sheet = 6, skip = 0, n_max = 1) %>%
    dplyr::select(contains('TESTING: LAST WEEK')) %>%
    names()
  
  
  cpr_day = tpr_names %>%
    str_match(., '(\\d{1,2}),') %>%
    .[2] %>%
    as.numeric()
    
  cpr_month = tpr_names %>% 
    str_extract_all(., 'January|February|March|April|May|June|July|August|September|October|November|December') %>% 
    as.data.frame() %>% 
    setNames('Date') %>% 
    mutate(Date = as.Date(glue('{Date}-01-2022'), '%B-%d-%Y')) %>% 
    arrange(desc(Date)) %>% 
    slice(1) %>% 
    pull(Date) %>% 
    month()

  cpr_date = as.Date(glue('{cpr_month}/{cpr_day}'), '%m/%d')
  if (cpr_date - Sys.Date() > 100) { 
      cpr_date = seq.Date(cpr_date, length.out = 2, by = '-1 year')[2]
    }
  
 print(cpr_date)
 cpr_tpr = read_xlsx(temp, sheet = 6, skip = 1) %>% 
   filter(`State Abbreviation` == 'TX') %>%
   select('County',
          contains('NAAT positivity rate - last 7 days'),
          contains('Total NAATs - last 7 days')) %>% 
   filter(County != 'Unallocated, TX') %>%
   mutate(County = gsub(' County, TX', '', County)) %>% 
   setNames(c('County', 'TPR_CPR', 'Tests')) %>% 
   mutate(Date = cpr_date) %>% 
   arrange(County)
 
 output = list(cpr_tpr)
 names(output) = cpr_date
 return(output)
}

page = read_html('https://beta.healthdata.gov/National/COVID-19-Community-Profile-Report/gqxm-d9w9')
file_loc = page %>%
  html_nodes('script') %>% 
  html_text() %>%
  str_detect('\\.xlsx') %>%
  which()

file_text = page %>% 
  html_nodes('script') %>%
  .[file_loc] %>%
  html_text() %>%
  str_replace(., '\n    var initialState =\n      ', '') %>%
  str_replace(., '\n   ;\n  ', '')

tpr_url = fromJSON(file_text)$view$attachments %>%
  filter(href %>% str_detect('.xlsx')) %>% 
  distinct() %>%
  arrange(desc(name)) %>%
  slice(1:28) %>%
  pull(href) %>%
  unname()

tpr_results = map(tpr_url[26:28], ~Clean_TPR(.)) %>% 
  unlist(., recursive = FALSE)

map(names(tpr_results), ~fwrite(tpr_results[[.]],
                                glue('original-sources/historical/cpr/cpr_tpr_{.}.csv'),
                                quote = TRUE))
```

Inconsistent updates, no longer using

```{r}
# cpr_tpr = fromJSON('https://services5.arcgis.com/qWZ7BaZXaP5isnfT/arcgis/rest/services/Community_Profile_Report_Counties/FeatureServer/0/query?where=State_Abbreviation%3D%27TX%27&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=none&distance=0.0&units=esriSRUnit_Meter&returnGeodetic=false&outFields=County%2C+test_positivity_rate_last_7_d%2C+total_tests_last_7_d%2C+last_updated&returnGeometry=false&returnCentroid=false&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pjson&token=')[['features']][['attributes']] %>% 
#   filter(!str_detect(County, 'Unallocated')) %>%
#   setNames(c('County', 'TPR_CPR', 'Tests', 'Date')) %>% 
#   mutate(Date = as_date(as_datetime(Date/1000))) %>% 
#   mutate(TPR_CPR = TPR_CPR / 100) %>% 
#   mutate(County = gsub(' County, TX', '', County)) %>% 
#   arrange(County)
# 
# cpr_date = cpr_tpr$Date[1]
# 
# 
# 
# fwrite(cpr_tpr,
#         paste0('original-sources/historical/cpr/cpr_tpr_', cpr_date, '.csv'),
#         row.names = FALSE,
#         quote = TRUE)
```



```{r}
# add cms archive (8/19 - 12/09) (data represented 2 weeks of cases)
cpr_dates = list.files('original-sources/historical/cpr') %>% 
  gsub('cpr_tpr_', '', .) %>% 
  gsub('.csv', '', .) %>% 
  as.Date(.)

cms_dates = list.files('original-sources/historical/cms_tpr/') %>% 
  gsub('TPR_', '', .) %>% 
  gsub('.csv', '', .) %>% 
  as.Date(.)

TPR_dates = sort(unique(c(cpr_dates, cms_dates)))

# combine cpr archive
all_cpr_tpr = rbindlist(lapply(list.files('original-sources/historical/cpr/', full.names = TRUE), read.csv)) %>% 
  rename(TPR = TPR_CPR) %>% 
  mutate(Date = as.Date(Date)) %>%
  mutate(TPR = ifelse(is.na(TPR), 0, TPR)) %>%
  mutate(Tests = NA)

TPR_all_dates = data.frame(
  County = rep(county_classifications$County %>% unique(), each = length(TPR_dates)),
  Date = rep(TPR_dates, times = length(county_classifications$County %>% unique())))


cms_archive = tpr_df %>% filter(Date < '2020-12-16') %>%
  select(Date, County, Tests, TPR)

cms_new = tpr_df %>% filter(Date >= '2020-12-16') %>%
  rbind(TPR_all_dates %>%
        filter(Date >= '2020-12-16'),
      fill = TRUE) %>% 
  group_by(County) %>% 
  arrange(County, Date) %>%
  tidyr::fill(Tests, .direction = 'down') %>%
  distinct() %>%
  select(Date, County, Tests)

tpr_cases = merged_county %>% 
  dplyr::select(County, Date, Cases_Daily, Population_DSHS) %>%
  filter(Date >= as.Date(min(TPR_dates)) - 13 & Date <= max(TPR_dates)) %>%
  group_by(County) %>%
  mutate(Cases_100K_7Day_MA = (rollmean(Cases_Daily, k = 7, align = 'right',
                                        na.pad = TRUE, na.rm = TRUE)
                               / Population_DSHS) * 100000) %>%
  mutate(Cases_100K_14Day_MA = (rollmean(Cases_Daily, k = 14, align = 'right',
                                         na.rm = TRUE, na.pad = TRUE)
                                / Population_DSHS) * 100000) %>% 
  filter(Date %in% TPR_dates) %>% 
  dplyr::select(-Cases_Daily, -Population_DSHS, -Cases_100K_14Day_MA)


tpr_out = all_cpr_tpr %>%
  rbind(TPR_all_dates %>% filter(Date >= '2020-12-16'), fill = TRUE) %>%
  distinct() %>%
  arrange(County, Date) %>%
  # fill(Tests, .direction = 'down') %>% 
  # fill(TPR, .direction = 'down') %>%
  rbind(cms_archive) %>%
  left_join(cms_new, by = c('County', 'Date')) %>%
  left_join(tpr_cases, by = c('County', 'Date')) %>%
  mutate(Tests.x = ifelse(is.na(Tests.y), Tests.x, Tests.y)) %>%
  rename(Tests = Tests.x) %>%
  dplyr::select(-Tests.y) %>%
  dplyr::select(County, Date, TPR, Tests, Cases_100K_7Day_MA) %>%
  arrange(County, Date) %>%
  group_by(County, Date) %>% 
  slice(1) %>% 
  distinct() %>% 
  group_by(Date) %>% 
  mutate(count_0 = sum(TPR == 0)) %>%
  filter(count_0 < 254 | is.na(count_0))
  
write.csv(tpr_out, 'tableau/county_TPR.csv', row.names = FALSE)
```

## vaccinations

```{r}
curl::curl_download('https://www.dshs.texas.gov/immunize/covid19/COVID-19-Vaccine-Data-by-County.xls', mode = 'wb', 
              destfile = glue('original-sources/historical/vaccinations/vaccinations_{date_out}.xlsx'))
# 
# Clean_Vaccines = function(x) {
#   file_date = Date_Parser(x)
#   df = read_excel(x, sheet = 2) %>%
#     mutate(Date = file_date) %>%
#     setNames(c('County', 'PHR',
#                'Doses_Allocated', 'Doses_Administered',
#                'People_Vaccinated_Partial', 'People_Vaccinated_Full',
#                'Population_Over_16', 'Population_Over_65',
#                'Population_Phase_1A_Healthcare',
#                'Population_Phase1A_Care_Residents',
#                'Population_Phase_1B_Medical_Condition', 'Date')) %>%
#     filter(!(County %in% c('Texas', '*Other', 'Federal Long-Term Care Vaccination Program'))) %>%
#     dplyr::select(Date, everything())
# }
# 
# vaccine_files = list.files('original-sources/historical/vaccinations/', full.names = TRUE)
# 
# county_vaccine = rbindlist(lapply(vaccine_files, Clean_Vaccines))
# demographics_vaccine = read_excel(vaccine_files[length(vaccine_files)], sheet = 3) %>%
#   setNames(c('Gender', 'Age', 'Race_Ethnicity', 'Doses_Administered', 'People_Vaccinated_Partial', 'People_Vaccinated_Full'))


# write.csv(county_vaccine, 'tableau/county_vaccine.csv', row.names = FALSE)
# write.csv(demographics_vaccine, 'tableau/demographics_vaccine.csv', row.names = FALSE)
```

## vaccine providers

```{r}
curl::curl_download('https://genesis.soc.texas.gov/files/accessibility/vaccineprovideraccessibilitydata.csv', mode = 'wb', 
              glue('original-sources/historical/vaccine-providers/vaccination-providers_{date_out}.csv')) %>% 
  try(., silent = TRUE)
```

## vaccines zip

```{r}
temp = tempfile()
curl::curl_download('https://dshs.texas.gov/coronavirus/TexasCOVID19VaccinesbyZIP.xlsx',
              temp, mode = 'wb') 
vaccines_zip = read_excel_allsheets(temp, col_option = FALSE)

vaccine_date = vaccines_zip[[1]] %>% slice(1) %>% select(2) %>% Date_Parser()
# vaccine_date = date_out

if (!is.na(vaccine_date)) {
  vaccines_zip_out = vaccines_zip[[2]] %>%
    select(1:4) %>%
    setNames(c('ZIP', 'Doses_Administered', 'At_Least_One_Dose', 'Fully_Vaccinated')) %>% 
    mutate_all(as.numeric) %>% 
    filter(!is.na(ZIP)) %>% 
    mutate(Date = vaccine_date) %>% 
    select(Date, ZIP, everything())
  write_csv(vaccines_zip_out, glue('original-sources/historical/vaccine-zip/vaccination-zip_{date_out}.csv'))
}
zip_archive = list.files(glue('original-sources/historical/vaccine-zip'), full.names = TRUE)

vaccines_zip_all = rbindlist(lapply(zip_archive, read_csv), fill = TRUE) %>%
  distinct() %>% 
  mutate(Date = as.Date(Date))

write_csv(vaccines_zip_all, 'tableau/zip_vaccine.csv')
```



## vaccine dashboard

```{r}
# TODO: update to only run when its monday and the files are new 
vax_dir = 'original-sources/historical/vax-dashboard'
date_modified = list.files(glue('{vax_dir}/temp/allocation'), full.names = TRUE)[1] %>%
  file.info() %>%
  .[['ctime']] %>%
  as.Date(.)

if (format(date_out, '%A') == 'Monday' & (date_out - date_modified == -1)) {
  vax_allocation = rbindlist(lapply(list.files(glue('{vax_dir}/temp/allocation/'), full.names = TRUE),
                                read.csv, fileEncoding="UTF-16LE", sep = '\t'),
                         fill = TRUE) %>%
    filter(X != 'DosesAllocatedWindow along Week No' & 
           X != 'SumDosesAllocated (copy)') %>%
    dplyr::select(-X) %>%
    reshape2::melt(id = c('Allocation.Week.Range', 'CountyNameDisplay', 'Dose.Number..group.')) %>%
    dplyr::select(-variable) %>%
    setNames(c('Date', 'County', 'Dose', 'Count')) %>%
    mutate(Count = ifelse(Count == '', NA, Count)) %>%
    mutate(Count = as.numeric(gsub(',', '', Count))) %>%
    na.omit() %>%
    mutate(County = gsub(' County', '', County)) %>%
    filter(County != 'Texas') %>%
    mutate(Date = as.Date(Date, '%m/%d/%Y')) %>%
    reshape(idvar = c('Date', 'County'), timevar = 'Dose', direction = 'wide') %>%
    rename('Doses_Allocated_1' = `Count.First Doses`,
           'Doses_Allocated_2' = `Count.Second Doses`) %>%
    group_by(Date, County) %>%
    mutate(Doses_Allocated_1 = sum(Doses_Allocated_1, `Count.Federal Programs, First Doses`, na.rm = TRUE)) %>% 
    dplyr::select(Date, County, Doses_Allocated_1, Doses_Allocated_2)

  vax_admin = rbindlist(lapply(list.files(glue('{vax_dir}/temp/admin/'), full.names = TRUE),
                                read.csv, fileEncoding="UTF-16LE", sep = '\t'),
                         fill = TRUE) %>%
    reshape2::melt(id = c('Week.Start.End', 'CountyNameDisplay')) %>%
    dplyr::select(-variable) %>%
    setNames(c('Date', 'County', 'Doses_Administered')) %>%
    mutate(Doses_Administered) %>%
    mutate(Doses_Administered = as.numeric(gsub(',', '', Doses_Administered))) %>%
    na.omit() %>%
    mutate(County = gsub(' County', '', County)) %>%
    mutate(Date = str_extract(Date, '\\- (.*)')) %>%
    mutate(Date = gsub('- ', '', Date)) %>%
    mutate(Date = as.Date(Date, '%m/%d/%Y'))

## FULL
  demo_archive = list.files(glue('{vax_dir}/archive/'), full.names = TRUE)
  
  age_archive = rbindlist(lapply(demo_archive %>% .[str_detect(., 'age')], read_csv), fill = TRUE) %>% distinct()
  race_archive = rbindlist(lapply(demo_archive %>% .[str_detect(., 'race')], read_csv), fill = TRUE) %>% distinct()
  
  vax_age_full = rbindlist(lapply(list.files(glue('{vax_dir}/temp/demo_age_full/'), full.names = TRUE),
                                  read.csv, fileEncoding="UTF-16LE", sep = '\t'),
                           fill = TRUE) %>%
    dplyr::select(X, X.1, X.3, People.Vaccinated) %>%
    reshape2::melt(id = c('X', 'X.1', 'X.3')) %>%
    dplyr::select(-variable) %>%
    setNames(c('Age', 'County', 'Gender', 'Fully_Vaccinated')) %>%
    mutate(Date = max(vax_admin$Date)) %>%
    mutate(County = gsub(' County', '', County)) %>%
    dplyr::select(Date, County, everything()) %>% 
    mutate(Date = as.Date(Date)) %>%
    mutate(Fully_Vaccinated = as.numeric(gsub(',', '', Fully_Vaccinated))) %>%
    arrange(Date, County)


  Read_Race = function(x) {
    county_name = str_match(x, '\\/race_(.*)\\.csv')[2]
    x_out = read.csv(x, fileEncoding="UTF-16LE", sep = '\t') %>%
              mutate(County = county_name)
    return(x_out)
    }


  vax_race_full = rbindlist(lapply(list.files(glue('{vax_dir}/temp/demo_race_full/'), full.names = TRUE),
                               Read_Race),
                         fill = TRUE) %>%
    setNames(c('Race', 'dump1', 'Fully_Vaccinated', 'dump2', 'County')) %>%
    mutate(Date = max(vax_admin$Date)) %>%
    dplyr::select(Date, County, Race, Fully_Vaccinated, -dump1, -dump2) %>% 
    mutate(Date = as.Date(Date)) %>%
    mutate(Fully_Vaccinated = as.numeric(gsub(',', '', Fully_Vaccinated))) %>%
    arrange(Date, County)

  
# PARTIAL
  vax_age_partial = rbindlist(lapply(list.files(glue('{vax_dir}/temp/demo_age_partial/'), full.names = TRUE),
                                  read.csv, fileEncoding="UTF-16LE", sep = '\t'),
                           fill = TRUE) %>%
    dplyr::select(X, X.1, X.3, People.Vaccinated) %>%
    reshape2::melt(id = c('X', 'X.1', 'X.3')) %>%
    dplyr::select(-variable) %>%
    setNames(c('Age', 'County', 'Gender', 'At_Least_One_Vaccinated')) %>%
    mutate(Date = max(vax_admin$Date)) %>%
    mutate(County = gsub(' County', '', County)) %>%
    dplyr::select(Date, County, everything()) %>% 
    mutate(Date = as.Date(Date)) %>%
    mutate(At_Least_One_Vaccinated = as.numeric(gsub(',', '', At_Least_One_Vaccinated))) %>%
    arrange(Date, County)


  vax_race_partial = rbindlist(lapply(list.files(glue('{vax_dir}/temp/demo_race_partial/'), full.names = TRUE),
                               Read_Race),
                         fill = TRUE) %>%
    setNames(c('Race', 'dump1', 'At_Least_One_Vaccinated', 'dump2', 'County')) %>%
    mutate(Date = max(vax_admin$Date)) %>%
    dplyr::select(Date, County, Race, At_Least_One_Vaccinated, -dump1, -dump2) %>% 
    mutate(Date = as.Date(Date)) %>%
    mutate(At_Least_One_Vaccinated = as.numeric(gsub(',', '', At_Least_One_Vaccinated))) %>%
    arrange(Date, County)
 
  vax_age = vax_age_full %>% 
    left_join(vax_age_partial, by = c('County', 'Date', 'Age', 'Gender')) %>% 
    plyr::rbind.fill(age_archive) %>% 
    arrange(County, Date)
  
  vax_race = vax_race_full %>% 
    left_join(vax_race_partial, by = c('County', 'Date', 'Race')) %>% 
    plyr::rbind.fill(race_archive) %>% 
    arrange(County, Date)

  pop_files = list.files('original-sources/historical/vaccinations/', full.names = TRUE)

  vax_pop_counts = read_xlsx(pop_files[length(pop_files)], sheet = 2) %>%
    dplyr::select(`County Name`, ends_with('5+'), ends_with('16+'), ends_with('65+'),
                  contains('Healthcare'), contains('Long-term'), contains('Medical Condition')) %>% 
    relocate(contains('65+'), .after=contains('16+')) %>%
      setNames(c('County',
                 'Population_Over_5', 'Population_Over_16', 'Population_Over_65',
                 'Population_Phase_1A_Healthcare',
                 'Population_Phase1A_Care_Residents',
                 'Population_Phase_1B_Medical_Condition', 'Date')) %>%
    filter(County %in% (dshs_pops$County %>% unique()))
  
  vax_out = vax_allocation %>% 
    full_join(vax_admin, by = c('Date', 'County')) %>% 
    left_join(vax_pop_counts, by = 'County') %>% 
    full_join(vax_age_partial %>% 
                group_by(Date, County) %>%
                summarize(At_Least_One_Vaccinated = sum(At_Least_One_Vaccinated, na.rm = TRUE))) %>% 
    full_join(vax_age_full %>% 
                group_by(Date, County) %>%
                summarize(Fully_Vaccinated = sum(Fully_Vaccinated, na.rm = TRUE))) %>% 
    dplyr::select(Date, County, Doses_Allocated_1, Doses_Allocated_2,
                  Doses_Administered, At_Least_One_Vaccinated, Fully_Vaccinated,
                  everything())

  
  write.csv(vax_out, 'tableau/county_vaccine.csv', row.names = FALSE)
  write.csv(vax_age, 'tableau/demographics_vax_age.csv', row.names = FALSE)
  write.csv(vax_age %>% filter(Date == max(Date)),
            glue('{vax_dir}/archive/{max(vax_admin$Date)}_demographics_vax_age.csv'), row.names = FALSE)
  write.csv(vax_race, 'tableau/demographics_vax_race.csv', row.names = FALSE)
  write.csv(vax_race %>% filter(Date == max(Date)),
            glue('{vax_dir}/archive/{max(vax_admin$Date)}_demographics_vax_race.csv'), row.names = FALSE)
}
```


## vax dashboard new

```{r}
dashboard_archive = list.files('C:/Users/jeffb/Desktop/Life/personal-projects/COVID/original-sources/historical/vaccinations', full.names = TRUE)

# combine all sheets, obtain unique date, count combos, save
all_dashboard_files = lapply(dashboard_archive, read_excel_allsheets, add_date = TRUE, col_option = FALSE, skip_option = 0)

# DSHS temporarily removed county level data on 10/6
all_dashboard_files = all_dashboard_files[-264]

county_vaccinations = 
  rbindlist(
  lapply(
    lapply(all_dashboard_files, `[[`, 'By County'),
           function(x) return(x %>%
                                setNames(slice(., 1)) %>%
                                slice(2:nrow(.)) %>%
                                rename('Date' = ncol(.)))
    )
    , fill = TRUE) %>% 
  filter(`County Name` %in% (dshs_pops$County %>% unique())) %>%
  # distinct_at(vars(-c(`County Name`, Date)), .keep_all = TRUE) %>%
  select(Date, `County Name`,
         `Total Doses Allocated`, `Vaccine Doses Administered`,
         `People Vaccinated with at least One Dose`, `People Fully Vaccinated`,
         ends_with('5+'), `Population, 16+`, `Population, 65+`) %>%
  relocate(ends_with('5+'), .before=ends_with('16+')) %>% 
  relocate(ends_with('65+'), .after=ends_with('16+')) %>%
  setNames(c('Date', 'County', 'Doses_Allocated',
             'Doses_Administered', 'At_Least_One_Dose', 'Fully_Vaccinated',
             'Population_5', 'Population_16', 'Population_65')) %>%
  mutate_at(vars(-County, -Date), as.numeric) %>%
  mutate(Doses_Allocated_Per_5 = Doses_Allocated / Population_5,
         Doses_Allocated_Per_16 = Doses_Allocated / Population_16,
         Doses_Allocated_Per_65 = Doses_Allocated / Population_65,
         Doses_Administered_Per_5 = Doses_Administered / Population_5,
         Doses_Administered_Per_16 = Doses_Administered / Population_16,
         Doses_Administered_Per_65 = Doses_Administered / Population_65,
         Fully_Vaccinated_Per_5 = Fully_Vaccinated / Population_5,
         Fully_Vaccinated_Per_16 = Fully_Vaccinated / Population_16,
         Fully_Vaccinated_Per_65 = Fully_Vaccinated / Population_65)


# DSHS swapped counts of full and partial vaccinations on 3/12 [duplicated on 3/13].
vaccinations_312 = 
  read_xlsx("original-sources/historical/vaccinations/vaccinations_2021-03-12.xlsx", sheet = 2) %>% 
  slice(2:nrow(.)) %>%
  mutate(Date = as.Date('2021-03-12')) %>%
  # select(- `People Fully Vaccinated`) %>% 
  rename(At_Least_One_Dose = `People Fully Vaccinated`,
         `People Fully Vaccinated` = `People Vaccinated with at least One Dose`) %>%
  # distinct_at(vars(-c(`County Name`, Date)), .keep_all = TRUE) %>% 
  select(Date, `County Name`,
         `Total Doses Allocated`, `Vaccine Doses Administered`,
         `At_Least_One_Dose`, `People Fully Vaccinated`,
         `Population, 16+`, `Population, 65+`) %>%
  setNames(c('Date', 'County', 'Doses_Allocated',
             'Doses_Administered', 'At_Least_One_Dose', 'Fully_Vaccinated',
             'Population_16', 'Population_65')) %>%
  filter(County %in% (dshs_pops$County %>% unique())) %>%
  mutate_at(vars(-County, -Date), as.numeric) %>%
  mutate(Doses_Allocated_Per_16 = Doses_Allocated / Population_16,
         Doses_Allocated_Per_65 = Doses_Allocated / Population_65,
         Doses_Administered_Per_16 = Doses_Administered / Population_16,
         Doses_Administered_Per_65 = Doses_Administered / Population_65,
         Fully_Vaccinated_Per_16 = Fully_Vaccinated / Population_16,
         Fully_Vaccinated_Per_65 = Fully_Vaccinated / Population_65)


vaccinations_312 = vaccinations_312 %>% rbind(vaccinations_312 %>% mutate(Date = as.Date('2021-03-13')))

# Average between 4/6 and 4/8 for missing 4/7 file
vaccinations_407 = county_vaccinations %>%
  filter(Date == '2021-04-06' | Date == '2021-04-08') %>% 
  group_by(County) %>% 
  summarize(across(Doses_Allocated:Fully_Vaccinated_Per_65, ~round(mean(.x, na.rm = TRUE), 0))) %>% 
  mutate(Date = as.Date('2021-04-07'))


population_12 = all_dashboard_files[[length(all_dashboard_files)]][[2]] %>%
  setNames(slice(., 1)) %>%
  select(`County Name`, `Population\r\n12+`) %>% 
  filter(`County Name` %in% (dshs_pops$County %>% unique())) %>%
  rename(County = `County Name`, Population_12 = `Population\r\n12+`) %>%
  filter(!is.na(County))



county_vaccinations_out = county_vaccinations %>% 
  filter(Date != '2021-03-12' & Date != '2021-03-13') %>% 
  plyr::rbind.fill(vaccinations_312) %>%
  plyr::rbind.fill(vaccinations_407) %>%
  arrange(Date, County) %>%
  mutate(County = gsub('\\*Other|\\* Other', 'Other', County)) %>%
  left_join(tsa_long_complete %>% select(County, TSA_Combined)) %>% 
  left_join(county_classifications %>% select(County, PHR_Combined, Metro_Area)) %>% 
  select(-contains('_Per')) %>% 
  left_join(county_demo_agesex %>%
              select(County, `Age Group`, Population_Total) %>%
              filter(`Age Group` %in% c('<16', '16+')) %>%
              group_by(County) %>%
              summarize(Population_Total = sum(Population_Total)) %>%
              arrange(-Population_Total)) %>%
  left_join(population_12) %>% 
  relocate(Population_12, .before = Population_16) %>%
  relocate(Population_Total, .before = TSA_Combined) %>% 
  group_by(County) %>% 
  mutate(Population_5 = coalesce(Population_5, NA)) %>% 
  tidyr::fill(Population_5, .direction = 'updown')
```

### diagnostics
```{r}
county_vaccinations_out %>%
  filter(County == 'Harris') %>% 
  filter(Date > as.Date('2021-04-05') & Date <= as.Date('2021-04-10')) %>%
  ggplot(aes(x = Date, y = Fully_Vaccinated)) + 
  geom_point() + 
  theme_pubr()


county_vaccinations_out %>%
  filter(County == 'Harris') %>%
  arrange(County, Date) %>%
  group_by(County) %>%
  mutate(date_check = ifelse(Date - lag(Date) > 1, TRUE, FALSE)) %>% 
  filter(date_check == TRUE)

county_vaccinations_out %>%
  filter(County == 'Harris') %>% 
  filter(Date >= date_out-7) %>%
  select(1:5) %>%
  arrange(desc(Date))

write_csv(county_vaccinations_out, 'tableau/sandbox/county_daily_vaccine.csv')
```

#### state
```{r}
# DSHS classified 5-11 and 12-15 as dates
state_demo = lapply(all_dashboard_files, `[[`, 'By Age, Gender, Race') %>% 
  discard(is.null) %>%
  lapply(., function(x) x %>% 
           setNames(slice(., 1) %>% unlist()) %>%
           rename(Date = ncol(.)) %>%
           slice(2:nrow(.))) %>%
  rbindlist(fill = TRUE) %>% 
  mutate(`Race/Ethnicity` = ifelse(is.na(`Race/Ethnicity`), str_c(Race, Ethnicity), `Race/Ethnicity`)) %>%
  select(-Race, -Ethnicity, -`People Vaccinated with at Least One Dose`, -`People Vaccinated`) %>%
  filter(`Age Group` != 'Total') %>%
  mutate(`Age Group` = ifelse(`Age Group` == '44692', '5-11 years', `Age Group`)) %>%
  mutate(`Age Group` = ifelse(`Age Group` == '44910', '12-15 years', `Age Group`)) %>%
  mutate(`Age Group` = ifelse(!str_detect(`Age Group`, 'years|Unknown'), glue('{`Age Group`} years'), `Age Group`)) %>%
  rename(Age_Group = 'Age Group',
         Doses_Administered = 'Doses Administered',
         At_Least_One_Vaccinated = 'People Vaccinated with at least One Dose',
         Fully_Vaccinated = 'People Fully Vaccinated',
         Booster = 'People with Booster Doses') %>%
  # remove dupes
  arrange(Date) %>%
  group_by(Gender, Age_Group, `Race/Ethnicity`) %>% 
  mutate(dupe_val = Fully_Vaccinated == lag(Fully_Vaccinated)) %>% 
  group_by(Date) %>% 
  mutate(dupe_count = sum(dupe_val, na.rm = TRUE)) %>% 
  mutate(row_count = n()) %>% 
  ungroup() %>%
  filter(dupe_count != row_count) %>%
  filter(Date == max(Date)) %>% 
  select(-dupe_count, -row_count, -dupe_val) %>% 
  # add pops
  left_join(county_demo_race %>%
              group_by(`Race/Ethnicity`) %>%
              summarize(State_Race_Total = sum(Population_Total, na.rm = TRUE))) %>%
  left_join(county_demo_agesex %>%
              filter(`Age Group` == '<16' | `Age Group` == '16+') %>%
              group_by(Gender) %>% 
              summarize(State_Gender_Total = sum(Population_Total, na.rm = TRUE))) %>% 
 left_join(county_demo_agesex %>%
              group_by(`Age Group`) %>%
              summarize(State_Age_Total = sum(Population_Total, na.rm = TRUE)) %>%
              rename('Age_Group' = `Age Group`)) %>%
  mutate_at(vars(-Gender, -Age_Group, -`Race/Ethnicity`), as.numeric) %>%
  mutate(Doses_Administered_Per_Race = Doses_Administered / State_Race_Total,
         Doses_Administered_Per_Gender = Doses_Administered / State_Gender_Total,
         Doses_Administered_Per_Age = Doses_Administered / State_Age_Total,
         At_Least_One_Vaccinated_Per_Race = At_Least_One_Vaccinated / State_Race_Total,
         At_Least_One_Vaccinated_Per_Gender = At_Least_One_Vaccinated / State_Gender_Total,
         At_Least_One_Vaccinated_Per_Age = At_Least_One_Vaccinated / State_Age_Total,
         Fully_Vaccinated_Per_Race = Fully_Vaccinated / State_Race_Total,
         Fully_Vaccinated_Per_Gender = Fully_Vaccinated / State_Gender_Total,
         Fully_Vaccinated_Per_Age = Fully_Vaccinated / State_Age_Total,
         Booster_Per_Race = Booster / State_Race_Total,
         Booster_Per_Gender = Booster / State_Gender_Total,
         Booster_Per_Age = Booster / State_Age_Total) %>% 
  relocate(`Race/Ethnicity`, .after=Age_Group) %>% 
  mutate(Date = format(as.Date(Date, origin = '1970-01-01'), '%Y-%m-%d')) %>%
  relocate(Date, .after=Booster_Per_Age)
  
write_csv(state_demo, 'tableau/sandbox/state_vaccine_demographics.csv')
```

```{r}
measure_cols = c('Doses_Administered', 'At_Least_One_Vaccinated', 'Fully_Vaccinated')


state_demo_stacked = 
  state_demo %>%
    select(c(contains('Gender'), measure_cols, -contains('Per'))) %>%
    mutate(Group_Type = 'Gender') %>%
    rename(Group = Gender,
           Population_Total = State_Gender_Total) %>%
    group_by(Group_Type, Group, Population_Total) %>% 
    summarize_at(measure_cols, sum, na.rm = TRUE) %>%
  rbind(state_demo %>%
    select(c(contains('Race'), measure_cols, -contains('Per'))) %>%
    mutate(Group_Type = 'Race') %>% 
    rename(Group = `Race/Ethnicity`,
           Population_Total = State_Race_Total)) %>%
    group_by(Group_Type, Group, Population_Total) %>% 
    summarize_at(measure_cols, sum, na.rm = TRUE) %>%
  rbind(state_demo %>%
    select(c(contains('Age'), measure_cols, -contains('Per'))) %>%
    mutate(Group_Type = 'Age') %>%
    rename(Group = Age_Group,
           Population_Total = State_Age_Total)) %>%
    group_by(Group_Type, Group, Population_Total) %>% 
    summarize_at(measure_cols, sum, na.rm = TRUE) %>%
  relocate(Group_Type, .before = Group)


# under_12 = data.frame(Group_Type = 'Age',
#                       Group = '< 12 years',
#                       Doses_Administered = 0,
#                       At_Least_One_Vaccinated = 0,
#                       Fully_Vaccinated = 0) %>% 
#   left_join(county_demo_agesex %>% filter(`Age Group` == '< 12 years') %>%
#               group_by(`Age Group`) %>%
#               summarize(Population_Total = sum(Population_Total)) %>% 
#               rename(Age_Group = `Age Group`) %>%
#               select(Age_Group, Population_Total),
#             by = c('Group' = 'Age_Group'))



state_demo_stacked_out = 
  state_demo_stacked %>% 
  # rbind(under_12) %>% 
  arrange(Group, Group_Type) %>%
  mutate(Population_Total =
           ifelse(Group == '65-79 years & 80+ years',
                    county_demo_agesex %>%
                    filter(`Age Group` %in% c('65-79 years', '80+ years')) %>%
                    summarize(Population_Total = sum(Population_Total)) %>% 
                    select(Population_Total) %>% 
                    unlist(),
                  Population_Total)) %>%
  # pop16
  left_join(county_demo_race_age_15 %>%
              group_by(`Race/Ethnicity`) %>%
              summarize(Population_16 = sum(Population_16)),
            by = c('Group' = 'Race/Ethnicity')) %>%
  mutate(Population_16 = ifelse(Group_Type == 'Age', Population_Total, Population_16)) %>% 
  mutate(Population_16 = ifelse(Group == '< 16 years', 0, Population_16)) %>% 
  left_join(county_demo_agesex %>%
              filter(`Age Group` == '16+') %>%
              group_by(Gender) %>%
              summarize(Population_16 = sum(Population_Total)),
            by = c('Group' = 'Gender')) %>% 
  mutate(Population_16 = ifelse(!is.na(Population_16.y), Population_16.y, Population_16.x)) %>% 
  select(-contains('.x'), -contains('.y')) %>% 
  relocate(Population_16, .after = Population_Total) %>%
  # pop 5
  left_join(county_demo_race_age_5 %>%
            group_by(`Race/Ethnicity`) %>%
            summarize(Population_5 = sum(Population_5)),
          by = c('Group' = 'Race/Ethnicity')) %>%
  mutate(Population_5 = ifelse(Group_Type == 'Age', Population_Total, Population_5)) %>% 
  left_join(county_demo_agesex %>%
              filter(`Age Group` %in% c('5-11 years', '12-15 years', '16+')) %>%
              group_by(Gender) %>%
              summarize(Population_5 = sum(Population_Total)),
            by = c('Group' = 'Gender')) %>% 
  mutate(Population_5 = ifelse(!is.na(Population_5.y), Population_5.y, Population_5.x)) %>% 
  select(-contains('.x'), -contains('.y')) %>% 
  relocate(Population_5, .after = Fully_Vaccinated) %>% 
  arrange(Group_Type)

write_csv(state_demo_stacked_out, 'tableau/sandbox/stacked_state_vaccine_demographics.csv')
```

```{r}
county_vax_race = lapply(all_dashboard_files, `[[`, 'By County, Race') %>%
  discard(is.null) %>%
  .[[length(.)]] %>% 
  setNames(slice(., 1)) %>%
  slice(2:nrow(.)) %>%
  select(1:(ncol(.)-1)) %>% 
  setNames(c('County', 'Race/Ethnicity',
             'At_Least_One_Vaccinated', 'Fully_Vaccinated', 'Booster', 'Doses_Administered')) %>% 
  left_join(county_demo_race) %>% 
  mutate_at(vars(-County, -`Race/Ethnicity`), as.numeric) %>%
  mutate(Doses_Administered_Per_Race = Doses_Administered / Population_Total) %>% 
  mutate(At_Least_One_Vaccinated_Per_Race = At_Least_One_Vaccinated / Population_Total) %>% 
  mutate(Fully_Vaccinated_Per_Race = Fully_Vaccinated / Population_Total) %>% 
  mutate(Booster_Per_Race = Booster / Population_Total) %>% 
  filter(!(County %in% c('Other', 'Grand Total'))) %>% 
  select(-contains('_Per'))


write_csv(county_vax_race, 'tableau/sandbox/county_vax_race.csv')
```

```{r}
county_vax_age = lapply(all_dashboard_files, `[[`, 'By County, Age') %>%
  discard(is.null) %>%
  .[[length(.)]] %>% 
  setNames(slice(., 1)) %>%
  slice(2:nrow(.)) %>%
  select(1:(ncol(.)-1)) %>%
  mutate(`Age Group` = ifelse(`Age Group` == '44692', '5-11 years', `Age Group`)) %>%
  mutate(`Age Group` = ifelse(`Age Group` == '44910', '12-15 years', `Age Group`)) %>%
  setNames(c('County', 'Age_Group',
             'Doses_Administered', 'At_Least_One_Vaccinated', 'Fully_Vaccinated', 'Booster')) %>%
  mutate(Age_Group = glue('{Age_Group} years')) %>%
  mutate(Age_Group = gsub('years years', 'years', Age_Group)) %>%
  mutate(Age_Group = gsub('Unknown years', 'Unknown', Age_Group)) %>%
  mutate(Age_Group = str_squish(Age_Group)) %>%
  left_join(county_demo_agesex %>%
              group_by(County, `Age Group`) %>% 
              summarize(Population_Total = sum(Population_Total, na.rm = TRUE)) %>%
              rename('Age_Group' = `Age Group`)) %>%
              # mutate(Age_Group = glue('{Age_Group} years')) %>%
              # mutate(Age_Group = gsub('years years', '', Age_Group)) %>%
              # mutate(Age_Group = str_squish(Age_Group))) %>%
  mutate_at(vars(-County, -`Age_Group`), as.numeric) %>%
  mutate(Doses_Administered_Per_Age = Doses_Administered / Population_Total) %>% 
  mutate(At_Least_One_Vaccinated_Per_Age = At_Least_One_Vaccinated / Population_Total) %>% 
  mutate(Fully_Vaccinated_Per_Age = Fully_Vaccinated / Population_Total) %>% 
  mutate(Booster_Per_Age = Booster / Population_Total) %>% 
  filter(!(County %in% c('Other', 'Grand Total'))) %>% 
  select(-contains('_Per'))

write_csv(county_vax_age, 'tableau/sandbox/county_vax_age.csv')
```


# TSA LEVEL

## Variants
DSHS moved to non-scrapeable DSHS dashboard
```{r}
# try(
#   variant_df <- 'http://www.dshs.texas.gov/news/updates.shtm' %>%
#     httr::GET(., httr::timeout(20)) %>% 
#     read_html() %>%
#     html_table() %>%
#     .[[which(str_detect(., 'ALPHA'))]] %>%
#     filter(TSA != 'Grand Total') %>% 
#     select(-Total) %>% 
#     mutate(Date = date_out)
#   )
# 
# try(write_csv(x = variant_df,
#               file = glue('original-sources\\historical\\variants\\tsa_variants_{date_out}.csv')))

# epsilon variants deescalated on 6/29
# all_variants = list.files('original-sources\\historical\\variants\\', full.names = TRUE) %>%
#   lapply(., function(x) 
#            fread(x) %>%
#            setNames(c('TSA', str_extract(names(.)[2:length(names(.))], '.*[\\S]'))) %>%
#            rename_all(., recode,
#                       B.1.1.7 = 'B.1.1.7 ALPHA (UK)',
#                       B.1.351 = 'B.1.351 BETA (South Africa)',
#                       B.1.617.2 = 'B.1.617.2 DELTA (India)',
#                       B.1.427 = 'B.1.427 EPSILON (California)',
#                       B.1.429 = 'B.1.429 EPSILON (California)',
#                       P.1 = 'P.1 GAMMA (Brazil)')
#          )  %>%
#   rbindlist(fill = TRUE) %>% 
#   relocate(Date, .before = TSA) %>%
#   left_join(tsa_long_complete %>%
#               select(TSA, TSA_Combined) %>%
#               distinct() %>%
#               rbind(
#                 data.frame(TSA = 'Pending patient info from lab',
#                            TSA_Combined = 'Pending patient info from lab')
#                 )) %>% 
#   select(-TSA) %>% 
#   rename('TSA' = 'TSA_Combined') %>% 
#   relocate(TSA, .after = Date) %>% 
#   mutate_at(vars(-Date, -TSA), function(x) gsub('\\,', '', x)) %>% 
#   mutate_at(vars(-Date, -TSA), as.numeric)
# 
# update_dates = all_variants %>% 
#   distinct_at(vars(-Date), .keep_all = TRUE) %>%
#   select(Date) %>% 
#   distinct() %>% 
#   unlist()
# 
# variants_out = all_variants %>%
#   select(-contains('EPSILON')) %>%
#   filter(Date %in% update_dates) %>% 
#   arrange(Date) %>% 
#   group_by(TSA) %>%
#   mutate(alpha_Case_Ratio = `B.1.1.7 ALPHA (UK)` / lag(`B.1.1.7 ALPHA (UK)`)) %>%
#   mutate(beta_Case_Ratio = `B.1.351 BETA (South Africa)` / lag(`B.1.351 BETA (South Africa)`)) %>% 
#   mutate(delta_Case_Ratio = `B.1.617.2 DELTA (India)` / lag(`B.1.617.2 DELTA (India)`)) %>% 
#   mutate(gamma_Case_Ratio = `P.1 GAMMA (Brazil)` / lag(`P.1 GAMMA (Brazil)`)) %>% 
#   mutate(across(where(is.numeric), ~na_if(., 'NaN'))) %>% 
#   mutate(across(where(is.numeric), ~na_if(., 'Inf'))) %>% 
#   arrange(TSA, Date)
# 
# variants_melt = all_variants %>%
#   select(-contains('EPSILON')) %>%
#   filter(Date %in% update_dates) %>%
#   reshape2::melt(id.vars = c('Date', 'TSA')) %>% 
#   rename('Cases' = 'value', 'Variant' = 'variable') %>% 
#   group_by(TSA, Variant) %>%
#   arrange(Date) %>% 
#   mutate(Case_Ratio = Cases / lag(Cases)) %>% 
#   mutate(across(where(is.numeric),  ~na_if(., 'NaN'))) %>% 
#   mutate(across(where(is.numeric), ~na_if(., 'Inf'))) %>% 
#   arrange(TSA, Date)
# 
# write_csv(x = variants_out,
#           file = 'tableau\\tsa_variants.csv')
# 
# write_csv(x = variants_melt, 
#           file = 'tableau\\tsa_variants_melt.csv')
```

## Computed

```{r}
# longitudinal counts (sum)
DSHS_tsa_counts =
    merged_county %>%
    group_by(Date, TSA, TSA_Name) %>% 
    summarize_at(vars(Cases_Cumulative, Cases_Daily,
                      Deaths_Cumulative, Deaths_Daily,
                      Tests_Cumulative, Tests_Daily,
                      Active_Cases_Cumulative, Active_Cases_Daily),
                 funs(sum))

# static pop counts (sum)
DSHS_tsa_pops = 
  subset(merged_county, Date == '2020-03-06') %>%
  group_by(TSA) %>%
  summarize_at(vars(Population_DSHS),
               funs(sum))

# longitudinal google data (mean)
DSHS_tsa_google =
  merged_county %>%
  group_by(Date, TSA, TSA_Name) %>%
  summarize_at(vars(Retail_Recreation, Grocery_Pharmacy,
                    Parks, Transit,
                    Workplaces, Residential),
               funs(weighted.mean(., Population_DSHS)), na.rm = TRUE)

DSHS_tsa = merge(DSHS_tsa_counts, DSHS_tsa_google, by = c('Date', 'TSA', 'TSA_Name'))
DSHS_tsa = merge(DSHS_tsa, DSHS_tsa_pops, by = 'TSA', all = TRUE)
```

## DSHS hospitals

```{r}
hosp_url = 'https://dshs.texas.gov/coronavirus/CombinedHospitalDataoverTimebyTSA.xlsx'
temp = tempfile()

curl::curl_download(hosp_url, temp, mode = 'wb') 
DSHS_tsa_hosp = read_excel_allsheets(temp)
 
DSHS_hosp_clean = function(df, var_name) { 
  names(df) = df[1, ]
  df_clean = df %>% 
    setNames(c('TSA ID', names(df)[2:length(names(df))])) %>% 
    slice(2:23) %>% 
    select(1, 3:ncol(.)) %>%
    mutate(`TSA ID` = gsub('.', '', `TSA ID`, fixed = TRUE))

  if (length(grep('.x', names(df_clean)) > 0)) { 
    df_clean = df_clean[, -grep('.x', names(df_clean))]
    names(df_clean) = gsub('.y', '', names(df_clean))
  }

  dates = names(df_clean)[2:length(names(df_clean))]
  clean_dates = Date_Parser(dates)
  names(df_clean)[2:length(names(df_clean))] = clean_dates

  df_long = reshape::melt(df_clean, id = 'TSA ID')
  names(df_long) = c('TSA', 'Date', var_name)
  df_long$Date = as.Date(df_long$Date)
  
  if(length(which(df_long$Date == '2008-08-08')) > 0) {
    df_long$Date[which(df_long$Date == '2008-08-08')] = as.Date('2020-08-08')
  }
  
  return(df_long)
}

hosp_vars = c('COVID-19 Hospitalizations', 'Adult COVID-19 General', 'Adult COVID-19 ICU',
              'Available Ventilators', 'Pediatric COVID-19', 'COVID-19 Admits 24HR',
              'Total Available Beds', 'Adult ICU Beds Available', 'Total Occupied Beds',
              'ICU Beds Occupied', 'Pediatric ICU Beds Available')
hosp_cols = lapply(hosp_vars, function(x) DSHS_hosp_clean(DSHS_tsa_hosp[[x]], x)) %>% 
  purrr::reduce(left_join, by = c('TSA', 'Date')) %>% 
  rename(c(
    "Hospitalizations_Total" = "COVID-19 Hospitalizations",
    "Hospitalizations_General" = "Adult COVID-19 General",
    "Hospitalizations_ICU" = "Adult COVID-19 ICU",
    "Ventilators_Available" = "Available Ventilators",
    "Hospitalizations_Pediatric" = "Pediatric COVID-19",
    "Hospitalizations_24" = "COVID-19 Admits 24HR",
    "Beds_Available_Total" = "Total Available Beds",
    "Beds_Available_ICU" = "Adult ICU Beds Available",
    "Beds_Occupied_Total" = "Total Occupied Beds",
    "Beds_Occupied_ICU" = "ICU Beds Occupied",
    "Pediatric_Beds_Available_ICU" = "Pediatric ICU Beds Available"
  )) %>% 
  mutate(across(Hospitalizations_Total:Pediatric_Beds_Available_ICU, as.character)) %>% 
  mutate(across(Hospitalizations_Total:Pediatric_Beds_Available_ICU, as.integer)) %>% 
  relocate(Hospitalizations_24, .after = ncol(.))
```
## merge

```{r}
merged_tsa = DSHS_tsa %>% 
  left_join(hosp_cols, by = c('TSA', 'Date')) %>%
  mutate(TSA_Combined = paste0(TSA, ' - ', TSA_Name)) %>%
  filter(!is.na(TSA) & !is.na(Date)) %>% 
  distinct() %>%
  select(Date, TSA, TSA_Name, TSA_Combined, Population_DSHS,
         Hospitalizations_Total:Hospitalizations_24) %>% 
  filter(Date >= as.Date('2020-04-11'))

write.csv(merged_tsa, file = 'tableau/hospitalizations_tsa.csv', row.names = F)
```

# STATE LEVEL

## Case/Hosp Wave Comparison
```{r}
# Wave declarations
waves = list(
  data.frame(Wave = 'Wave 1', Date = seq(as.Date('2020-10-01'), as.Date('2021-06-30'), by = 'days')),
  data.frame(Wave = 'Wave 2', Date = seq(as.Date('2021-07-01'), as.Date('2021-12-11'), by = 'days')),
  data.frame(Wave = 'Wave 3', Date = seq(as.Date('2021-12-12'), Sys.Date(), by = 'days'))
  ) %>% 
  rbindlist() %>% 
  mutate(Date = as.Date(Date))


# tsa wave
wave_comparison_tsa = fread('tableau/county.csv') %>%
  mutate(Date = as.Date(Date)) %>% 
  group_by(TSA_Combined, Date) %>% 
  summarize(Cases_Daily = sum(Cases_Daily, na.rm = TRUE),
            Deaths_Daily = sum(Deaths_Daily, na.rm = TRUE)) %>%
  ungroup() %>% 
  left_join(fread('tableau/hospitalizations_tsa.csv') %>%
              mutate(Date = as.Date(Date)) %>%
              group_by(TSA_Combined, Date) %>%
              summarize(Hospitalizations_24 = sum(Hospitalizations_24, na.rm = TRUE)),
            by = c('Date' = 'Date', 'TSA_Combined' = 'TSA_Combined')) %>%
  left_join(waves, by = c('Date' = 'Date')) %>% 
  filter(!is.na(Wave)) %>%
  group_by(TSA_Combined, Wave) %>%
  summarize(Hospitalizations_24 = sum(Hospitalizations_24, na.rm = TRUE),
            Cases_Total = sum(Cases_Daily, na.rm = TRUE)) %>%
  mutate(Hospitalizations_24_Ratio = Hospitalizations_24 / Cases_Total) %>% 
  mutate(Level_Type = 'TSA') %>% 
  rename(Level = TSA_Combined) %>% 
  relocate(Level_Type, .before = Level)


wave_comparison = wave_comparison_tsa %>%
  plyr::rbind.fill(
    wave_comparison_tsa %>%
      group_by(Wave) %>% 
      mutate(Hospitalizations_24 = sum(Hospitalizations_24, na.rm = TRUE),
             Cases_Total = sum(Cases_Total, na.rm = TRUE)) %>% 
      mutate(Hospitalizations_24_Ratio = Hospitalizations_24 / Cases_Total) %>% 
      ungroup() %>%
      mutate(Level_Type = 'State', Level = 'Texas') %>% 
      distinct()
    )

fwrite(wave_comparison, 'tableau/wave_comparison.csv')
```


## CDC variant data
```{r}
variant_lookup = data.frame(
  stringsAsFactors = FALSE,
           Variant = c("B.1.1.7","B.1.351","P.1",
                       "B.1.617.2","AY.1","AY.2","B.1.526","B.1.617.1",
                       "B.1.621","Other","B.1.427/429","B.1.525","B.1.617.3",
                       "P.2"),
     Variant_Label = c("Alpha","Beta","Gamma",
                       "Delta","Delta","Delta","Iota","Kappa","Mu","Other",
                       "Epsilon","Eta",NA,"Zeta"))


cdc_variant_data = lapply(list.files('original-sources/historical/cdc_variants/', full.names=TRUE),
                          fread) %>% 
  rbindlist(fill = TRUE) %>% 
  group_by(Date) %>% 
  slice(1) %>% 
  ungroup() %>%
  unite(Sequences, c('Total Available sequences', 'Total Available Sequences', 'Total Sequences'), na.rm = TRUE) %>% 
  select(-V3) %>%
  mutate(across(everything(), ~gsub('\\%|\\,', '', .))) %>% 
  mutate(across(-c(Date, State), as.numeric)) %>%
  reshape2::melt(id.vars = c('Date', 'State', 'Sequences')) %>% 
  setNames(c('Date', 'State', 'Total_Sequences', 'Variant', 'Proportion')) %>% 
  group_by(Date) %>% 
  mutate(Proportion_Total = sum(Proportion, na.rm = TRUE)) %>% 
  group_by(row_number()) %>% 
  mutate(Proportion = ifelse(Proportion_Total > 1, Proportion/100, Proportion)) %>%
  group_by(Date) %>% 
  mutate(Proportion_Total1 = sum(Proportion, na.rm = TRUE)) %>% 
  select(1:5) %>%
  ungroup() %>%
  mutate_if(is.factor, as.character) %>% 
  left_join(variant_lookup, by = 'Variant') %>% 
  group_by(Date, Variant_Label) %>% 
  mutate(Proportion = sum(Proportion, na.rm = TRUE)) %>% 
  filter(!Variant %in% c('AY.1', 'AY.2', 'B.1.617.3')) %>% 
  select(Date, Variant, Variant_Label, Total_Sequences, Proportion) %>%
  mutate(Sequences = floor(Total_Sequences * Proportion)) %>% 
  ungroup()

fwrite(cdc_variant_data, 'tableau/cdc_variant_data.csv')
```


```{r}
state_url = 'https://www.dshs.state.tx.us/coronavirus/TexasCOVID19CaseCountData.xlsx'
temp = tempfile()
curl::curl_download(state_url, temp, mode = 'wb')
dshs_header = names(read_excel(temp, sheet = 1)[1])

current_year =  substr(Sys.Date(), 1, 4)
dshs_date = str_extract_all(dshs_header, '\\d{2}\\/\\d{2}\\/\\d{4}')[[1]][2]
# dshs_date = paste0(current_year, '/',  str_extract_all(dshs_header, '\\d*\\/\\d*')[[1]])
dshs_date = format(as.Date(dshs_date, '%m/%d/%Y'), '%Y_%m_%d')

# save state level file to historical database for longitudinal demo
curl::curl_download(state_url, paste0('original-sources/historical/state/dshs_',
                                dshs_date, '.xlsx'), mode = 'wb')
```
## DSHS Demographics


## POST 12/11 DEMOGRAPHIC SCRAPING 

```{r}

Clean_Demographics = function(sheet_name, file_date=date_out) {
  group_type = str_extract(sheet_name, 'Age|Gender|Race')
  stat_type = str_extract(sheet_name, 'Case|Fatal')
  
  if(stat_type == 'Case') {
  out_df = weekly_demo[[sheet_name]] %>%
    as.data.frame() %>%
    dplyr::select(1:2) %>%
    setNames(c('Group', 'Cases_Cumulative')) %>%
    filter(!Group %in% c('Pending DOB', 'Total', 'Unknown', 'Grand Total')) %>%
    mutate(Date = as.Date(file_date)) %>%
    mutate(Group_Type = group_type) %>%
    group_by(Date) %>%
    mutate(Cases_PCT = Cases_Cumulative / sum(Cases_Cumulative)) %>%
    dplyr::select(Date, Group_Type, Group, Cases_Cumulative, Cases_PCT)
  
  } else if (stat_type == 'Fatal') { 
  out_df = weekly_demo[sheet_name] %>% 
    as.data.frame() %>%
    dplyr::select(1:2) %>%
    setNames(c('Group', 'Deaths_Cumulative')) %>%
    filter(!Group %in% c('Pending DOB', 'Total', 'Unknown', 'Grand Total')) %>%
    mutate(Date = as.Date(file_date)) %>%
    mutate(Group_Type = group_type) %>%
    group_by(Date) %>%
    mutate(Deaths_PCT = Deaths_Cumulative / sum(Deaths_Cumulative)) %>%
    dplyr::select(Date, Group_Type, Group, Deaths_Cumulative, Deaths_PCT)
  }
  return(out_df)
}

# demo_releases = seq(as.Date('2020-09-25'), by = 'week', length = 200)
# 
# if (date_out %in% demo_releases) {
#   demo_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID19Demographics.xlsx'
#   curl::curl_download(demo_url, glue('original-sources/historical/demo-archive/demo_{date_out}.xlsx'))
#   temp = tempfile()
#   curl::curl_download(demo_url, temp, mode = 'wb')
#   weekly_demo = read_excel_allsheets(temp, col_option = FALSE)
# 
#   # --- temp demo fix 12/10 - 12/31
#   # missing_dates = seq.Date(from=as.Date('2021-12-10'), to=as.Date('2021-12-31'), by = 'week')
#   # for (m_date in as.character(missing_dates)) { 
#   #   weekly_demo = read_excel_allsheets(glue('original-sources/historical/demo-archive/demo_{m_date}.xlsx'),
#   #                                      col_option = FALSE)
#   daily_demo_stack = rbindlist(lapply(names(weekly_demo), function(x) Clean_Demographics(x, date_out)), fill = TRUE) %>%
#     mutate(Date = as.Date(Date)) %>%
#     group_by(Date, Group_Type, Group) %>% 
#     tidyr::fill(Deaths_Cumulative, .direction = 'updown') %>% 
#     tidyr::fill(Deaths_PCT, .direction = 'updown') %>%
#     slice(1) %>% 
#     ungroup()
#   write.csv(daily_demo_stack, paste0('original-sources/historical/demo/dshs_', date_out, '.csv'), row.names = FALSE)
# }

```


## Post 1/14
Case & Death file became single dataset containing archive of monthly data
```{r}
Clean_Demo_New = function(sheet_name) { 
  if (str_detect(sheet_name, 'Fatal|Confirmed')) { 
  
    group_type = str_extract(sheet_name, 'Age|Sex|Gender|Race')
    stat_type = str_extract(sheet_name, 'Cases|Fatalities')
    
    df = demographics_all[[sheet_name]] 
    
    clean_df = df %>% 
      slice(3:nrow(df)) %>% 
      setNames(df[2, ]) %>% 
      select(-Total) %>%
      pivot_longer(!1) %>% 
      setNames(c('Date', 'Group', stat_type)) %>% 
      filter(!str_detect(Date, 'Total|Notes')) %>%
      mutate(Date = as.Date(glue('01 {Date}'), '%d %B %Y')) %>% 
      mutate(Group_Type = group_type)
  
    return(clean_df)  
  }
}

# monthly
demo_releases = seq(as.Date('2022-01-01'), by = 'month', length = 50) + days(14)

if (date_out %in% demo_releases) {
  demo_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID19Demographics_Counts.xlsx'
  curl::curl_download(demo_url, glue('original-sources/historical/demo-archive/demo_{date_out}.xlsx'))


  all_demo_files = list.files('original-sources/historical/demo-archive', full.names = TRUE)
  monthly_update_dates = str_extract(all_demo_files, '\\d{4}-\\d{2}-\\d{2}') %>%
    as.Date() %>% 
    .[which(. >= as.Date('2022-01-14'))]
                             
  monthly_updates = sapply(monthly_update_dates, 
                           function(x) str_detect(all_demo_files, as.character(x)) %>%
                             which(.) %>%
                             all_demo_files[.]
                           )
  
  demographics_all = read_excel_allsheets(monthly_updates[length(monthly_updates)])

  cleaned_demo_new = lapply(names(demographics_all), function(x) Clean_Demo_New(x)) %>% 
    rbindlist(fill = TRUE) %>% 
    rename(Deaths_Monthly = Fatalities,
           Cases_Monthly = Cases) %>%
    mutate(across(c(Deaths_Monthly, Cases_Monthly), as.numeric)) %>%
    group_by(Date, Group_Type, Group) %>%
    tidyr::fill(Deaths_Monthly, .direction = 'updown') %>% 
    tidyr::fill(Cases_Monthly, .direction = 'updown') %>% 
    slice(1) %>% 
    ungroup() %>% 
    arrange(Date, Group_Type, Group) %>% 
    relocate(Group_Type, .before='Group') %>% 
    mutate(Group_Type = str_replace_all(Group_Type, c('Sex' = 'Gender'))) %>% 
    mutate(Group = ifelse(Group_Type == 'Age' & !str_detect(Group, 'Unknown'), glue('{Group} years'), Group)) %>% 
    group_by(Date, Group_Type) %>%
    mutate(Deaths_PCT = Deaths_Monthly / sum(Deaths_Monthly, na.rm = TRUE)) %>%
    mutate(Cases_PCT = Cases_Monthly / sum(Cases_Monthly, na.rm = TRUE)) %>% 
    filter(!is.na(Date))
    # mutate(Date = ifelse(is.na(Date), 'Unknown', as.character(Date)))

  write_csv(cleaned_demo_new, 'tableau/stacked_demographics_v2.csv')
}
```
